{"docstore/metadata": {"c1bb021d-c026-414e-978d-e50117b7b240": {"doc_hash": "8b8f6240aa74045321746b588967388449e5c2347fba369ce746d5a4c3b3d62a"}, "b55fad2e-5468-4402-83ba-2a4dcccbb970": {"doc_hash": "e8f5cfb0641c9020485c8ee49d5f4e235b20f755e8131745c84bb9591e1e7ec7"}, "526a3a14-babc-49ab-b719-060f22c8acde": {"doc_hash": "4909a67671964d786b04a74d81202abe7d205197e550f052f740349cd3fde539"}, "142d2b06-2a04-4014-b1ba-e900d1f1a974": {"doc_hash": "6bb6e193ea29f57835cbe2c8f44fe09d5607fd4d280f2b266ba024ce8b69f210"}, "8b4cb2e3-5daf-4f35-9422-b871544a3553": {"doc_hash": "c5c2c391188f6657c9770406d59334a607407b54ca80df37efeea073f9020b2a"}, "46e93b41-ad95-4467-909a-25bee6310e92": {"doc_hash": "841f1263b81e50f7b438d2ddbd9c5f0d973b53a7d9c5493df64fa1d3c3bf4b73"}, "a2397c02-ef77-4e66-a996-bd92936a906a": {"doc_hash": "09c0930a2864c26d85c44ceb845db1fad056207fbf7d36be60210724e785aa95"}, "c8e54ded-0a8c-4735-84cc-717723633d3c": {"doc_hash": "ee4e32c6569b298425ec7c4c9f35fb00774d0a74d74547cf9313db854cbc7fa6"}, "e2be2921-7682-4cd6-97ed-f4febdca9ede": {"doc_hash": "4729a15fdd5b2933e134fb6c6724105c840b4ab31c3497c5356652521f1b5b39"}, "5042ea56-9bd0-42bd-972f-b469bdc85dd3": {"doc_hash": "1245188b856c2847b116f54445a1a71d0b175113484fa5881b2b3b3cf041dd43"}, "04960000-bdbb-4945-9b63-1b573c1547ff": {"doc_hash": "d974dcb70743ac7bb2dd502589feb63b5437683b542353158ad07a9c047e8950"}, "b9a72acd-14d0-438c-966b-ae3f50a604d0": {"doc_hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b"}, "4028d764-4d2a-43ab-b597-c78ea8082de0": {"doc_hash": "c99bf9fd479b4c0341b97e93ba5fe1bc1e3e84d797d5fc3c37e377ddaa2c38f7"}, "e692095b-711d-46c7-b7b8-8a052dc2e6a1": {"doc_hash": "66ffd3950c82d43e3fffd066dd69c9075f5a075b863d7c8de79611726e9fc21a"}, "6eff1c77-d741-4887-84c3-a75c26a30af4": {"doc_hash": "38e43daf146d33b3b3995ad84573e930081e2e61d39ac0427f3b3ccedf7439ad"}, "33475eeb-211e-4d3b-bea8-9814bb151a88": {"doc_hash": "882c66e2c0cb98fd636e85ce85aabd4fe6892aa2177e599b298bbc39f33fd350"}, "d62af2ac-59fc-49bf-929a-cfc3267c326e": {"doc_hash": "2637c50fcdf927119efb9e06e063521319dad06430d90990de01d060714be365"}, "8b0f921c-88eb-469d-a896-42883dba0683": {"doc_hash": "cc2b046e1b7a853734605c2a68fab25a0d2ae9249106ca7b9bd5cd4f72b4ec78"}, "6c4cf643-8275-44c8-bb4a-d059ee2cce6c": {"doc_hash": "6ec507bcb64a0142fffe530f6ec7c68947f989c754202cd03bbf9f095be68d84"}, "4a66f4ae-e766-43cd-a75e-36273460ca82": {"doc_hash": "5ac814b97be61e283423d50560fc24efc846c097a3862ae0cc0111247653c2fe"}, "ec294211-ea6c-422a-9fbf-3ffdf691b338": {"doc_hash": "e3fdbc5c15e2d4ff6035ab470f4999edf06c9ad7b3b637791f3ad595eac9ab1c", "ref_doc_id": "c1bb021d-c026-414e-978d-e50117b7b240"}, "aca37b48-6b1f-430f-b20b-5df62a74059a": {"doc_hash": "8e603b3ae71c6bb7698cbf37be7d50b00bd99158c9b0e778cca561bb5ca056e5", "ref_doc_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970"}, "ec3a6d6c-8ce3-4944-a2a9-1c00ddafc32c": {"doc_hash": "9f6da4fcaafccefb9554613de9b0771ce3bec757fc79e0e0a1758b1caec3f1d5", "ref_doc_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970"}, "b203f11e-0356-405e-b791-9c6911b38bf6": {"doc_hash": "f0455d38d44f091e648eb61ff99016d6bc37684e909827ffab3991350f2a3495", "ref_doc_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970"}, "670affde-bda1-4aa7-8d08-c792e77bfe8c": {"doc_hash": "3c923544fa7a7c49757ff7e5ddb4e03375564ce67f2705309eb4451fdbfc255b", "ref_doc_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970"}, "a20f28c8-74f3-43d8-aafe-5588bf9d31f7": {"doc_hash": "08a7761dcd73386d53522d84401a89867fa62dc57660a930a6d10a471201d4b3", "ref_doc_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970"}, "370b1bb6-4124-420a-a37c-db8eb51d68ec": {"doc_hash": "f63ccfd4c00aaaa01b4b70b1ddcf4aa9bff7ac64e2c97d928325efd797fbd095", "ref_doc_id": "526a3a14-babc-49ab-b719-060f22c8acde"}, "89ebeb32-70cb-4650-a253-7f734cfaa477": {"doc_hash": "bcf57bb015cb843aa738921e8841f78786a9d0cbca32db3fa98d971c808b9d08", "ref_doc_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974"}, "d28bf661-b545-4d7f-b694-b82e868764ef": {"doc_hash": "73bdc0bd9477bcbc9ed0ed99e88eb725e62f9735b20b71df61f9ad634b5f3fb3", "ref_doc_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974"}, "d05750ce-0fc9-461c-8960-3b4226dc7cb4": {"doc_hash": "9922f55cf387a8ff91608f4d8c802d7d02fd7b7b38e8d4f0f43b35af63f6f763", "ref_doc_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974"}, "0fbed2a3-552f-4e86-b264-b5bb0b8081d9": {"doc_hash": "d190152b6bda104f82d8256fecd3d2ae5d7da38337127f208aacf5d474591c04", "ref_doc_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974"}, "c237c144-f112-495f-b0a6-b4b3fd320948": {"doc_hash": "219bf826631ad0e887bd9e70dcfcb635f0abe6f0f25ad466adcb9bc623237ff3", "ref_doc_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974"}, "7686b79b-7ec6-44cf-8c8f-ea127aeecc50": {"doc_hash": "1b68c9412cf11caa55558bf4e22b4e15ad13ee718aaf620a7819f8edf0534b3d", "ref_doc_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974"}, "c86b5e4e-81b6-4f44-823d-bdb26cc82c6c": {"doc_hash": "d2da91fea7518dd926072080ede0cd311f025232d5a8dcdc265fef2cb3843eb5", "ref_doc_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974"}, "b0d26fbf-24ad-4369-828f-0a35cb2ae210": {"doc_hash": "d34447cadb7bd80fe7dbcc604b9281a1a825d9debe785ecf6315edb9a0920bc6", "ref_doc_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974"}, "789a2479-3af1-4241-92fe-08a7e2c4bcd2": {"doc_hash": "5f4d4aeaf530d3175bcfb8ef62147ec6a972d73ca8c733dc6639af6af6d6ea3b", "ref_doc_id": "8b4cb2e3-5daf-4f35-9422-b871544a3553"}, "683b30de-b242-44b3-bdcc-1f11bf7cb7a9": {"doc_hash": "2163cf5253fbc597cffbdbfee8e95ff9b34c60cbcc82e27e922fc504532768c9", "ref_doc_id": "46e93b41-ad95-4467-909a-25bee6310e92"}, "472224fc-e18f-459f-a378-42775b012790": {"doc_hash": "6c60339182c5ccf5fd316efc4d17e7802be1a589ab50def87e2d0dea8ae66437", "ref_doc_id": "46e93b41-ad95-4467-909a-25bee6310e92"}, "93638a5c-ec51-43d4-8fc0-7b7d2dd42b0f": {"doc_hash": "78bdd5185edf8314ac77e51b776fbe1e393245e505dfc6fa61b92f13c606a632", "ref_doc_id": "46e93b41-ad95-4467-909a-25bee6310e92"}, "8b057e07-3860-4b09-bec1-6aef08707715": {"doc_hash": "b7008c90b3e0df15fd1720602247d4130533d52c26c6743fbe0bd9ba2b0348a3", "ref_doc_id": "46e93b41-ad95-4467-909a-25bee6310e92"}, "243e90fc-5988-4ff2-819b-92866b8a2593": {"doc_hash": "e19c19e9d52b9103149ead18e008dfa323acbd9cf6424021056c5b9dc3be9f88", "ref_doc_id": "46e93b41-ad95-4467-909a-25bee6310e92"}, "0a2230cf-d536-4d4e-8d6e-4a79a9549907": {"doc_hash": "e8b9fa1c46dd48f6a8203583234a8a4e2a2a463f33e0fd0379587968f1a9c34a", "ref_doc_id": "46e93b41-ad95-4467-909a-25bee6310e92"}, "f87f924d-dd4d-4e3e-817b-99be324cf7d6": {"doc_hash": "072196647e4a972172ecaefc1593d016ebbb3e5f926dabfd3c1ddf5180476a6b", "ref_doc_id": "46e93b41-ad95-4467-909a-25bee6310e92"}, "b893a183-5a4c-406b-a547-3d237e52ebfd": {"doc_hash": "f0f5530a68bc33ed96e028804989c5eaab85f75a5dd1d89b5dbc17adf1fe068b", "ref_doc_id": "46e93b41-ad95-4467-909a-25bee6310e92"}, "dd337360-80af-4c87-9c5f-b933e04cdf49": {"doc_hash": "eb480c37cad071f7028bf18a2d04790f1496401fd2d3abfdf4b495112758d0ab", "ref_doc_id": "a2397c02-ef77-4e66-a996-bd92936a906a"}, "ccc71d38-5a26-47c6-ad36-c889b3ebec78": {"doc_hash": "72a67b003c7452d271ceaedd82d2cc737990ab826173977698111e8015122e05", "ref_doc_id": "c8e54ded-0a8c-4735-84cc-717723633d3c"}, "667dff72-31cf-45b3-9418-4fba278c21d9": {"doc_hash": "a0387d3532950b197df33f534caf0f52553328a9d142f6a72dc0b115c0e7244a", "ref_doc_id": "c8e54ded-0a8c-4735-84cc-717723633d3c"}, "07962b5f-fbf2-4244-b93c-44d043b8ccb8": {"doc_hash": "f74395b0ab0f544f77b7c0a179a926cdf5f6064bdd9880529c11b1ed8dfb3686", "ref_doc_id": "e2be2921-7682-4cd6-97ed-f4febdca9ede"}, "15caced0-bd93-4f15-97dc-2fbf877182c5": {"doc_hash": "167fc74427e28aefe13ba3b6ed7851a4a59c2bc47d7bd6fa14422386f0566bfd", "ref_doc_id": "e2be2921-7682-4cd6-97ed-f4febdca9ede"}, "e6b0b270-46ac-47b1-8ddb-7461aee811f3": {"doc_hash": "12b2426889e938d9f83f9ea89f5da51ccb457466cdf5ccdbf438da0d0dee5e35", "ref_doc_id": "e2be2921-7682-4cd6-97ed-f4febdca9ede"}, "6a8056b6-ec31-4b40-9466-2bbbf6f2ab54": {"doc_hash": "5ec0c1d715c12931dd776ae29097e55084cf6bca6e66eabcf3608c148e497dcb", "ref_doc_id": "5042ea56-9bd0-42bd-972f-b469bdc85dd3"}, "c6266478-f7d5-497c-b2d1-bbfd69f585e4": {"doc_hash": "880a19e3a7bcd79d888ba686aa4f078f3013edd21cfdfac71dd8f530dd676f26", "ref_doc_id": "5042ea56-9bd0-42bd-972f-b469bdc85dd3"}, "fddc9aef-13f1-4501-97bd-5c8857c46ed4": {"doc_hash": "0e0da755c0e9da0d785e6c19ad36cd545fb7dfe84fa27a1a1d9d55ab3a4289ba", "ref_doc_id": "5042ea56-9bd0-42bd-972f-b469bdc85dd3"}, "3887f856-f3bb-4ec9-afba-a4d4b730a96b": {"doc_hash": "12f4e214b06f504cdd1085fb7ba5bdcb7133dfb1f6edf732db3fb6565a716d3f", "ref_doc_id": "04960000-bdbb-4945-9b63-1b573c1547ff"}, "d1245507-4d09-436e-a832-69b255e4acf3": {"doc_hash": "2a8a4f5d9eeb6aa58b0690f2d7005ae8377e44bc1de96a15550d69a1c19498cc", "ref_doc_id": "04960000-bdbb-4945-9b63-1b573c1547ff"}, "bfa5e719-3f1c-4a82-8b2d-c7e1b0c8d716": {"doc_hash": "56b21a41dd961d0f5d186c90d145b5335f0021d0761306e4d00f021246183456", "ref_doc_id": "04960000-bdbb-4945-9b63-1b573c1547ff"}, "c1ee8682-6045-4237-840c-176bf074517e": {"doc_hash": "4c36e322796eade0960873b990cd092a61cb2b6ad7e6214529d1a6cad7fe7994", "ref_doc_id": "04960000-bdbb-4945-9b63-1b573c1547ff"}, "84651a80-f1ca-469f-a720-0323ac01dfa2": {"doc_hash": "06a9c6a607ddf81d98dbde9859069d20cefb1accb7c013a339b7a41e1136a03c", "ref_doc_id": "04960000-bdbb-4945-9b63-1b573c1547ff"}, "eb670015-50de-45f3-87d3-9a81932f56ba": {"doc_hash": "87110de9d34b6326d83e14f61f7d4c4412d5b1e8ead930d6ff6caf8d80bd738b", "ref_doc_id": "04960000-bdbb-4945-9b63-1b573c1547ff"}, "065feb0e-d739-455b-b15a-1c3f6009134c": {"doc_hash": "37cce30604ce35225096137818bdb7af3de23a1a8902c1db3bd00af4a404fe99", "ref_doc_id": "04960000-bdbb-4945-9b63-1b573c1547ff"}, "adb90f85-b90a-40bd-99f9-d0d3dd1d2166": {"doc_hash": "8d5ed17e384fa5b6ed6c9223aa1aa79f0ac9618b5562327c477564dcd6e13a22", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "398b5d0b-9007-47da-b894-fa0ab1e4a092": {"doc_hash": "e17baf45dc8a782a3b08f9d3420ba1eb77a5e72cda93f1905dc3f6828dfd8dd7", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "bd877776-d1ba-4c2a-8182-cf6857fe1788": {"doc_hash": "cb4615d0e5f5fd30aae4d6d801bc51d0208d4549da201cfec360a7d58158cc4e", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "b9f62199-5805-4461-a2d5-67f69642edd4": {"doc_hash": "66029d7ec1bfa58b270503614caef627d0f5dff8ceb3ef4356e9f75282d20a05", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "564888d8-ef72-4be8-8c44-ed42371db73d": {"doc_hash": "1c39eb69105c245c0b1b64dedbfb1ada41c4c09dacaf050825cd1598cfc9dc8a", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "a260fdeb-846a-470b-9d3b-1e1d7e53bb34": {"doc_hash": "f6a04a38ef8e66dc905237ccb65094cbc9dcede7a7c8576da2fe18f80bb519ca", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "2115b34a-a52e-4c77-8f05-1354636b69ff": {"doc_hash": "ab0c6ed08f93acc69475669f447092ae4c2b144a7bf5c30c73d9b42dc1676e14", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "a43c2e60-0840-4ea9-9115-d5d3f2bf2a1c": {"doc_hash": "2fa1bd60513d896b1b55973229df2d0525f3fefaa42fe7b4334802eba1273716", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "b0131a46-10dd-4d1f-a083-3b2e3e31ef72": {"doc_hash": "3f423df69636003df052f704798b9a3a65ef660ae5f6ae9211860101e7f12881", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "10483143-2734-4430-8a32-8e0cb6a47761": {"doc_hash": "3464bdd88c12390c6ce039472f4555273266d47c40eb551b0a8a6966c9c86eeb", "ref_doc_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0"}, "aa83e7ed-7fe7-41c8-b76d-87c18ed9c522": {"doc_hash": "f9d1d88c65b9e66368534c877d8ddfffd5faa1ff7a866bda8c7161ec37152a4d", "ref_doc_id": "4028d764-4d2a-43ab-b597-c78ea8082de0"}, "53fc4b1f-5534-4133-9725-7a8394a76498": {"doc_hash": "aed5251020538361ed0430c3251a0f69087c5f143beaefa7a9fa05d6fc5c9ec1", "ref_doc_id": "4028d764-4d2a-43ab-b597-c78ea8082de0"}, "8ae21b56-433b-47d4-acb2-8bc98f2c745c": {"doc_hash": "02bbe8ebd30cbda52d6f5f6a33382cef39fd6123b35df630c24d697bb33ec69d", "ref_doc_id": "4028d764-4d2a-43ab-b597-c78ea8082de0"}, "4f83db66-c900-48be-9738-5a55289ca695": {"doc_hash": "3a209058064ffcb7fe8000c9e9eb66f1740168c054b6e3ba97e8be57df8f980c", "ref_doc_id": "4028d764-4d2a-43ab-b597-c78ea8082de0"}, "db1e61d0-568f-4a5b-95d3-748be1b2c1af": {"doc_hash": "4cb1b0f74b72e1a2292ecca86cbe64a1ec43f0853a2d1afefd173e4ae31964af", "ref_doc_id": "4028d764-4d2a-43ab-b597-c78ea8082de0"}, "2525f3b0-a618-4880-a597-0ff9ea4a4639": {"doc_hash": "585aefdb776f94c565999e70c90413e764160c00234804c1881292434b40eec7", "ref_doc_id": "4028d764-4d2a-43ab-b597-c78ea8082de0"}, "3e754b4c-01d4-4040-8fdb-8beb3cdd70a8": {"doc_hash": "66ffd3950c82d43e3fffd066dd69c9075f5a075b863d7c8de79611726e9fc21a", "ref_doc_id": "e692095b-711d-46c7-b7b8-8a052dc2e6a1"}, "f62be28f-ba87-424e-977a-d644aac7eef8": {"doc_hash": "fade4a1f8f69bfe0d67620a3d8b6e6dc9ccf98ad726eebeb76d3712c904e1c24", "ref_doc_id": "6eff1c77-d741-4887-84c3-a75c26a30af4"}, "b12ee25d-cb1a-4b8f-af02-42f38a09f449": {"doc_hash": "d8816b0043fa6f647a78c59664a85163c3aaeaf49ce4bca1837fcda98a6e9676", "ref_doc_id": "6eff1c77-d741-4887-84c3-a75c26a30af4"}, "8b3d4e32-ddb3-4eda-b1d7-bd348c98b8c9": {"doc_hash": "09f816394a267cd8fecf9de8ace23475f6df54e994b09d5652ec74612bf1f04f", "ref_doc_id": "6eff1c77-d741-4887-84c3-a75c26a30af4"}, "ed31e661-e370-4374-89ad-42f25ea4d794": {"doc_hash": "0b27ffb71511aaaa7c22e072930a8b6be3bd96d139500e10873ca084678ce5a3", "ref_doc_id": "6eff1c77-d741-4887-84c3-a75c26a30af4"}, "328deb55-38b7-4c8d-9612-96dd37f39df8": {"doc_hash": "e06b0cd5330760ae4b4f7e5789259743bd16fc27e2782f3b3734639784b450b7", "ref_doc_id": "33475eeb-211e-4d3b-bea8-9814bb151a88"}, "fa7e52b2-6abb-4f84-ab65-484b24861dc5": {"doc_hash": "dd35af6637937b59d76a1457311cb1b77bca5008929b497c58523126d09282ca", "ref_doc_id": "33475eeb-211e-4d3b-bea8-9814bb151a88"}, "e2d373b3-70f9-465b-a292-5a1f5ff2b04e": {"doc_hash": "7be448bf4d7e259d87cb7762d4f1520a4e0c7ce7efaacf15355c523706f17334", "ref_doc_id": "33475eeb-211e-4d3b-bea8-9814bb151a88"}, "00e0f831-a1ed-4d02-82ae-aa620fc5d848": {"doc_hash": "e9aa92185c94e5a4b0334a3febe8bbf3ad16d79daaf3a71a80f02dac749db1b4", "ref_doc_id": "33475eeb-211e-4d3b-bea8-9814bb151a88"}, "c7bd55a2-2933-4ef3-bc98-37c0c0944fd2": {"doc_hash": "d8bd5e59a50ece065dbb7ef35a1e5ffc02f14a0a0e73f2aa02321171c47c2dec", "ref_doc_id": "33475eeb-211e-4d3b-bea8-9814bb151a88"}, "85c6f2ad-a505-42a1-b5d2-449f2231304a": {"doc_hash": "dc3045c9521193007fac952f2b9c932303b856b0f411ac758a4642e691f63239", "ref_doc_id": "33475eeb-211e-4d3b-bea8-9814bb151a88"}, "a1bd4651-cb3c-4cab-a0e1-9dc57d636a51": {"doc_hash": "a4fdb733d82d442995b3311e45312cdd81a181c9fd776cef763fc02cddb16f4f", "ref_doc_id": "33475eeb-211e-4d3b-bea8-9814bb151a88"}, "daf23db7-2e87-4dcc-9644-33c491552f4c": {"doc_hash": "adccd6e125aca1ee6fc391637ab223c19a42910396fa6dce2c9d894860d87126", "ref_doc_id": "d62af2ac-59fc-49bf-929a-cfc3267c326e"}, "b245d025-bcd9-48c8-bade-5fe385a2e175": {"doc_hash": "c9b2820b2c8099e3b603908b03f6641a6cb295a8f227883b19eeaf268fae01a6", "ref_doc_id": "8b0f921c-88eb-469d-a896-42883dba0683"}, "d8f8d5cd-1272-4c96-88da-e6d07170aac2": {"doc_hash": "6caefbb63734a745a86f2094f4b25d5351d5c927d3c6e76e9c739c710a74a240", "ref_doc_id": "6c4cf643-8275-44c8-bb4a-d059ee2cce6c"}, "02ecfb36-afed-4669-9700-dc1beb9b54c3": {"doc_hash": "ff6f5219bc3e34a8ef4d015cf96af3bdc465e593828ad6a266bdcfa92c321118", "ref_doc_id": "6c4cf643-8275-44c8-bb4a-d059ee2cce6c"}, "5189a10d-5554-44b8-ab70-da50fe3b23a4": {"doc_hash": "901f3999461b321ef529b66b892d2e8dfacd4eac30fa13fb581ebec10db2559c", "ref_doc_id": "4a66f4ae-e766-43cd-a75e-36273460ca82"}, "35e34bf0-e5ca-4f25-97c4-f10b66f8da2b": {"doc_hash": "d4ed5d5fbda8e287ce2d55713b6fd5563b6c2342b523eda27e1bfc23eb66d057", "ref_doc_id": "4a66f4ae-e766-43cd-a75e-36273460ca82"}, "909eda1a-62c4-459b-9148-6f2dc785e81a": {"doc_hash": "3b71bd953ed98bac7035f2eab289cb6c5cdf90706451cfbb013fa59e081e67b8", "ref_doc_id": "4a66f4ae-e766-43cd-a75e-36273460ca82"}, "5fefe9c5-86a8-47cf-94a9-8739b87c1e37": {"doc_hash": "35efd4d9bef36e6a4546585f4988ea0074d691d7206448ba01619398ab32d882", "ref_doc_id": "4a66f4ae-e766-43cd-a75e-36273460ca82"}, "9b7ac8dd-ad1a-4d2f-8cc7-fd2c08cfe167": {"doc_hash": "529df5e1de2e3a1b10dc51af729e3261c7b49850e8fa08cc9bed109995ee359d", "ref_doc_id": "4a66f4ae-e766-43cd-a75e-36273460ca82"}}, "docstore/data": {"ec294211-ea6c-422a-9fbf-3ffdf691b338": {"__data__": {"id_": "ec294211-ea6c-422a-9fbf-3ffdf691b338", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "file_size": 285, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c1bb021d-c026-414e-978d-e50117b7b240", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "file_size": 285, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "8b8f6240aa74045321746b588967388449e5c2347fba369ce746d5a4c3b3d62a", "class_name": "RelatedNodeInfo"}}, "text": "# Configure a logger from trackpy.\r\n# This must be done before utils is imported.\r\nimport logging\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nfrom ._version import get_versions\r\n__version__ = get_versions()['version']\r\ndel get_versions\r\n\r\nfrom trackpy.api import *\r\n\r\nhandle_logging()", "start_char_idx": 0, "end_char_idx": 283, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aca37b48-6b1f-430f-b20b-5df62a74059a": {"__data__": {"id_": "aca37b48-6b1f-430f-b20b-5df62a74059a", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e8f5cfb0641c9020485c8ee49d5f4e235b20f755e8131745c84bb9591e1e7ec7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ec3a6d6c-8ce3-4944-a2a9-1c00ddafc32c", "node_type": "1", "metadata": {}, "hash": "1bb9caa1e41c9c7a2fe1aaa54594a78ffbc128fdf899d3ae66cc25e2ea1ab9b0", "class_name": "RelatedNodeInfo"}}, "text": "# This file helps to compute a version number in source trees obtained from\r\n# git-archive tarball (such as those provided by githubs download-from-tag\r\n# feature). Distribution tarballs (built by setup.py sdist) and build\r\n# directories (produced by setup.py build) will contain a much shorter file\r\n# that just contains the computed version number.\r\n\r\n# This file is released into the public domain. Generated by\r\n# versioneer-0.15 (https://github.com/warner/python-versioneer)\r\n\r\nimport errno\r\nimport os\r\nimport re\r\nimport subprocess\r\nimport sys\r\n\r\n\r\ndef get_keywords():\r\n    # these strings will be replaced by git during git-archive.\r\n    # setup.py/versioneer.py will grep for the variable names, so they must\r\n    # each be defined on a line of their own. _version.py will just call\r\n    # get_keywords().\r\n    git_refnames = \"$Format:%d$\"\r\n    git_full = \"$Format:%H$\"\r\n    keywords = {\"refnames\": git_refnames, \"full\": git_full}\r\n    return keywords\r\n\r\n\r\nclass VersioneerConfig:\r\n    pass\r\n\r\n\r\ndef get_config():\r\n    # these strings are filled in when 'setup.py versioneer' creates\r\n    # _version.py\r\n    cfg = VersioneerConfig()\r\n    cfg.VCS = \"git\"\r\n    cfg.style = \"pep440\"\r\n    cfg.tag_prefix = \"v\"\r\n    cfg.parentdir_prefix = \"None\"\r\n    cfg.versionfile_source = \"trackpy/_version.py\"\r\n    cfg.verbose = False\r\n    return cfg\r\n\r\n\r\nclass NotThisMethod(Exception):\r\n    pass\r\n\r\n\r\nLONG_VERSION_PY = {}\r\nHANDLERS = {}\r\n\r\n\r\ndef register_vcs_handler(vcs, method):  # decorator\r\n    def decorate(f):\r\n        if vcs not in HANDLERS:\r\n            HANDLERS[vcs] = {}\r\n        HANDLERS[vcs][method] = f\r\n        return f\r\n    return decorate\r\n\r\n\r\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):\r\n    assert isinstance(commands, list)\r\n    p = None\r\n    for c in commands:\r\n        try:\r\n            dispcmd = str([c] + args)\r\n            # remember shell=False, so use git.cmd on windows, not just git\r\n            p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE,\r\n                                 stderr=(subprocess.PIPE if hide_stderr\r\n                                         else None))\r\n            break\r\n        except OSError:\r\n            e = sys.exc_info()[1]\r\n            if e.errno == errno.ENOENT:\r\n                continue\r\n            if verbose:\r\n                print(\"unable to run %s\" % dispcmd)\r\n                print(e)\r\n            return None\r\n    else:\r\n        if verbose:\r\n            print(\"unable to find command, tried {}\".format(commands))\r\n        return None\r\n    stdout = p.communicate()[0].strip().decode()\r\n    if p.returncode != 0:\r\n        if verbose:\r\n            print(\"unable to run %s (error)\" % dispcmd)\r\n        return None\r\n    return stdout\r\n\r\n\r\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\r\n    # Source tarballs conventionally unpack into a directory that includes\r\n    # both the project name and a version string.\r\n    dirname = os.path.basename(root)\r\n    if not dirname.startswith(parentdir_prefix):\r\n        if verbose:\r\n            print(\"guessing rootdir is '%s', but '%s' doesn't start with \"\r\n                  \"prefix '%s'\" % (root, dirname, parentdir_prefix))\r\n        raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")\r\n    return {\"version\": dirname[len(parentdir_prefix):],\r\n            \"full-revisionid\": None,\r\n            \"dirty\": False, \"error\": None}\r\n\r\n\r\n@register_vcs_handler(\"git\", \"get_keywords\")\r\ndef git_get_keywords(versionfile_abs):\r\n    # the code embedded in _version.py can just fetch the value of these\r\n    # keywords. When used from setup.py, we don't want to import _version.py,\r\n    # so we do it with a regexp instead. This function is not used from\r\n    # _version.py.\r\n    keywords = {}\r\n    try:\r\n        f = open(versionfile_abs)\r\n        for line in f.readlines():\r\n            if line.strip().startswith(\"git_refnames =\"):\r\n                mo = re.search(r'=\\s*\"(.*)\"', line)\r\n                if mo:\r\n                    keywords[\"refnames\"] = mo.group(1)\r\n            if line.strip().startswith(\"git_full =\"):\r\n                mo = re.search(r'=\\s*\"(.", "start_char_idx": 0, "end_char_idx": 4125, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ec3a6d6c-8ce3-4944-a2a9-1c00ddafc32c": {"__data__": {"id_": "ec3a6d6c-8ce3-4944-a2a9-1c00ddafc32c", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e8f5cfb0641c9020485c8ee49d5f4e235b20f755e8131745c84bb9591e1e7ec7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aca37b48-6b1f-430f-b20b-5df62a74059a", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "8e603b3ae71c6bb7698cbf37be7d50b00bd99158c9b0e778cca561bb5ca056e5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b203f11e-0356-405e-b791-9c6911b38bf6", "node_type": "1", "metadata": {}, "hash": "4af12d07ca919cba14565be610e066a400c7a1b5232173868c1821395d4556f3", "class_name": "RelatedNodeInfo"}}, "text": "When used from setup.py, we don't want to import _version.py,\r\n    # so we do it with a regexp instead. This function is not used from\r\n    # _version.py.\r\n    keywords = {}\r\n    try:\r\n        f = open(versionfile_abs)\r\n        for line in f.readlines():\r\n            if line.strip().startswith(\"git_refnames =\"):\r\n                mo = re.search(r'=\\s*\"(.*)\"', line)\r\n                if mo:\r\n                    keywords[\"refnames\"] = mo.group(1)\r\n            if line.strip().startswith(\"git_full =\"):\r\n                mo = re.search(r'=\\s*\"(.*)\"', line)\r\n                if mo:\r\n                    keywords[\"full\"] = mo.group(1)\r\n        f.close()\r\n    except OSError:\r\n        pass\r\n    return keywords\r\n\r\n\r\n@register_vcs_handler(\"git\", \"keywords\")\r\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\r\n    if not keywords:\r\n        raise NotThisMethod(\"no keywords at all, weird\")\r\n    refnames = keywords[\"refnames\"].strip()\r\n    if refnames.startswith(\"$Format\"):\r\n        if verbose:\r\n            print(\"keywords are unexpanded, not using\")\r\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\r\n    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\r\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\r\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\r\n    TAG = \"tag: \"\r\n    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\r\n    if not tags:\r\n        # Either we're using git < 1.8.3, or there really are no tags. We use\r\n        # a heuristic: assume all version tags have a digit. The old git %d\r\n        # expansion behaves like git log --decorate=short and strips out the\r\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\r\n        # between branches and tags. By ignoring refnames without digits, we\r\n        # filter out many common branch names like \"release\" and\r\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\r\n        tags = {r for r in refs if re.search(r'\\d', r)}\r\n        if verbose:\r\n            print(\"discarding '%s', no digits\" % \",\".join(refs-tags))\r\n    if verbose:\r\n        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\r\n    for ref in sorted(tags):\r\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\r\n        if ref.startswith(tag_prefix):\r\n            r = ref[len(tag_prefix):]\r\n            if verbose:\r\n                print(\"picking %s\" % r)\r\n            return {\"version\": r,\r\n                    \"full-revisionid\": keywords[\"full\"].strip(),\r\n                    \"dirty\": False, \"error\": None\r\n                    }\r\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\r\n    if verbose:\r\n        print(\"no suitable tags, using unknown + full revision id\")\r\n    return {\"version\": \"0+unknown\",\r\n            \"full-revisionid\": keywords[\"full\"].strip(),\r\n            \"dirty\": False, \"error\": \"no suitable tags\"}\r\n\r\n\r\n@register_vcs_handler(\"git\", \"pieces_from_vcs\")\r\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\r\n    # this runs 'git' from the root of the source tree. This only gets called\r\n    # if the git-archive 'subst' keywords were *not* expanded, and\r\n    # _version.py hasn't already been rewritten with a short version string,\r\n    # meaning we're inside a checked out source tree.", "start_char_idx": 3582, "end_char_idx": 6899, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b203f11e-0356-405e-b791-9c6911b38bf6": {"__data__": {"id_": "b203f11e-0356-405e-b791-9c6911b38bf6", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e8f5cfb0641c9020485c8ee49d5f4e235b20f755e8131745c84bb9591e1e7ec7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ec3a6d6c-8ce3-4944-a2a9-1c00ddafc32c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "9f6da4fcaafccefb9554613de9b0771ce3bec757fc79e0e0a1758b1caec3f1d5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "670affde-bda1-4aa7-8d08-c792e77bfe8c", "node_type": "1", "metadata": {}, "hash": "1599dbf439c4b06c85f78a9f8dc362dca59beab545519eb272d5175aba212a36", "class_name": "RelatedNodeInfo"}}, "text": "This only gets called\r\n    # if the git-archive 'subst' keywords were *not* expanded, and\r\n    # _version.py hasn't already been rewritten with a short version string,\r\n    # meaning we're inside a checked out source tree.\r\n\r\n    if not os.path.exists(os.path.join(root, \".git\")):\r\n        if verbose:\r\n            print(\"no .git in %s\" % root)\r\n        raise NotThisMethod(\"no .git directory\")\r\n\r\n    GITS = [\"git\"]\r\n    if sys.platform == \"win32\":\r\n        GITS = [\"git.cmd\", \"git.exe\"]\r\n    # if there is a tag, this yields TAG-NUM-gHEX[-dirty]\r\n    # if there are no tags, this yields HEX[-dirty] (no NUM)\r\n    describe_out = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\r\n                                      \"--always\", \"--long\"],\r\n                               cwd=root)\r\n    # --long was added in git-1.5.5\r\n    if describe_out is None:\r\n        raise NotThisMethod(\"'git describe' failed\")\r\n    describe_out = describe_out.strip()\r\n    full_out = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\r\n    if full_out is None:\r\n        raise NotThisMethod(\"'git rev-parse' failed\")\r\n    full_out = full_out.strip()\r\n\r\n    pieces = {}\r\n    pieces[\"long\"] = full_out\r\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\r\n    pieces[\"error\"] = None\r\n\r\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\r\n    # TAG might have hyphens.\r\n    git_describe = describe_out\r\n\r\n    # look for -dirty suffix\r\n    dirty = git_describe.endswith(\"-dirty\")\r\n    pieces[\"dirty\"] = dirty\r\n    if dirty:\r\n        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\r\n\r\n    # now we have TAG-NUM-gHEX or HEX\r\n\r\n    if \"-\" in git_describe:\r\n        # TAG-NUM-gHEX\r\n        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\r\n        if not mo:\r\n            # unparseable. Maybe git-describe is misbehaving?\r\n            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\r\n                               % describe_out)\r\n            return pieces\r\n\r\n        # tag\r\n        full_tag = mo.group(1)\r\n        if not full_tag.startswith(tag_prefix):\r\n            if verbose:\r\n                fmt = \"tag '%s' doesn't start with prefix '%s'\"\r\n                print(fmt % (full_tag, tag_prefix))\r\n            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\r\n                               % (full_tag, tag_prefix))\r\n            return pieces\r\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\r\n\r\n        # distance: number of commits since tag\r\n        pieces[\"distance\"] = int(mo.group(2))\r\n\r\n        # commit: short hex revision ID\r\n        pieces[\"short\"] = mo.group(3)\r\n\r\n    else:\r\n        # HEX: no tags\r\n        pieces[\"closest-tag\"] = None\r\n        count_out = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\r\n                                cwd=root)\r\n        pieces[\"distance\"] = int(count_out)  # total number of commits\r\n\r\n    return pieces\r\n\r\n\r\ndef plus_or_dot(pieces):\r\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\r\n        return \".\"\r\n    return \"+\"\r\n\r\n\r\ndef render_pep440(pieces):\r\n    # now build up version string, with post-release \"local version\r\n    # identifier\". Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\r\n    # get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\r\n\r\n    # exceptions:\r\n    # 1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\r\n\r\n    if pieces[\"closest-tag\"]:\r\n        rendered = pieces[\"closest-tag\"]\r\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\r\n            rendered += plus_or_dot(pieces)\r\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\r\n            if pieces[\"dirty\"]:\r\n                rendered += \".dirty\"\r\n    else:\r\n        # exception #1\r\n        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\r\n                                          pieces[\"short\"])\r\n        if pieces[\"dirty\"]:\r\n            rendered += \".dirty\"\r\n    return rendered\r\n\r\n\r\ndef render_pep440_pre(pieces):\r\n    # TAG[.post.devDISTANCE] .", "start_char_idx": 6677, "end_char_idx": 10688, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "670affde-bda1-4aa7-8d08-c792e77bfe8c": {"__data__": {"id_": "670affde-bda1-4aa7-8d08-c792e77bfe8c", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e8f5cfb0641c9020485c8ee49d5f4e235b20f755e8131745c84bb9591e1e7ec7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b203f11e-0356-405e-b791-9c6911b38bf6", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "f0455d38d44f091e648eb61ff99016d6bc37684e909827ffab3991350f2a3495", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a20f28c8-74f3-43d8-aafe-5588bf9d31f7", "node_type": "1", "metadata": {}, "hash": "236a96215cb90f7dddf7cd23d9e91ba145e3290c083258edff27d555decc80fe", "class_name": "RelatedNodeInfo"}}, "text": "git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\r\n\r\n    if pieces[\"closest-tag\"]:\r\n        rendered = pieces[\"closest-tag\"]\r\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\r\n            rendered += plus_or_dot(pieces)\r\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\r\n            if pieces[\"dirty\"]:\r\n                rendered += \".dirty\"\r\n    else:\r\n        # exception #1\r\n        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\r\n                                          pieces[\"short\"])\r\n        if pieces[\"dirty\"]:\r\n            rendered += \".dirty\"\r\n    return rendered\r\n\r\n\r\ndef render_pep440_pre(pieces):\r\n    # TAG[.post.devDISTANCE] . No -dirty\r\n\r\n    # exceptions:\r\n    # 1: no tags. 0.post.devDISTANCE\r\n\r\n    if pieces[\"closest-tag\"]:\r\n        rendered = pieces[\"closest-tag\"]\r\n        if pieces[\"distance\"]:\r\n            rendered += \".post.dev%d\" % pieces[\"distance\"]\r\n    else:\r\n        # exception #1\r\n        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\r\n    return rendered\r\n\r\n\r\ndef render_pep440_post(pieces):\r\n    # TAG[.postDISTANCE[.dev0]+gHEX] . The \".dev0\" means dirty. Note that\r\n    # .dev0 sorts backwards (a dirty tree will appear \"older\" than the\r\n    # corresponding clean one), but you shouldn't be releasing software with\r\n    # -dirty anyways.\r\n\r\n    # exceptions:\r\n    # 1: no tags. 0.postDISTANCE[.dev0]\r\n\r\n    if pieces[\"closest-tag\"]:\r\n        rendered = pieces[\"closest-tag\"]\r\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\r\n            rendered += \".post%d\" % pieces[\"distance\"]\r\n            if pieces[\"dirty\"]:\r\n                rendered += \".dev0\"\r\n            rendered += plus_or_dot(pieces)\r\n            rendered += \"g%s\" % pieces[\"short\"]\r\n    else:\r\n        # exception #1\r\n        rendered = \"0.post%d\" % pieces[\"distance\"]\r\n        if pieces[\"dirty\"]:\r\n            rendered += \".dev0\"\r\n        rendered += \"+g%s\" % pieces[\"short\"]\r\n    return rendered\r\n\r\n\r\ndef render_pep440_old(pieces):\r\n    # TAG[.postDISTANCE[.dev0]] . The \".dev0\" means dirty.\r\n\r\n    # exceptions:\r\n    # 1: no tags. 0.postDISTANCE[.dev0]\r\n\r\n    if pieces[\"closest-tag\"]:\r\n        rendered = pieces[\"closest-tag\"]\r\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\r\n            rendered += \".post%d\" % pieces[\"distance\"]\r\n            if pieces[\"dirty\"]:\r\n                rendered += \".dev0\"\r\n    else:\r\n        # exception #1\r\n        rendered = \"0.post%d\" % pieces[\"distance\"]\r\n        if pieces[\"dirty\"]:\r\n            rendered += \".dev0\"\r\n    return rendered\r\n\r\n\r\ndef render_git_describe(pieces):\r\n    # TAG[-DISTANCE-gHEX][-dirty], like 'git describe --tags --dirty\r\n    # --always'\r\n\r\n    # exceptions:\r\n    # 1: no tags. HEX[-dirty]  (note: no 'g' prefix)\r\n\r\n    if pieces[\"closest-tag\"]:\r\n        rendered = pieces[\"closest-tag\"]\r\n        if pieces[\"distance\"]:\r\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\r\n    else:\r\n        # exception #1\r\n        rendered = pieces[\"short\"]\r\n    if pieces[\"dirty\"]:\r\n        rendered += \"-dirty\"\r\n    return rendered\r\n\r\n\r\ndef render_git_describe_long(pieces):\r\n    # TAG-DISTANCE-gHEX[-dirty], like 'git describe --tags --dirty\r\n    # --always -long'. The distance/hash is unconditional.\r\n\r\n    # exceptions:\r\n    # 1: no tags.", "start_char_idx": 10003, "end_char_idx": 13265, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a20f28c8-74f3-43d8-aafe-5588bf9d31f7": {"__data__": {"id_": "a20f28c8-74f3-43d8-aafe-5588bf9d31f7", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b55fad2e-5468-4402-83ba-2a4dcccbb970", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e8f5cfb0641c9020485c8ee49d5f4e235b20f755e8131745c84bb9591e1e7ec7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "670affde-bda1-4aa7-8d08-c792e77bfe8c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "3c923544fa7a7c49757ff7e5ddb4e03375564ce67f2705309eb4451fdbfc255b", "class_name": "RelatedNodeInfo"}}, "text": "HEX[-dirty]  (note: no 'g' prefix)\r\n\r\n    if pieces[\"closest-tag\"]:\r\n        rendered = pieces[\"closest-tag\"]\r\n        if pieces[\"distance\"]:\r\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\r\n    else:\r\n        # exception #1\r\n        rendered = pieces[\"short\"]\r\n    if pieces[\"dirty\"]:\r\n        rendered += \"-dirty\"\r\n    return rendered\r\n\r\n\r\ndef render_git_describe_long(pieces):\r\n    # TAG-DISTANCE-gHEX[-dirty], like 'git describe --tags --dirty\r\n    # --always -long'. The distance/hash is unconditional.\r\n\r\n    # exceptions:\r\n    # 1: no tags. HEX[-dirty]  (note: no 'g' prefix)\r\n\r\n    if pieces[\"closest-tag\"]:\r\n        rendered = pieces[\"closest-tag\"]\r\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\r\n    else:\r\n        # exception #1\r\n        rendered = pieces[\"short\"]\r\n    if pieces[\"dirty\"]:\r\n        rendered += \"-dirty\"\r\n    return rendered\r\n\r\n\r\ndef render(pieces, style):\r\n    if pieces[\"error\"]:\r\n        return {\"version\": \"unknown\",\r\n                \"full-revisionid\": pieces.get(\"long\"),\r\n                \"dirty\": None,\r\n                \"error\": pieces[\"error\"]}\r\n\r\n    if not style or style == \"default\":\r\n        style = \"pep440\"  # the default\r\n\r\n    if style == \"pep440\":\r\n        rendered = render_pep440(pieces)\r\n    elif style == \"pep440-pre\":\r\n        rendered = render_pep440_pre(pieces)\r\n    elif style == \"pep440-post\":\r\n        rendered = render_pep440_post(pieces)\r\n    elif style == \"pep440-old\":\r\n        rendered = render_pep440_old(pieces)\r\n    elif style == \"git-describe\":\r\n        rendered = render_git_describe(pieces)\r\n    elif style == \"git-describe-long\":\r\n        rendered = render_git_describe_long(pieces)\r\n    else:\r\n        raise ValueError(\"unknown style '%s'\" % style)\r\n\r\n    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\r\n            \"dirty\": pieces[\"dirty\"], \"error\": None}\r\n\r\n\r\ndef get_versions():\r\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\r\n    # __file__, we can work backwards from there to the root. Some\r\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\r\n    # case we can only use expanded keywords.\r\n\r\n    cfg = get_config()\r\n    verbose = cfg.verbose\r\n\r\n    try:\r\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\r\n                                          verbose)\r\n    except NotThisMethod:\r\n        pass\r\n\r\n    try:\r\n        root = os.path.realpath(__file__)\r\n        # versionfile_source is the relative path from the top of the source\r\n        # tree (where the .git directory might live) to this file. Invert\r\n        # this to find the root from __file__.\r\n        for i in cfg.versionfile_source.split('/'):\r\n            root = os.path.dirname(root)\r\n    except NameError:\r\n        return {\"version\": \"0+unknown\", \"full-revisionid\": None,\r\n                \"dirty\": None,\r\n                \"error\": \"unable to find root of source tree\"}\r\n\r\n    try:\r\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\r\n        return render(pieces, cfg.style)\r\n    except NotThisMethod:\r\n        pass\r\n\r\n    try:\r\n        if cfg.parentdir_prefix:\r\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\r\n    except NotThisMethod:\r\n        pass\r\n\r\n    return {\"version\": \"0+unknown\", \"full-revisionid\": None,\r\n            \"dirty\": None,\r\n            \"error\": \"unable to compute version\"}", "start_char_idx": 12691, "end_char_idx": 16124, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "370b1bb6-4124-420a-a37c-db8eb51d68ec": {"__data__": {"id_": "370b1bb6-4124-420a-a37c-db8eb51d68ec", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\api.py", "file_name": "api.py", "file_type": "text/x-python", "file_size": 1467, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "526a3a14-babc-49ab-b719-060f22c8acde", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\api.py", "file_name": "api.py", "file_type": "text/x-python", "file_size": 1467, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "4909a67671964d786b04a74d81202abe7d205197e550f052f740349cd3fde539", "class_name": "RelatedNodeInfo"}}, "text": "import warnings\r\n\r\nfrom .find import percentile_threshold, grey_dilation\r\nfrom .motion import msd, imsd, emsd, compute_drift, subtract_drift, \\\r\n           proximity, vanhove, relate_frames, velocity_corr, \\\r\n           direction_corr, is_typical, diagonal_size\r\nfrom .static import proximity, pair_correlation_2d, pair_correlation_3d, \\\r\n           cluster\r\nfrom .plots import annotate, annotate3d, plot_traj, ptraj, \\\r\n           plot_displacements, subpx_bias, mass_size, mass_ecc, \\\r\n           scatter, scatter3d, plot_traj3d, ptraj3d, plot_density_profile\r\nfrom .linking import (link, link_df, link_iter, link_df_iter,\r\n                      find_link, find_link_iter, link_partial,\r\n                      reconnect_traj_patch,\r\n                      SubnetOversizeException, UnknownLinkingError)\r\nfrom .filtering import filter_stubs, filter_clusters, filter\r\nfrom .feature import locate, batch, local_maxima, \\\r\n           estimate_mass, estimate_size, minmass_v03_change, minmass_v04_change\r\nfrom .preprocessing import bandpass, invert_image\r\nfrom .framewise_data import FramewiseData, PandasHDFStore, PandasHDFStoreBig, \\\r\n           PandasHDFStoreSingleNode\r\nfrom .locate_functions import locate_brightfield_ring\r\nfrom .refine import refine_com, refine_leastsq\r\nfrom . import predict\r\nfrom . import utils\r\nfrom . import artificial\r\nfrom .utils import handle_logging, ignore_logging, quiet\r\nfrom .try_numba import try_numba_jit, enable_numba, disable_numba", "start_char_idx": 0, "end_char_idx": 1465, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89ebeb32-70cb-4650-a253-7f734cfaa477": {"__data__": {"id_": "89ebeb32-70cb-4650-a253-7f734cfaa477", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6bb6e193ea29f57835cbe2c8f44fe09d5607fd4d280f2b266ba024ce8b69f210", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d28bf661-b545-4d7f-b694-b82e868764ef", "node_type": "1", "metadata": {}, "hash": "7443c9875f52b62867fed92b66ffd40bba556800c45a77e9cb734ed0b098aa5e", "class_name": "RelatedNodeInfo"}}, "text": "import numpy as np\r\nimport pandas as pd\r\nimport warnings\r\nfrom trackpy.find import drop_close\r\nfrom trackpy.utils import validate_tuple\r\nfrom trackpy.preprocessing import bandpass\r\ntry:\r\n    from pims import Frame as _Frame\r\nexcept ImportError:\r\n    _Frame = None\r\n\r\n\r\ndef draw_point(image, pos, value):\r\n    image[tuple(pos)] = value\r\n\r\n\r\ndef feat_gauss(r, ndim):\r\n    \"\"\" Gaussian at r = 0. \"\"\"\r\n    return np.exp(r**2 * ndim/-2)\r\n\r\n\r\ndef feat_ring(r, ndim, thickness):\r\n    \"\"\" Ring feature with a gaussian profile with a certain thickness.\"\"\"\r\n    return np.exp(((r-1+thickness)/thickness)**2 * ndim/-2)\r\n\r\n\r\ndef feat_hat(r, ndim, disc_size):\r\n    \"\"\" Solid disc of size disc_size, with Gaussian smoothed borders. \"\"\"\r\n    result = np.ones_like(r)\r\n    mask = r > disc_size\r\n    result[mask] = np.exp(((r[mask] - disc_size)/(1 - disc_size))**2 *\r\n                          ndim/-2)\r\n    return result\r\n\r\n\r\ndef feat_step(r, ndim):\r\n    \"\"\" Solid disc. \"\"\"\r\n    return (r <= 1).astype(float)\r\n\r\n\r\nfeat_disc = feat_hat\r\nfeat_dict = dict(gauss=feat_gauss, disc=feat_disc, ring=feat_ring,\r\n                 hat=feat_hat, step=feat_step)\r\n\r\ndef draw_feature(image, position, size, max_value=None, feat_func='gauss',\r\n                 ecc=None, mask_diameter=None, **kwargs):\r\n    \"\"\" Draws a radial symmetric feature and adds it to the image at given\r\n    position. The given function will be evaluated at each pixel coordinate,\r\n    no averaging or convolution is done.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n        image to draw features on\r\n    position : iterable\r\n        coordinates of feature position\r\n    size : number\r\n        the size of the feature (meaning depends on feature, for feat_gauss,\r\n        it is the radius of gyration)\r\n    max_value : number\r\n        maximum feature value. should be much less than the max value of the\r\n        image dtype, to avoid pixel wrapping at overlapping features\r\n    feat_func : {'gauss', 'disc', 'ring'} or callable\r\n        Default: 'gauss'\r\n        When callable is given, it should take an ndarray of radius values\r\n        and it should return intensity values <= 1\r\n    ecc : positive number, optional\r\n        eccentricity of feature, defined only in 2D. Identical to setting\r\n        diameter to (diameter / (1 - ecc), diameter * (1 - ecc))\r\n    mask_diameter :\r\n        defines the box that will be drawn on. Default 4 * size.\r\n    kwargs : keyword arguments are passed to feat_func\r\n\r\n    See also\r\n    --------\r\n    draw_spots\r\n    \"\"\"\r\n    if len(position) != image.ndim:\r\n        raise ValueError(\"Number of position coordinates should match image\"\r\n                         \" dimensionality.\")\r\n    if not hasattr(feat_func, '__call__'):\r\n        feat_func = feat_dict[feat_func]\r\n    size = validate_tuple(size, image.ndim)\r\n    if ecc is not None:\r\n        if len(size) != 2:\r\n            raise ValueError(\"Eccentricity is only defined in 2 dimensions\")\r\n        if size[0] != size[1]:\r\n            raise ValueError(\"Diameter is already anisotropic; eccentricity is\"\r\n                             \" not defined.\")\r\n        size = (size[0] / (1 - ecc), size[1] * (1 - ecc))\r\n    if mask_diameter is None:\r\n        mask_diameter = tuple([s * 4 for s in size])\r\n    else:\r\n        mask_diameter = validate_tuple(mask_diameter, image.ndim)\r\n    if max_value is None:\r\n        max_value = np.iinfo(image.dtype).max - 3\r\n    rect = []\r\n    vectors = []\r\n    for (c, s, m, lim) in zip(position, size, mask_diameter, image.shape):\r\n        if (c >= lim) or (c < 0):\r\n            raise ValueError(\"Position outside of image.\")", "start_char_idx": 0, "end_char_idx": 3604, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d28bf661-b545-4d7f-b694-b82e868764ef": {"__data__": {"id_": "d28bf661-b545-4d7f-b694-b82e868764ef", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6bb6e193ea29f57835cbe2c8f44fe09d5607fd4d280f2b266ba024ce8b69f210", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89ebeb32-70cb-4650-a253-7f734cfaa477", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "bcf57bb015cb843aa738921e8841f78786a9d0cbca32db3fa98d971c808b9d08", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d05750ce-0fc9-461c-8960-3b4226dc7cb4", "node_type": "1", "metadata": {}, "hash": "fbcefd133c2b196231293afd36260f617fa003a7de6317563c6c8c2179eeedee", "class_name": "RelatedNodeInfo"}}, "text": "size = (size[0] / (1 - ecc), size[1] * (1 - ecc))\r\n    if mask_diameter is None:\r\n        mask_diameter = tuple([s * 4 for s in size])\r\n    else:\r\n        mask_diameter = validate_tuple(mask_diameter, image.ndim)\r\n    if max_value is None:\r\n        max_value = np.iinfo(image.dtype).max - 3\r\n    rect = []\r\n    vectors = []\r\n    for (c, s, m, lim) in zip(position, size, mask_diameter, image.shape):\r\n        if (c >= lim) or (c < 0):\r\n            raise ValueError(\"Position outside of image.\")\r\n        lower_bound = max(int(np.floor(c - m / 2)), 0)\r\n        upper_bound = min(int(np.ceil(c + m / 2 + 1)), lim)\r\n        rect.append(slice(lower_bound, upper_bound))\r\n        vectors.append(np.arange(lower_bound - c, upper_bound - c) / s)\r\n    coords = np.meshgrid(*vectors, indexing='ij')\r\n    r = np.sqrt(np.sum(np.array(coords)**2, axis=0))\r\n    spot = max_value * feat_func(r, ndim=image.ndim, **kwargs)\r\n    image[tuple(rect)] += spot.astype(image.dtype)\r\n\r\n\r\ndef gen_random_locations(shape, count, margin=0):\r\n    \"\"\" Generates `count` number of positions within `shape`. If a `margin` is\r\n    given, positions will be inside this margin. Margin may be tuple-valued.\r\n    \"\"\"\r\n    margin = validate_tuple(margin, len(shape))\r\n    np.random.seed(0)\r\n    pos = [np.random.randint(round(m), round(s - m), count)\r\n           for (s, m) in zip(shape, margin)]\r\n    return np.array(pos).T\r\n\r\n\r\ndef gen_connected_locations(shape, count, separation, margin=0):\r\n    \"\"\" Generates `count` number of positions within `shape` that are touching.\r\n    If a `margin` is given, positions will be inside this margin. Margin may be\r\n    tuple-valued.  \"\"\"\r\n    margin = validate_tuple(margin, len(shape))\r\n    center_pos = margin + np.round(np.subtract(shape, margin)/2.0)\r\n    indices = np.arange(0, count, 1) - np.round(count/2.0)\r\n    pos = np.array([np.add(center_pos, np.multiply(i, separation)) for i in indices])\r\n\r\n    return pos\r\n\r\ndef gen_nonoverlapping_locations(shape, count, separation, margin=0):\r\n    \"\"\" Generates `count` number of positions within `shape`, that have minimum\r\n    distance `separation` from each other. The number of positions returned may\r\n    be lower than `count`, because positions too close to each other will be\r\n    deleted. If a `margin` is given, positions will be inside this margin.\r\n    Margin may be tuple-valued.\r\n    \"\"\"\r\n    positions = gen_random_locations(shape, count, margin)\r\n    return drop_close(positions, separation)\r\n\r\n\r\ndef draw_spots(shape, positions, size, noise_level=0, bitdepth=8, **kwargs):\r\n    \"\"\" Generates an image with features at given positions. A feature with\r\n    position x will be centered around pixel x. In other words, the origin of\r\n    the output image is located at the center of pixel (0, 0).", "start_char_idx": 3110, "end_char_idx": 5875, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d05750ce-0fc9-461c-8960-3b4226dc7cb4": {"__data__": {"id_": "d05750ce-0fc9-461c-8960-3b4226dc7cb4", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6bb6e193ea29f57835cbe2c8f44fe09d5607fd4d280f2b266ba024ce8b69f210", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d28bf661-b545-4d7f-b694-b82e868764ef", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "73bdc0bd9477bcbc9ed0ed99e88eb725e62f9735b20b71df61f9ad634b5f3fb3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0fbed2a3-552f-4e86-b264-b5bb0b8081d9", "node_type": "1", "metadata": {}, "hash": "082a73b65896f9bb00633e81bade223c32866aa25918dcd44609ae087267129b", "class_name": "RelatedNodeInfo"}}, "text": "The number of positions returned may\r\n    be lower than `count`, because positions too close to each other will be\r\n    deleted. If a `margin` is given, positions will be inside this margin.\r\n    Margin may be tuple-valued.\r\n    \"\"\"\r\n    positions = gen_random_locations(shape, count, margin)\r\n    return drop_close(positions, separation)\r\n\r\n\r\ndef draw_spots(shape, positions, size, noise_level=0, bitdepth=8, **kwargs):\r\n    \"\"\" Generates an image with features at given positions. A feature with\r\n    position x will be centered around pixel x. In other words, the origin of\r\n    the output image is located at the center of pixel (0, 0).\r\n\r\n    Parameters\r\n    ----------\r\n    shape : tuple of int\r\n        the shape of the produced image\r\n    positions : iterable of tuples\r\n        an iterable of positions\r\n    size : number\r\n        the size of the feature (meaning depends on feature, for feat_gauss,\r\n        it is the radius of gyration)\r\n    noise_level : int, default: 0\r\n        white noise will be generated up to this level\r\n    bitdepth : int, default: 8\r\n        the desired bitdepth of the image (<=32 bits)\r\n    kwargs : keyword arguments are passed to draw_feature\r\n\r\n    See also\r\n    --------\r\n    draw_feature\r\n    \"\"\"\r\n    if bitdepth <= 8:\r\n        dtype = np.uint8\r\n        internaldtype = np.uint16\r\n    elif bitdepth <= 16:\r\n        dtype = np.uint16\r\n        internaldtype = np.uint32\r\n    elif bitdepth <= 32:\r\n        dtype = np.uint32\r\n        internaldtype = np.uint64\r\n    else:\r\n        raise ValueError('Bitdepth should be <= 32')\r\n    np.random.seed(0)\r\n    image = np.zeros([int(s) for s in shape], dtype=internaldtype)\r\n    if noise_level > 0:\r\n        image += np.random.randint(0, noise_level + 1,\r\n                                   shape).astype(internaldtype)\r\n    for pos in positions:\r\n        draw_feature(image, pos, size, max_value=2**bitdepth - 1, **kwargs)\r\n    return image.clip(0, 2**bitdepth - 1).astype(dtype)\r\n\r\n\r\ndef draw_array(N, size, separation=None, ndim=2, **kwargs):\r\n    \"\"\" Generates an image with an array of features. Each feature has a random\r\n    offset of +- 0.5 pixel.", "start_char_idx": 5235, "end_char_idx": 7374, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0fbed2a3-552f-4e86-b264-b5bb0b8081d9": {"__data__": {"id_": "0fbed2a3-552f-4e86-b264-b5bb0b8081d9", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6bb6e193ea29f57835cbe2c8f44fe09d5607fd4d280f2b266ba024ce8b69f210", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d05750ce-0fc9-461c-8960-3b4226dc7cb4", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "9922f55cf387a8ff91608f4d8c802d7d02fd7b7b38e8d4f0f43b35af63f6f763", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c237c144-f112-495f-b0a6-b4b3fd320948", "node_type": "1", "metadata": {}, "hash": "a8286028c61f4de4f4066b89a40c959edbaa8b9b1d1a8cdf01099cc5d5527e2e", "class_name": "RelatedNodeInfo"}}, "text": "Each feature has a random\r\n    offset of +- 0.5 pixel.\r\n\r\n    Parameters\r\n    ----------\r\n    N : int\r\n        the number of features\r\n    size : number\r\n        the size of the feature (meaning depends on feature, for feat_gauss,\r\n        it is the radius of gyration)\r\n    separation : number or tuple\r\n        the desired separation between features\r\n    kwargs : keyword arguments are passed to draw_spots\r\n\r\n    See also\r\n    --------\r\n    draw_spots\r\n    draw_feature\r\n    \"\"\"\r\n    size = validate_tuple(size, ndim)\r\n    if separation is None:\r\n        separation = tuple([sz * 8 for sz in size])\r\n    margin = separation\r\n    Nsqrt = int(N**(1/ndim) + 0.9999)\r\n    pos = np.meshgrid(*[np.arange(0, s * Nsqrt, s) for s in separation],\r\n                      indexing='ij')\r\n    pos = np.array([p.ravel() for p in pos], dtype=float).T[:N] + margin\r\n    pos += (np.random.random(pos.shape) - 0.5)  #randomize subpixel location\r\n    shape = tuple(np.max(pos, axis=0).astype(int) + margin)\r\n    return pos, draw_spots(shape, pos, size, **kwargs)\r\n\r\n\r\ndef rot_2d(angle):\r\n    c, s = np.cos(angle), np.sin(angle)\r\n    return np.array([[c, -s], [s, c]], float)\r\n\r\n\r\ndef rot_3d(angles):\r\n    # Tait-Bryan angles in ZYX convention\r\n    if not hasattr(angles, '__iter__'):\r\n        angles = (angles, 0, 0)\r\n    if len(angles) == 2:\r\n        angles = (angles[0], angles[1], 0)\r\n    s1, s2, s3 = [np.sin(x) for x in angles]\r\n    c1, c2, c3 = [np.cos(x) for x in angles]\r\n    return np.array([[c1*c2, c1*s2*s3-c3*s1, s1*s3+c1*c3*s2],\r\n                     [c2*s1, c1*c3+s1*s2*s3, c3*s1*s2 - c1*s3],\r\n                     [-s2, c2*s3, c2*c3]], float)\r\n\r\n\r\nclusters_2d = {1: np.array([[0, 0]], float),\r\n               2: np.array([[0, -1], [0, 1]], float),\r\n               3: np.array([[0, 1],\r\n                            [-0.5 * np.sqrt(3), -0.5],\r\n                            [0.5 * np.sqrt(3), -0.5]], float)*2/3*np.sqrt(3),\r\n               4: np.array([[-1, -1], [1, -1], [-1, 1], [1, 1]], float)}\r\nclusters_3d = {1: np.array([[0, 0, 0]], float),\r\n               2: np.array([[0, 0, -1], [0, 0, 1]], float),\r\n               3: np.array([[0, 0, 2/np.sqrt(3)],\r\n                            [-1, 0, -1/np.sqrt(3)],\r\n                            [1, 0,  -1/np.sqrt(3)]], float),\r\n               4: np.array([[0, 0, (1/2)*np.sqrt(6)],\r\n                            [0, -(2/3)*np.sqrt(3), -(1/6)*np.sqrt(6)],\r\n                            [1, (1/3)*np.sqrt(3), -(1/6)*np.sqrt(6)],\r\n                            [-1, (1/3)*np.sqrt(3), -(1/6)*np.sqrt(6)]], float)}\r\n\r\n\r\ndef draw_cluster(image, position, size, cluster_size, hard_radius=1., angle=0,\r\n                 **kwargs):\r\n    \"\"\"Draws a cluster of size `n` at `pos` with angle `angle`. The distance\r\n    between particles is determined by `hard_radius`.\"\"\"", "start_char_idx": 7320, "end_char_idx": 10117, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c237c144-f112-495f-b0a6-b4b3fd320948": {"__data__": {"id_": "c237c144-f112-495f-b0a6-b4b3fd320948", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6bb6e193ea29f57835cbe2c8f44fe09d5607fd4d280f2b266ba024ce8b69f210", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0fbed2a3-552f-4e86-b264-b5bb0b8081d9", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d190152b6bda104f82d8256fecd3d2ae5d7da38337127f208aacf5d474591c04", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7686b79b-7ec6-44cf-8c8f-ea127aeecc50", "node_type": "1", "metadata": {}, "hash": "9e506fd49c0542e1b95f38abdd5d5580f62623d3425cc250fc0bce8873885f03", "class_name": "RelatedNodeInfo"}}, "text": "The distance\r\n    between particles is determined by `hard_radius`.\"\"\"\r\n    if image.ndim == 2:\r\n        rot = rot_2d(angle)\r\n        coord = clusters_2d[cluster_size]\r\n    elif image.ndim == 3:\r\n        rot = rot_3d(angle)\r\n        coord = clusters_3d[cluster_size]\r\n    coord = np.dot(coord, rot.T)  # rotate\r\n    coord *= hard_radius * np.array(size)[np.newaxis, :]  # scale\r\n    coord += np.array(position)[np.newaxis, :]  # translate\r\n    for pos in coord:\r\n        draw_feature(image, pos, size, **kwargs)\r\n    return coord\r\n\r\nclass SimulatedImage:\r\n    \"\"\" This class makes it easy to generate artificial pictures.\r\n\r\n    Parameters\r\n    ----------\r\n    shape : tuple of int\r\n    dtype : numpy.dtype, default np.uint8\r\n    saturation : maximum value in image\r\n    hard_radius : default radius of particles, used for determining the\r\n                  distance between particles in clusters\r\n    feat_dict : dictionary of arguments passed to tp.artificial.draw_feature\r\n\r\n    Attributes\r\n    ----------\r\n    image : ndarray containing pixel values\r\n    center : the center [y, x] to use for radial coordinates\r\n\r\n    Examples\r\n    --------\r\n    image = SimulatedImage(shape=(50, 50), dtype=np.uint8, hard_radius=7,\r\n                           feat_dict={'diameter': 20, 'max_value': 100,\r\n                                      'feat_func': SimulatedImage.feat_hat,\r\n                                      'disc_size': 0.2})\r\n    image.draw_feature((10, 10))\r\n    image.draw_dimer((32, 35), angle=75)\r\n    image.add_noise(5)\r\n    image()\r\n    \"\"\"\r\n    def __init__(self, shape, size, dtype=np.uint8, saturation=None,\r\n                 hard_radius=None, signal=None, noise=0,\r\n                 feat_func=feat_gauss, **feat_kwargs):\r\n        self.ndim = len(shape)\r\n        self.shape = shape\r\n        self.dtype = dtype\r\n        self.image = np.zeros(shape, dtype=dtype)\r\n        if _Frame is not None:\r\n            self.image = _Frame(self.image)\r\n        self.size = validate_tuple(size, self.ndim)\r\n        self.isotropic = np.all([self.size[1:] == self.size[:-1]])\r\n        self.feat_func = feat_func\r\n        self.feat_kwargs = feat_kwargs\r\n        self.noise = noise\r\n        if saturation is None and np.issubdtype(dtype, np.integer):\r\n            self.saturation = np.iinfo(dtype).max\r\n        elif saturation is None and np.issubdtype(dtype, np.floating):\r\n            self.saturation = 1\r\n        else:\r\n            self.saturation = saturation\r\n        if signal is None:\r\n            self.signal = self.saturation\r\n        else:\r\n            self.signal = signal\r\n        self.center = tuple([s // 2 for s in shape])\r\n        self.hard_radius = hard_radius\r\n        self._coords = []\r\n        self.pos_columns = ['z', 'y', 'x'][-self.ndim:]\r\n        if self.isotropic:\r\n            self.size_columns = ['size']\r\n        else:\r\n            self.size_columns = ['size_z', 'size_y', 'size_x'][-self.ndim:]\r\n\r\n    def __call__(self):\r\n        # so that you can checkout the image with image() instead of image.image\r\n        return self.noisy_image(self.noise)\r\n\r\n    def clear(self):\r\n        \"\"\"Clears the current image\"\"\"\r\n        self._coords = []\r\n        self.image = np.zeros_like(self.image)\r\n\r\n    def draw_feature(self, pos):\r\n        \"\"\"Draws a feature at `pos`.\"\"\"\r\n        pos = [float(p) for p in pos]\r\n        self._coords.append(pos)\r\n        draw_feature(self.image, pos, self.size, self.signal,\r\n                     self.feat_func, **self.feat_kwargs)\r\n\r\n    def draw_features(self, N, separation=0, margin=None):\r\n        \"\"\"Draws N features at random locations, using minimum separation\r\n        and a margin. If separation > 0, less than N features may be drawn.\"\"\"\r\n        if margin is None:\r\n            margin = self.hard_radius\r\n        if margin is None:\r\n            margin = 0\r\n        pos = gen_random_locations(self.shape, N, margin)\r\n        if separation > 0:\r\n            pos = drop_close(pos, separation)\r\n        for p in pos:\r\n            self.draw_feature(p)\r\n        return pos\r\n\r\n    def draw_feature_radial(self, r, angle, center=None):\r\n        \"\"\"Draws a feature at radial coordinates `r`, `angle`. The center\r\n        of the radial coordinates system is determined by `center`. If this\r\n        is not given, self.center is used.", "start_char_idx": 10047, "end_char_idx": 14332, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7686b79b-7ec6-44cf-8c8f-ea127aeecc50": {"__data__": {"id_": "7686b79b-7ec6-44cf-8c8f-ea127aeecc50", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6bb6e193ea29f57835cbe2c8f44fe09d5607fd4d280f2b266ba024ce8b69f210", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c237c144-f112-495f-b0a6-b4b3fd320948", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "219bf826631ad0e887bd9e70dcfcb635f0abe6f0f25ad466adcb9bc623237ff3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c86b5e4e-81b6-4f44-823d-bdb26cc82c6c", "node_type": "1", "metadata": {}, "hash": "920b0318883d96ba900a6f42f05a3e5f9557e86daafd8346be26c7bb0926c9c3", "class_name": "RelatedNodeInfo"}}, "text": "If separation > 0, less than N features may be drawn.\"\"\"\r\n        if margin is None:\r\n            margin = self.hard_radius\r\n        if margin is None:\r\n            margin = 0\r\n        pos = gen_random_locations(self.shape, N, margin)\r\n        if separation > 0:\r\n            pos = drop_close(pos, separation)\r\n        for p in pos:\r\n            self.draw_feature(p)\r\n        return pos\r\n\r\n    def draw_feature_radial(self, r, angle, center=None):\r\n        \"\"\"Draws a feature at radial coordinates `r`, `angle`. The center\r\n        of the radial coordinates system is determined by `center`. If this\r\n        is not given, self.center is used.\r\n\r\n        For 3D, angle has to be a tuple of length 2: (phi, theta), in which\r\n        theta is the angle with the positive z axis.\"\"\"\r\n        if center is None:\r\n            center = self.center\r\n        if self.ndim == 2:\r\n            pos = (center[0] + self.size[0]*r*np.sin(angle*(np.pi/180)),\r\n                   center[1] + self.size[1]*r*np.cos(angle*(np.pi/180)))\r\n        elif self.ndim == 3:\r\n            if not hasattr(angle, '__iter__'):\r\n                angle = (angle, 0)\r\n            r_sin_theta = r*np.sin(angle[1]*(np.pi/180))\r\n            pos = (center[0] + self.size[0]*r*np.cos(angle[1]*(np.pi/180)),\r\n                   center[1] + self.size[1]*r_sin_theta*np.sin(angle[0]*(np.pi/180)),\r\n                   center[2] + self.size[2]*r_sin_theta*np.cos(angle[0]*(np.pi/180)))\r\n        else:\r\n            raise ValueError(\"Don't know how to draw in {} dimensions\".format(self.ndim))\r\n        self.draw_feature(pos)\r\n        return pos\r\n\r\n    def draw_dimer(self, pos, angle, hard_radius=None):\r\n        \"\"\"Draws a dimer at `pos` with angle `angle`. The distance\r\n        between particles is determined by 2*`hard_radius`. If this is not\r\n        given, self.separation is used.\"\"\"\r\n        return self.draw_cluster(2, pos, angle, hard_radius)\r\n    draw_dumbell = draw_dimer\r\n\r\n    def draw_trimer(self, pos, angle, hard_radius=None):\r\n        \"\"\"Draws a trimer at `pos` with angle `angle`. The distance\r\n        between particles is determined by `separation`. If this is not\r\n        given, self.separation is used.\"\"\"\r\n        return self.draw_cluster(3, pos, angle, hard_radius)\r\n    draw_triangle = draw_trimer\r\n\r\n    def draw_cluster(self, cluster_size, center=None, angle=0, hard_radius=None):\r\n        \"\"\"Draws a cluster of size `n` at `pos` with angle `angle`. The distance\r\n        between particles is determined by `separation`. If this is not\r\n        given, self.separation is used.\"\"\"\r\n        if hard_radius is None:\r\n            hard_radius = self.hard_radius\r\n        if center is None:\r\n            center = self.center\r\n        if self.ndim == 2:\r\n            rot = rot_2d(angle)\r\n            coord = clusters_2d[cluster_size]\r\n        elif self.ndim == 3:\r\n            rot = rot_3d(angle)\r\n            coord = clusters_3d[cluster_size]\r\n        coord = np.dot(coord, rot.T)  # rotate\r\n        coord *= hard_radius * np.array(self.size)[np.newaxis, :]  # scale\r\n        coord += np.array(center)[np.newaxis, :]  # translate\r\n        for pos in coord:\r\n            self.draw_feature(pos)\r\n        return coord\r\n\r\n    def draw_clusters(self, N, cluster_size, hard_radius=None, separation=0,\r\n                      margin=None):\r\n        \"\"\"Draws N clusters at random locations, using minimum separation\r\n        and a margin. If separation > 0, less than N features may be drawn.\"\"\"", "start_char_idx": 13689, "end_char_idx": 17153, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c86b5e4e-81b6-4f44-823d-bdb26cc82c6c": {"__data__": {"id_": "c86b5e4e-81b6-4f44-823d-bdb26cc82c6c", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6bb6e193ea29f57835cbe2c8f44fe09d5607fd4d280f2b266ba024ce8b69f210", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7686b79b-7ec6-44cf-8c8f-ea127aeecc50", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "1b68c9412cf11caa55558bf4e22b4e15ad13ee718aaf620a7819f8edf0534b3d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b0d26fbf-24ad-4369-828f-0a35cb2ae210", "node_type": "1", "metadata": {}, "hash": "6da37cb6afee13623dcf3de3f5e075232aad841421b8d2ebba2dbdbeaec0fb43", "class_name": "RelatedNodeInfo"}}, "text": "If separation > 0, less than N features may be drawn.\"\"\"\r\n        if hard_radius is None:\r\n            hard_radius = self.hard_radius\r\n        if margin is None:\r\n            margin = self.hard_radius\r\n        if margin is None:\r\n            margin = 0\r\n        pos = gen_random_locations(self.shape, N, margin)\r\n        if separation > 0:\r\n            pos = drop_close(pos, separation)\r\n\r\n        if self.ndim == 2:\r\n            angles = np.random.uniform(0, 2*np.pi, N)\r\n        elif self.ndim == 3:\r\n            angles = np.random.uniform(0, 2*np.pi, (N, 3))\r\n\r\n        for p, a in zip(pos, angles):\r\n            self.draw_cluster(cluster_size, p, a, hard_radius)\r\n        return pos\r\n\r\n    def noisy_image(self, noise_level):\r\n        \"\"\"Adds noise to the current image, uniformly distributed\r\n        between 0 and `noise_level`, not including noise_level.\"\"\"\r\n        if noise_level <= 0:\r\n            return self.image\r\n        if np.issubdtype(self.dtype, np.integer):\r\n            noise = np.random.poisson(noise_level, self.shape)\r\n        else:\r\n            noise = np.clip(np.random.normal(noise_level, noise_level/2, self.shape), 0, self.saturation)\r\n        noisy_image = np.clip(self.image + noise, 0, self.saturation)\r\n        result = np.array(noisy_image, dtype=self.dtype)\r\n        if _Frame is not None:\r\n            result = _Frame(result)\r\n        return result\r\n\r\n    def denoised(self, noise_level, noise_size, smoothing_size=None,\r\n                 threshold=None):\r\n        image = self.noisy_image(noise_level)\r\n        return bandpass(image, noise_size, smoothing_size, threshold)\r\n\r\n    @property\r\n    def coords(self):\r\n        if len(self._coords) == 0:\r\n            return np.zeros((0, self.ndim), dtype=float)\r\n        return np.array(self._coords)\r\n\r\n    def f(self, noise=0):\r\n        result = self.coords + np.random.random(self.coords.shape) * noise\r\n        result = pd.DataFrame(result, columns=self.pos_columns)\r\n        result['signal'] = float(self.signal)\r\n        if self.isotropic:\r\n            result[self.size_columns[0]] = float(self.size[0])\r\n        else:\r\n            for col, s in zip(self.size_columns, self.size):\r\n                result[col] = float(s)\r\n        return result\r\n\r\ndef feat_brightfield(r, ndim, radius, dark_value, bright_value, dip):\r\n    \"\"\" Brightfield particle with intensity dip in center at r = 0. \"\"\"\r\n    image = np.zeros_like(r)\r\n\r\n    # by definition\r\n    r_rel = 1.0\r\n    r_factor = radius / r_rel\r\n    thickness = r_rel*0.1\r\n\r\n    if thickness*r_factor < 2.0:\r\n        thickness = 2.0 / r_factor\r\n\r\n    mask = r < r_rel\r\n    mask_ring = mask & (r > (r_rel-thickness))\r\n\r\n    if dip:\r\n        mask_dip = r < thickness\r\n        image[mask_dip] += 1.5*dark_value\r\n\r\n    gauss_radius = r_rel-1*thickness\r\n    image[mask] += bright_value*np.exp(-(r[mask]/(gauss_radius**2))**2)\r\n\r\n    image[mask_ring] = dark_value\r\n\r\n    return image\r\n\r\ndef draw_features_brightfield(shape, positions, radius, noise_level=0,\r\n                              bitdepth=8, background=0.5, dip=False, **kwargs):\r\n    \"\"\" Generates an image with features at given positions. A feature with\r\n    position x will be centered around pixel x. In other words, the origin of\r\n    the output image is located at the center of pixel (0, 0).", "start_char_idx": 17097, "end_char_idx": 20382, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b0d26fbf-24ad-4369-828f-0a35cb2ae210": {"__data__": {"id_": "b0d26fbf-24ad-4369-828f-0a35cb2ae210", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "142d2b06-2a04-4014-b1ba-e900d1f1a974", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6bb6e193ea29f57835cbe2c8f44fe09d5607fd4d280f2b266ba024ce8b69f210", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c86b5e4e-81b6-4f44-823d-bdb26cc82c6c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d2da91fea7518dd926072080ede0cd311f025232d5a8dcdc265fef2cb3843eb5", "class_name": "RelatedNodeInfo"}}, "text": "A feature with\r\n    position x will be centered around pixel x. In other words, the origin of\r\n    the output image is located at the center of pixel (0, 0).\r\n\r\n    Parameters\r\n    ----------\r\n    shape : tuple of int\r\n        the shape of the produced image\r\n    positions : iterable of tuples\r\n        an iterable of positions\r\n    radius : number\r\n        the radius of the feature\r\n    noise_level : int, default: 0\r\n        white noise will be generated up to this level\r\n    bitdepth : int, default: 8\r\n        the desired bitdepth of the image (<=32 bits)\r\n    background : float, default: 0.5\r\n        the value of the background ranging from 0 (black) to 1 (white)\r\n    kwargs : keyword arguments are passed to draw_feature\r\n\r\n    See also\r\n    --------\r\n    draw_feature_brightfield\r\n    \"\"\"\r\n    if bitdepth <= 8:\r\n        dtype = np.uint8\r\n        internaldtype = np.uint16\r\n    elif bitdepth <= 16:\r\n        dtype = np.uint16\r\n        internaldtype = np.uint32\r\n    elif bitdepth <= 32:\r\n        dtype = np.uint32\r\n        internaldtype = np.uint64\r\n    else:\r\n        raise ValueError('Bitdepth should be <= 32')\r\n    np.random.seed(0)\r\n\r\n    max_brightness = 2**bitdepth - 1\r\n\r\n    if background is None or background < 0 or background > 1:\r\n        background = 0.5\r\n\r\n    image = background*max_brightness*np.ones([int(s) for s in shape], \r\n                                              dtype=internaldtype)\r\n\r\n    if noise_level > 0:\r\n        image += np.random.randint(0, noise_level + 1,\r\n                                   shape).astype(internaldtype)\r\n\r\n    if np.max(image) > max_brightness:\r\n        image = image/np.max(image)*max_brightness\r\n\r\n    kwargs['feat_func'] = feat_brightfield\r\n    kwargs['dark_value'] = -0.3\r\n    kwargs['bright_value'] = 0.8\r\n    kwargs['dip'] = dip\r\n    kwargs['radius'] = radius[0]\r\n\r\n    for pos in positions:\r\n        draw_feature(image, pos, radius, max_value=max_brightness, **kwargs)\r\n    result = image.clip(0, 2**bitdepth - 1).astype(dtype)\r\n\r\n    return result", "start_char_idx": 20225, "end_char_idx": 22250, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "789a2479-3af1-4241-92fe-08a7e2c4bcd2": {"__data__": {"id_": "789a2479-3af1-4241-92fe-08a7e2c4bcd2", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\diag.py", "file_name": "diag.py", "file_type": "text/x-python", "file_size": 1533, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8b4cb2e3-5daf-4f35-9422-b871544a3553", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\diag.py", "file_name": "diag.py", "file_type": "text/x-python", "file_size": 1533, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "c5c2c391188f6657c9770406d59334a607407b54ca80df37efeea073f9020b2a", "class_name": "RelatedNodeInfo"}}, "text": "import sys\r\nimport importlib\r\nfrom collections import OrderedDict\r\n\r\nfrom . import try_numba\r\nfrom . import preprocessing\r\nfrom . import __version__\r\n\r\n\r\ndef performance_report():\r\n    \"\"\"Display summary of which optional speedups are installed/enabled\"\"\"\r\n    print(\"Yes, but could it be faster?\")\r\n    if try_numba.NUMBA_AVAILABLE:\r\n        print(\"FAST: numba is available and enabled \"\r\n              \"(fast subnets and feature-finding).\")\r\n    else:\r\n        print(\"SLOW: numba was not found\")\r\n\r\n\r\ndef dependencies():\r\n    \"\"\"\r\n    Give the version of each of the dependencies -- useful for bug reports.\r\n\r\n    Returns\r\n    -------\r\n    result : dict\r\n        mapping the name of each package to its version string or, if an\r\n        optional dependency is not installed, None\r\n    \"\"\"\r\n    packages = ['numpy', 'scipy', 'matplotlib', 'pandas',\r\n                'sklearn', 'pyyaml', 'tables', 'numba', 'pims']\r\n    result = OrderedDict()\r\n\r\n    # trackpy itself comes first\r\n    result['trackpy'] = __version__\r\n\r\n    for package_name in packages:\r\n        try:\r\n            package = importlib.import_module(package_name)\r\n        except ImportError:\r\n            result[package_name] = None\r\n        else:\r\n            result[package_name] = package.__version__\r\n\r\n    # Build Python version string\r\n    version_info = sys.version_info\r\n    version_string = '.'.join(map(str, [version_info[0], version_info[1],\r\n                                  version_info[2]]))\r\n    result['python'] = version_string\r\n\r\n    return result", "start_char_idx": 0, "end_char_idx": 1531, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "683b30de-b242-44b3-bdcc-1f11bf7cb7a9": {"__data__": {"id_": "683b30de-b242-44b3-bdcc-1f11bf7cb7a9", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "46e93b41-ad95-4467-909a-25bee6310e92", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "841f1263b81e50f7b438d2ddbd9c5f0d973b53a7d9c5493df64fa1d3c3bf4b73", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "472224fc-e18f-459f-a378-42775b012790", "node_type": "1", "metadata": {}, "hash": "331294c91ae358ebb761b217f6a617a33cf6c957a83a5f0bca8df77cea173d54", "class_name": "RelatedNodeInfo"}}, "text": "import warnings\r\nimport logging\r\nfrom functools import partial\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nfrom .preprocessing import (bandpass, convert_to_int, invert_image,\r\n                            scalefactor_to_gamut)\r\nfrom .utils import (record_meta, validate_tuple, is_isotropic,\r\n                    default_pos_columns, default_size_columns,\r\n                    pandas_concat, get_pool)\r\nfrom .find import grey_dilation, where_close\r\nfrom .refine import refine_com, refine_com_arr\r\nfrom .masks import (binary_mask, N_binary_mask, r_squared_mask,\r\n                    x_squared_masks, cosmask, sinmask)\r\nfrom .uncertainty import _static_error, measure_noise\r\nimport trackpy  # to get trackpy.__version__\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\ndef minmass_v03_change(raw_image, old_minmass, preprocess=True,\r\n                       invert=False, noise_size=1, smoothing_size=None,\r\n                       threshold=None):\r\n    \"\"\"Convert minmass value from v0.2.4 to v0.3.\r\n\r\n    From trackpy version 0.3.0, the mass calculation is changed. Before\r\n    version 0.3.0 the mass was calculated from a rescaled image. From version\r\n    0.3.0, this rescaling is compensated at the end so that the mass reflects\r\n    the actual intensities in the image.\r\n\r\n    This function calculates the scalefactor between the old and new mass\r\n    and applies it to calculate the new minmass filter value.\r\n\r\n    Parameters\r\n    ----------\r\n    raw_image : ndarray\r\n    old_minmass : number\r\n    preprocess : boolean, optional\r\n        Defaults to True\r\n    invert : boolean, optional\r\n        Defaults to False\r\n    noise_size : number, optional\r\n        Defaults to 1\r\n    smoothing_size : number, optional\r\n        Required when preprocessing. In locate, it equals diameter by default.\r\n    threshold : number, optional\r\n\r\n    Returns\r\n    -------\r\n    New minmass\r\n    \"\"\"\r\n    if preprocess and smoothing_size is None:\r\n        raise ValueError('Please specify the smoothing size. By default, this '\r\n                         'equals diameter.')\r\n\r\n    if np.issubdtype(raw_image.dtype, np.integer):\r\n        dtype = raw_image.dtype\r\n        if invert:\r\n            raw_image = raw_image ^ np.iinfo(dtype).max\r\n    else:\r\n        dtype = np.uint8\r\n        if invert:\r\n            raw_image = 1 - raw_image\r\n\r\n    if preprocess:\r\n        image = bandpass(raw_image, noise_size, smoothing_size, threshold)\r\n    else:\r\n        image = raw_image\r\n\r\n    scale_factor = scalefactor_to_gamut(image, dtype)\r\n\r\n    return old_minmass / scale_factor\r\n\r\n\r\ndef minmass_v04_change(raw_image, old_minmass, diameter, preprocess=True,\r\n                       old_smoothing_size=None, new_smoothing_size=None):\r\n    \"\"\"Convert minmass value from v0.3 to v0.4.\r\n\r\n    From trackpy version 0.4.0, the default image preprocessing is changed.\r\n    Before version 0.4.0 a blurred out image (rolling or boxcar average) with\r\n    a circular kernel with radius `diameter` was subtracted from the image\r\n    before refinement and mass calculation. From version 0.4.0, this has\r\n    changed to a square kernel with sides `diameter`, more or less twice as\r\n    small. This increases tracking accuracy, and reduces the mass.\r\n\r\n    This function estimates this difference and applies it to calculate the\r\n    new minmass value.\r\n\r\n    Here the following approximate relation between the \"real\" mass of the\r\n    feature and the mass apparent from the bandpassed image is used:\r\n\r\n    .. math::\r\n\r\n        M_{bp} = M_{real} \\\\left( 1 - \\\\frac{n_r}{n_{bp}} \\\\right)\r\n\r\n    Where :math:`n_r` denotes the number of pixels in the (circular)\r\n    refine mask and :math:`n_{bp}` the number of pixels in the (square)\r\n    rolling average kernel.\r\n\r\n    This follows from a simple model where the bandpassed image :math:`I_{bp}`\r\n    relates to the \"real\" feature :math:`F` and the noise :math:`N` by:\r\n\r\n    .. math::\r\n\r\n        I_{bp} = F + N - \\\\left(N + \\\\frac{M_{real}}{n_{bp}} \\\\right)\r\n\r\n    Parameters\r\n    ----------\r\n    raw_image : ndarray\r\n    old_minmass : number\r\n    diameter : number or tuple\r\n        Odd-valued number that is used in locate\r\n    preprocess : boolean, optional\r\n        Defaults to True. Minmass is not changed when preprocess=False.", "start_char_idx": 0, "end_char_idx": 4234, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "472224fc-e18f-459f-a378-42775b012790": {"__data__": {"id_": "472224fc-e18f-459f-a378-42775b012790", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "46e93b41-ad95-4467-909a-25bee6310e92", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "841f1263b81e50f7b438d2ddbd9c5f0d973b53a7d9c5493df64fa1d3c3bf4b73", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "683b30de-b242-44b3-bdcc-1f11bf7cb7a9", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "2163cf5253fbc597cffbdbfee8e95ff9b34c60cbcc82e27e922fc504532768c9", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "93638a5c-ec51-43d4-8fc0-7b7d2dd42b0f", "node_type": "1", "metadata": {}, "hash": "34c83528e5bd013d8366a78bcdd49a9954696c06c6aae80997224d649851fc80", "class_name": "RelatedNodeInfo"}}, "text": "This follows from a simple model where the bandpassed image :math:`I_{bp}`\r\n    relates to the \"real\" feature :math:`F` and the noise :math:`N` by:\r\n\r\n    .. math::\r\n\r\n        I_{bp} = F + N - \\\\left(N + \\\\frac{M_{real}}{n_{bp}} \\\\right)\r\n\r\n    Parameters\r\n    ----------\r\n    raw_image : ndarray\r\n    old_minmass : number\r\n    diameter : number or tuple\r\n        Odd-valued number that is used in locate\r\n    preprocess : boolean, optional\r\n        Defaults to True. Minmass is not changed when preprocess=False.\r\n    old_smoothing_size : number or tuple, optional\r\n        The smoothing size used in the old (pre v0.4) trackpy version (the\r\n        radius of the circular kernel). Defaults to diameter.\r\n    new_smoothing_size : number or tuple, optional\r\n        The smoothing size used in the new (post v0.4) trackpy version (the\r\n        size of the sides of the square kernel). Defaults to diameter.\r\n\r\n    Returns\r\n    -------\r\n    New minmass\r\n    \"\"\"\r\n    if not preprocess:\r\n        return old_minmass\r\n\r\n    ndim = raw_image.ndim\r\n    diameter = validate_tuple(diameter, ndim)\r\n    if old_smoothing_size is None:\r\n        old_smoothing_size = diameter\r\n    else:\r\n        old_smoothing_size = validate_tuple(old_smoothing_size, ndim)\r\n    if new_smoothing_size is None:\r\n        new_smoothing_size = diameter\r\n    else:\r\n        new_smoothing_size = validate_tuple(new_smoothing_size, ndim)\r\n\r\n    radius = tuple(int(d / 2) for d in diameter)\r\n    old_bp_size = tuple(s * 2 + 1 for s in old_smoothing_size)\r\n\r\n    n_px_refine = N_binary_mask(radius, ndim)\r\n    n_px_old_bp = N_binary_mask(old_bp_size, ndim)\r\n    n_px_new_bp = np.prod(new_smoothing_size)\r\n\r\n    real_minmass = old_minmass / (1 - n_px_refine / n_px_old_bp)\r\n    new_minmass = real_minmass * (1 - n_px_refine / n_px_new_bp)\r\n    return new_minmass\r\n\r\n\r\ndef local_maxima(image, radius, percentile=64, margin=None):\r\n    \"\"\"Find local maxima whose brightness is above a given percentile.\r\n    This function will be deprecated. Please use the routines in trackpy.find,\r\n    with the minimum separation between features as second argument.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n        For best performance, provide an integer-type array. If the type is not\r\n        of integer-type, the image will be normalized and coerced to uint8.\r\n    radius : the radius of the circular grey dilation kernel, which is the\r\n        minimum separation between maxima\r\n    percentile : chooses minimum grayscale value for a local maximum\r\n    margin : zone of exclusion at edges of image. Defaults to radius.\r\n            A smarter value is set by locate().\r\n    \"\"\"\r\n    warnings.warn(\"Local_maxima will be deprecated: please use routines in \"\r\n                  \"trackpy.find\", PendingDeprecationWarning)\r\n    return grey_dilation(image, radius, percentile, margin)\r\n\r\n\r\ndef estimate_mass(image, radius, coord):\r\n    \"Compute the total brightness in the neighborhood of a local maximum.\"\r\n    square = [slice(c - rad, c + rad + 1) for c, rad in zip(coord, radius)]\r\n    neighborhood = binary_mask(radius, image.ndim)*image[square]\r\n    return np.sum(neighborhood)\r\n\r\n\r\ndef estimate_size(image, radius, coord, estimated_mass):\r\n    \"Compute the total brightness in the neighborhood of a local maximum.\"\r\n    square = [slice(c - rad, c + rad + 1) for c, rad in zip(coord, radius)]\r\n    neighborhood = binary_mask(radius, image.ndim)*image[square]\r\n    Rg = np.sqrt(np.sum(r_squared_mask(radius, image.ndim) * neighborhood) /\r\n                 estimated_mass)\r\n    return Rg\r\n\r\n\r\ndef refine(*args, **kwargs):\r\n    \"\"\"\r\n    Deprecated.\r\n\r\n    See also\r\n    --------\r\n    trackpy.refine.refine_com\r\n    \"\"\"\r\n    warnings.warn(\"trackpy.feature.refine is deprecated: please use routines in \"\r\n                  \"trackpy.refine\", PendingDeprecationWarning)\r\n    return refine_com(*args, **kwargs)\r\n\r\n\r\ndef locate(raw_image, diameter, minmass=None, maxsize=None, separation=None,\r\n           noise_size=1, smoothing_size=None, threshold=None, invert=False,\r\n           percentile=64, topn=None, preprocess=True, max_iterations=10,\r\n           filter_before=None, filter_after=None,\r\n           characterize=True, engine='auto'):\r\n    \"\"\"Locate Gaussian-like blobs of some approximate size in an image.", "start_char_idx": 3721, "end_char_idx": 7991, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "93638a5c-ec51-43d4-8fc0-7b7d2dd42b0f": {"__data__": {"id_": "93638a5c-ec51-43d4-8fc0-7b7d2dd42b0f", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "46e93b41-ad95-4467-909a-25bee6310e92", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "841f1263b81e50f7b438d2ddbd9c5f0d973b53a7d9c5493df64fa1d3c3bf4b73", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "472224fc-e18f-459f-a378-42775b012790", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6c60339182c5ccf5fd316efc4d17e7802be1a589ab50def87e2d0dea8ae66437", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b057e07-3860-4b09-bec1-6aef08707715", "node_type": "1", "metadata": {}, "hash": "5fd63602b6a421aaf7f6cd28cc7d215ee514d268f1f947253045fff2ea16bc5d", "class_name": "RelatedNodeInfo"}}, "text": "See also\r\n    --------\r\n    trackpy.refine.refine_com\r\n    \"\"\"\r\n    warnings.warn(\"trackpy.feature.refine is deprecated: please use routines in \"\r\n                  \"trackpy.refine\", PendingDeprecationWarning)\r\n    return refine_com(*args, **kwargs)\r\n\r\n\r\ndef locate(raw_image, diameter, minmass=None, maxsize=None, separation=None,\r\n           noise_size=1, smoothing_size=None, threshold=None, invert=False,\r\n           percentile=64, topn=None, preprocess=True, max_iterations=10,\r\n           filter_before=None, filter_after=None,\r\n           characterize=True, engine='auto'):\r\n    \"\"\"Locate Gaussian-like blobs of some approximate size in an image.\r\n\r\n    Preprocess the image by performing a band pass and a threshold.\r\n    Locate all peaks of brightness, characterize the neighborhoods of the peaks\r\n    and take only those with given total brightness (\"mass\"). Finally,\r\n    refine the positions of each peak.\r\n\r\n    Parameters\r\n    ----------\r\n    raw_image : array (any dimensions)\r\n        Image used for final characterization. Ideally, pixel values of\r\n        this image are not rescaled, but it can also be identical to\r\n        ``image``.\r\n    image : array (same size as raw_image)\r\n        Processed image used for centroid-finding and most particle\r\n        measurements.\r\n    diameter : odd integer or tuple of odd integers\r\n        This may be a single number or a tuple giving the feature's\r\n        extent in each dimension, useful when the dimensions do not have\r\n        equal resolution (e.g. confocal microscopy). The tuple order is the\r\n        same as the image shape, conventionally (z, y, x) or (y, x). The\r\n        number(s) must be odd integers. When in doubt, round up.\r\n    minmass : float\r\n        The minimum integrated brightness. This is a crucial parameter for\r\n        eliminating spurious features.\r\n        Recommended minimum values are 100 for integer images and 1 for float\r\n        images. Defaults to 0 (no filtering).\r\n        .. warning:: The mass value is changed since v0.3.0\r\n        .. warning:: The default behaviour of minmass has changed since v0.4.0\r\n    maxsize : float\r\n        maximum radius-of-gyration of brightness, default None\r\n    separation : float or tuple\r\n        Minimum separation between features.\r\n        Default is diameter + 1. May be a tuple, see diameter for details.\r\n    noise_size : float or tuple\r\n        Width of Gaussian blurring kernel, in pixels\r\n        Default is 1. May be a tuple, see diameter for details.\r\n    smoothing_size : float or tuple\r\n        The size of the sides of the square kernel used in boxcar (rolling\r\n        average) smoothing, in pixels\r\n        Default is diameter. May be a tuple, making the kernel rectangular.\r\n    threshold : float\r\n        Clip bandpass result below this value. Thresholding is done on the\r\n        already background-subtracted image.\r\n        By default, 1 for integer images and 1/255 for float images.\r\n    invert : boolean\r\n        This will be deprecated. Use an appropriate PIMS pipeline to invert a\r\n        Frame or FramesSequence.\r\n        Set to True if features are darker than background. False by default.\r\n    percentile : float\r\n        Features must have a peak brighter than pixels in this\r\n        percentile. This helps eliminate spurious peaks.\r\n    topn : integer\r\n        Return only the N brightest features above minmass.\r\n        If None (default), return all features above minmass.\r\n    preprocess : boolean\r\n        Set to False to turn off bandpass preprocessing.\r\n    max_iterations : integer\r\n        max number of loops to refine the center of mass, default 10\r\n    filter_before : boolean\r\n        filter_before is no longer supported as it does not improve performance.\r\n    filter_after : boolean\r\n        This parameter has been deprecated: use minmass and maxsize.\r\n    characterize : boolean\r\n        Compute \"extras\": eccentricity, signal, ep. True by default.\r\n    engine : {'auto', 'python', 'numba'}\r\n\r\n    Returns\r\n    -------\r\n    DataFrame([x, y, mass, size, ecc, signal, raw_mass])\r\n        where \"x, y\" are appropriate to the dimensionality of the image,\r\n        mass means total integrated brightness of the blob,\r\n        size means the radius of gyration of its Gaussian-like profile,\r\n        ecc is its eccentricity (0 is circular),\r\n        and raw_mass is the total integrated brightness in raw_image.", "start_char_idx": 7338, "end_char_idx": 11733, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8b057e07-3860-4b09-bec1-6aef08707715": {"__data__": {"id_": "8b057e07-3860-4b09-bec1-6aef08707715", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "46e93b41-ad95-4467-909a-25bee6310e92", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "841f1263b81e50f7b438d2ddbd9c5f0d973b53a7d9c5493df64fa1d3c3bf4b73", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "93638a5c-ec51-43d4-8fc0-7b7d2dd42b0f", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "78bdd5185edf8314ac77e51b776fbe1e393245e505dfc6fa61b92f13c606a632", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "243e90fc-5988-4ff2-819b-92866b8a2593", "node_type": "1", "metadata": {}, "hash": "8b4266ca0b14a971aa84badde7e88341db007324ea88a60623d38074a3189f1b", "class_name": "RelatedNodeInfo"}}, "text": "max_iterations : integer\r\n        max number of loops to refine the center of mass, default 10\r\n    filter_before : boolean\r\n        filter_before is no longer supported as it does not improve performance.\r\n    filter_after : boolean\r\n        This parameter has been deprecated: use minmass and maxsize.\r\n    characterize : boolean\r\n        Compute \"extras\": eccentricity, signal, ep. True by default.\r\n    engine : {'auto', 'python', 'numba'}\r\n\r\n    Returns\r\n    -------\r\n    DataFrame([x, y, mass, size, ecc, signal, raw_mass])\r\n        where \"x, y\" are appropriate to the dimensionality of the image,\r\n        mass means total integrated brightness of the blob,\r\n        size means the radius of gyration of its Gaussian-like profile,\r\n        ecc is its eccentricity (0 is circular),\r\n        and raw_mass is the total integrated brightness in raw_image.\r\n\r\n    See Also\r\n    --------\r\n    batch : performs location on many images in batch\r\n    minmass_v03_change : to convert minmass from v0.2.4 to v0.3.0\r\n    minmass_v04_change : to convert minmass from v0.3.x to v0.4.x\r\n\r\n    Notes\r\n    -----\r\n    Locate works with a coordinate system that has its origin at the center of\r\n    pixel (0, 0). In almost all cases this will be the top-left pixel: the\r\n    y-axis is pointing downwards.\r\n\r\n    This is an implementation of the Crocker-Grier centroid-finding algorithm.\r\n    [1]_\r\n\r\n    References\r\n    ----------\r\n    .. [1] Crocker, J.C., Grier, D.G. http://dx.doi.org/10.1006/jcis.1996.0217\r\n\r\n    \"\"\"\r\n    if invert:\r\n        warnings.warn(\"The invert argument will be deprecated. Use a PIMS \"\r\n                      \"pipeline for this.\", PendingDeprecationWarning)\r\n    if filter_before is not None:\r\n        raise ValueError(\"The filter_before argument is no longer supported as \"\r\n                         \"it does not improve performance. Features are \"\r\n                         \"filtered after refine.\") # see GH issue #141\r\n    if filter_after is not None:\r\n        warnings.warn(\"The filter_after argument has been deprecated: it is \"\r\n                      \"always on, unless minmass = None and maxsize = None.\",\r\n                      DeprecationWarning)\r\n\r\n    # Validate parameters and set defaults.\r\n    raw_image = np.squeeze(raw_image)\r\n    shape = raw_image.shape\r\n    ndim = len(shape)\r\n\r\n    diameter = validate_tuple(diameter, ndim)\r\n    diameter = tuple([int(x) for x in diameter])\r\n    if not np.all([x & 1 for x in diameter]):\r\n        raise ValueError(\"Feature diameter must be an odd integer. Round up.\")\r\n    radius = tuple([x//2 for x in diameter])\r\n\r\n    isotropic = np.all(radius[1:] == radius[:-1])\r\n    if (not isotropic) and (maxsize is not None):\r\n        raise ValueError(\"Filtering by size is not available for anisotropic \"\r\n                         \"features.\")\r\n\r\n    is_float_image = not np.issubdtype(raw_image.dtype, np.integer)\r\n\r\n    if separation is None:\r\n        separation = tuple([x + 1 for x in diameter])\r\n    else:\r\n        separation = validate_tuple(separation, ndim)\r\n\r\n    if smoothing_size is None:\r\n        smoothing_size = diameter\r\n    else:\r\n        smoothing_size = validate_tuple(smoothing_size, ndim)\r\n\r\n    noise_size = validate_tuple(noise_size, ndim)\r\n\r\n    if minmass is None:\r\n        minmass = 0\r\n\r\n    # Check whether the image looks suspiciously like a color image.\r\n    if 3 in shape or 4 in shape:\r\n        dim = raw_image.ndim\r\n        warnings.warn(\"I am interpreting the image as {}-dimensional. \"\r\n                      \"If it is actually a {}-dimensional color image, \"\r\n                      \"convert it to grayscale first.\".format(dim, dim-1))\r\n\r\n    if threshold is None:\r\n        if is_float_image:\r\n            threshold = 1/255.\r\n        else:\r\n            threshold = 1\r\n\r\n    # Invert the image if necessary\r\n    if invert:\r\n        raw_image = invert_image(raw_image)\r\n\r\n    # Determine `image`: the image to find the local maxima on.\r\n    if preprocess:\r\n        image = bandpass(raw_image, noise_size, smoothing_size, threshold)\r\n    else:\r\n        image = raw_image\r\n\r\n    # For optimal performance, performance, coerce the image dtype to integer.", "start_char_idx": 10875, "end_char_idx": 15020, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "243e90fc-5988-4ff2-819b-92866b8a2593": {"__data__": {"id_": "243e90fc-5988-4ff2-819b-92866b8a2593", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "46e93b41-ad95-4467-909a-25bee6310e92", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "841f1263b81e50f7b438d2ddbd9c5f0d973b53a7d9c5493df64fa1d3c3bf4b73", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b057e07-3860-4b09-bec1-6aef08707715", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "b7008c90b3e0df15fd1720602247d4130533d52c26c6743fbe0bd9ba2b0348a3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0a2230cf-d536-4d4e-8d6e-4a79a9549907", "node_type": "1", "metadata": {}, "hash": "c4b53d5f43391d9fb708adcbc5f70e48f44b959f98b3ebfee9b9f94bac7376d4", "class_name": "RelatedNodeInfo"}}, "text": "if 3 in shape or 4 in shape:\r\n        dim = raw_image.ndim\r\n        warnings.warn(\"I am interpreting the image as {}-dimensional. \"\r\n                      \"If it is actually a {}-dimensional color image, \"\r\n                      \"convert it to grayscale first.\".format(dim, dim-1))\r\n\r\n    if threshold is None:\r\n        if is_float_image:\r\n            threshold = 1/255.\r\n        else:\r\n            threshold = 1\r\n\r\n    # Invert the image if necessary\r\n    if invert:\r\n        raw_image = invert_image(raw_image)\r\n\r\n    # Determine `image`: the image to find the local maxima on.\r\n    if preprocess:\r\n        image = bandpass(raw_image, noise_size, smoothing_size, threshold)\r\n    else:\r\n        image = raw_image\r\n\r\n    # For optimal performance, performance, coerce the image dtype to integer.\r\n    if is_float_image:  # For float images, assume bitdepth of 8.\r\n        dtype = np.uint8\r\n    else:   # For integer images, take original dtype\r\n        dtype = raw_image.dtype\r\n    # Normalize_to_int does nothing if image is already of integer type.\r\n    scale_factor, image = convert_to_int(image, dtype)\r\n\r\n    pos_columns = default_pos_columns(image.ndim)\r\n\r\n    # Find local maxima.\r\n    # Define zone of exclusion at edges of image, avoiding\r\n    #   - Features with incomplete image data (\"radius\")\r\n    #   - Extended particles that cannot be explored during subpixel\r\n    #       refinement (\"separation\")\r\n    #   - Invalid output of the bandpass step (\"smoothing_size\")\r\n    margin = tuple([max(rad, sep // 2 - 1, sm // 2) for (rad, sep, sm) in\r\n                    zip(radius, separation, smoothing_size)])\r\n    # Find features with minimum separation distance of `separation`. This\r\n    # excludes detection of small features close to large, bright features\r\n    # using the `maxsize` argument.\r\n    coords = grey_dilation(image, separation, percentile, margin, precise=False)\r\n\r\n    # Refine their locations and characterize mass, size, etc.\r\n    refined_coords = refine_com(raw_image, image, radius, coords,\r\n                                max_iterations=max_iterations,\r\n                                engine=engine, characterize=characterize)\r\n    if len(refined_coords) == 0:\r\n        return refined_coords\r\n\r\n    # Flat peaks return multiple nearby maxima. Eliminate duplicates.\r\n    if np.all(np.greater(separation, 0)):\r\n        to_drop = where_close(refined_coords[pos_columns], separation,\r\n                              refined_coords['mass'])\r\n        refined_coords.drop(to_drop, axis=0, inplace=True)\r\n        refined_coords.reset_index(drop=True, inplace=True)\r\n\r\n    # mass and signal values has to be corrected due to the rescaling\r\n    # raw_mass was obtained from raw image; size and ecc are scale-independent\r\n    refined_coords['mass'] /= scale_factor\r\n    if 'signal' in refined_coords:\r\n        refined_coords['signal'] /= scale_factor\r\n\r\n    # Filter on mass and size, if set.\r\n    condition = refined_coords['mass'] > minmass\r\n    if maxsize is not None:\r\n        condition &= refined_coords['size'] < maxsize\r\n    if not condition.all():  # apply the filter\r\n        # making a copy to avoid SettingWithCopyWarning\r\n        refined_coords = refined_coords.loc[condition].copy()\r\n\r\n    if len(refined_coords) == 0:\r\n        warnings.warn(\"No maxima survived mass- and size-based filtering. \"\r\n                      \"Be advised that the mass computation was changed from \"\r\n                      \"version 0.2.4 to 0.3.0 and from 0.3.3 to 0.4.0. \"\r\n                      \"See the documentation and the convenience functions \"\r\n                      \"'minmass_v03_change' and 'minmass_v04_change'.\")\r\n        return refined_coords\r\n\r\n    if topn is not None and len(refined_coords) > topn:\r\n        # go through numpy for easy pandas backwards compatibility\r\n        mass = refined_coords['mass'].values\r\n        if topn == 1:\r\n            # special case for high performance and correct shape\r\n            refined_coords = refined_coords.iloc[[np.argmax(mass)]]\r\n        else:\r\n            refined_coords = refined_coords.iloc[np.argsort(mass)[-topn:]]\r\n\r\n    # Estimate the uncertainty in position using signal (measured in refine)\r\n    # and noise (measured here below).", "start_char_idx": 14225, "end_char_idx": 18435, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0a2230cf-d536-4d4e-8d6e-4a79a9549907": {"__data__": {"id_": "0a2230cf-d536-4d4e-8d6e-4a79a9549907", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "46e93b41-ad95-4467-909a-25bee6310e92", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "841f1263b81e50f7b438d2ddbd9c5f0d973b53a7d9c5493df64fa1d3c3bf4b73", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "243e90fc-5988-4ff2-819b-92866b8a2593", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e19c19e9d52b9103149ead18e008dfa323acbd9cf6424021056c5b9dc3be9f88", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f87f924d-dd4d-4e3e-817b-99be324cf7d6", "node_type": "1", "metadata": {}, "hash": "c947c7049e5791cf9ab32a2cc99ead7311df457357b5cadb9af9019012132ecf", "class_name": "RelatedNodeInfo"}}, "text": "\"Be advised that the mass computation was changed from \"\r\n                      \"version 0.2.4 to 0.3.0 and from 0.3.3 to 0.4.0. \"\r\n                      \"See the documentation and the convenience functions \"\r\n                      \"'minmass_v03_change' and 'minmass_v04_change'.\")\r\n        return refined_coords\r\n\r\n    if topn is not None and len(refined_coords) > topn:\r\n        # go through numpy for easy pandas backwards compatibility\r\n        mass = refined_coords['mass'].values\r\n        if topn == 1:\r\n            # special case for high performance and correct shape\r\n            refined_coords = refined_coords.iloc[[np.argmax(mass)]]\r\n        else:\r\n            refined_coords = refined_coords.iloc[np.argsort(mass)[-topn:]]\r\n\r\n    # Estimate the uncertainty in position using signal (measured in refine)\r\n    # and noise (measured here below).\r\n    if characterize:\r\n        black_level, noise = measure_noise(image, raw_image, radius)\r\n        Npx = N_binary_mask(radius, ndim)\r\n        mass = refined_coords['raw_mass'].values - Npx * black_level\r\n        ep = _static_error(mass, noise, radius, noise_size)\r\n\r\n        if ep.ndim == 1:\r\n            refined_coords['ep'] = ep\r\n        else:\r\n            ep = pd.DataFrame(ep, columns=['ep_' + cc for cc in pos_columns])\r\n            refined_coords = pandas_concat([refined_coords, ep], axis=1)\r\n\r\n    # If this is a pims Frame object, it has a frame number.\r\n    # Tag it on; this is helpful for parallelization.\r\n    if hasattr(raw_image, 'frame_no') and raw_image.frame_no is not None:\r\n        refined_coords['frame'] = int(raw_image.frame_no)\r\n    return refined_coords\r\n\r\n\r\ndef batch(frames, diameter, output=None, meta=None, processes='auto',\r\n          after_locate=None, **kwargs):\r\n    \"\"\"Locate Gaussian-like blobs of some approximate size in a set of images.\r\n\r\n    Preprocess the image by performing a band pass and a threshold.\r\n    Locate all peaks of brightness, characterize the neighborhoods of the peaks\r\n    and take only those with given total brightness (\"mass\"). Finally,\r\n    refine the positions of each peak.\r\n\r\n    Parameters\r\n    ----------\r\n    frames : list (or iterable) of images\r\n        The frames to process.\r\n    diameter : odd integer or tuple of odd integers\r\n        This may be a single number or a tuple giving the feature's\r\n        extent in each dimension, useful when the dimensions do not have\r\n        equal resolution (e.g. confocal microscopy). The tuple order is the\r\n        same as the image shape, conventionally (z, y, x) or (y, x). The\r\n        number(s) must be odd integers. When in doubt, round up.\r\n    output : {None, trackpy.PandasHDFStore, SomeCustomClass}\r\n        If None, return all results as one big DataFrame. Otherwise, pass\r\n        results from each frame, one at a time, to the put() method\r\n        of whatever class is specified here.\r\n    meta : filepath or file object\r\n        If specified, information relevant to reproducing this batch is saved\r\n        as a YAML file, a plain-text machine- and human-readable format.\r\n        By default, this is None, and no file is saved.\r\n    processes : integer or \"auto\"\r\n        The number of processes to use in parallel. If <= 1, multiprocessing is\r\n        disabled. If \"auto\", the number returned by `os.cpu_count()`` is used.\r\n    after_locate : function\r\n        Specify a custom function to apply to the detected features in each\r\n        processed frame. It must accept the following arguments:\r\n\r\n        - ``frame_no``: an integer specifying the number of the current frame.\r\n        - ``features``: a DataFrame containing the detected features.\r\n\r\n        Furthermore it must return a DataFrame like ``features``.\r\n    **kwargs :\r\n        Keyword arguments that are passed to the wrapped `trackpy.locate`.\r\n        Refer to its docstring for further details.\r\n\r\n    Returns\r\n    -------\r\n    DataFrame([x, y, mass, size, ecc, signal])\r\n        where mass means total integrated brightness of the blob,\r\n        size means the radius of gyration of its Gaussian-like profile,\r\n        and ecc is its eccentricity (0 is circular).\r\n\r\n    See Also\r\n    --------\r\n    locate : performs location on a single image\r\n\r\n    Notes\r\n    -----\r\n    This is a convenience function that wraps `trackpy.locate` (see its\r\n    docstring for further details) and allows batch processing of multiple\r\n    frames, optionally in parallel by using multiprocessing.\r\n    \"\"\"", "start_char_idx": 17580, "end_char_idx": 22025, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f87f924d-dd4d-4e3e-817b-99be324cf7d6": {"__data__": {"id_": "f87f924d-dd4d-4e3e-817b-99be324cf7d6", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "46e93b41-ad95-4467-909a-25bee6310e92", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "841f1263b81e50f7b438d2ddbd9c5f0d973b53a7d9c5493df64fa1d3c3bf4b73", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0a2230cf-d536-4d4e-8d6e-4a79a9549907", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e8b9fa1c46dd48f6a8203583234a8a4e2a2a463f33e0fd0379587968f1a9c34a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b893a183-5a4c-406b-a547-3d237e52ebfd", "node_type": "1", "metadata": {}, "hash": "58c668b82d6a231f6c272f009782c3a804e7368a3122aeab81ad0c458bb2e89d", "class_name": "RelatedNodeInfo"}}, "text": "- ``features``: a DataFrame containing the detected features.\r\n\r\n        Furthermore it must return a DataFrame like ``features``.\r\n    **kwargs :\r\n        Keyword arguments that are passed to the wrapped `trackpy.locate`.\r\n        Refer to its docstring for further details.\r\n\r\n    Returns\r\n    -------\r\n    DataFrame([x, y, mass, size, ecc, signal])\r\n        where mass means total integrated brightness of the blob,\r\n        size means the radius of gyration of its Gaussian-like profile,\r\n        and ecc is its eccentricity (0 is circular).\r\n\r\n    See Also\r\n    --------\r\n    locate : performs location on a single image\r\n\r\n    Notes\r\n    -----\r\n    This is a convenience function that wraps `trackpy.locate` (see its\r\n    docstring for further details) and allows batch processing of multiple\r\n    frames, optionally in parallel by using multiprocessing.\r\n    \"\"\"\r\n    if \"raw_image\" in kwargs:\r\n        raise KeyError(\"the argument `raw_image` musn't be in `kwargs`, it is \"\r\n                       \"provided internally by `frames`\")\r\n    # Add required keyword argument\r\n    kwargs[\"diameter\"] = diameter\r\n\r\n    if meta:\r\n        # Gather meta information and save as YAML in current directory.\r\n        try:\r\n            source = frames.filename\r\n        except AttributeError:\r\n            source = None\r\n        meta_info = dict(\r\n            timestamp=pd.datetime.utcnow().strftime('%Y-%m-%d-%H%M%S'),\r\n            trackpy_version=trackpy.__version__,\r\n            source=source,\r\n            **kwargs\r\n        )\r\n        if isinstance(meta, str):\r\n            with open(meta, 'w') as file_obj:\r\n                record_meta(meta_info, file_obj)\r\n        else:\r\n            # Interpret meta to be a file handle.\r\n            record_meta(meta_info, meta)\r\n\r\n    # Prepare wrapped function for mapping to `frames`\r\n    curried_locate = partial(locate, **kwargs)\r\n\r\n    pool, map_func = get_pool(processes)\r\n\r\n    if after_locate is None:\r\n        def after_locate(frame_no, features):\r\n            return features\r\n\r\n    try:\r\n        all_features = []\r\n        for i, features in enumerate(map_func(curried_locate, frames)):\r\n            image = frames[i]\r\n            if hasattr(image, 'frame_no') and image.frame_no is not None:\r\n                frame_no = image.frame_no\r\n                # Even if this worked, if locate() was running in parallel,\r\n                # it may not have had access to the \"frame_no\" attribute.\r\n                # Therefore we'll add the frame number to the DataFrame if\r\n                # needed, below.\r\n            else:\r\n                frame_no = i\r\n            if 'frame' not in features.columns:\r\n                features['frame'] = frame_no  # just counting iterations\r\n            features = after_locate(frame_no, features)\r\n\r\n            logger.info(\"Frame %d: %d features\", frame_no, len(features))\r\n            if len(features) > 0:\r\n                # Store if features were found\r\n                if output is None:\r\n                    all_features.append(features)\r\n                else:\r\n                    output.put(features)\r\n    finally:\r\n        if pool:\r\n            # Ensure correct termination of Pool\r\n            pool.terminate()\r\n\r\n    if output is None:\r\n        if len(all_features) > 0:\r\n            return pandas_concat(all_features).reset_index(drop=True)\r\n        else:  # return empty DataFrame\r\n            warnings.warn(\"No maxima found in any frame.\")\r\n            return pd.DataFrame(columns=list(features.columns) + ['frame'])\r\n    else:\r\n        return output\r\n\r\n\r\ndef characterize(coords, image, radius, scale_factor=1.):\r\n    \"\"\" Characterize a 2d ndarray of coordinates. Returns a dictionary of 1d\r\n    ndarrays. If the feature region (partly) falls out of the image, then the\r\n    corresponding element in the characterized arrays will be NaN.\"\"\"", "start_char_idx": 21156, "end_char_idx": 24989, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b893a183-5a4c-406b-a547-3d237e52ebfd": {"__data__": {"id_": "b893a183-5a4c-406b-a547-3d237e52ebfd", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "46e93b41-ad95-4467-909a-25bee6310e92", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "841f1263b81e50f7b438d2ddbd9c5f0d973b53a7d9c5493df64fa1d3c3bf4b73", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f87f924d-dd4d-4e3e-817b-99be324cf7d6", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "072196647e4a972172ecaefc1593d016ebbb3e5f926dabfd3c1ddf5180476a6b", "class_name": "RelatedNodeInfo"}}, "text": "return pd.DataFrame(columns=list(features.columns) + ['frame'])\r\n    else:\r\n        return output\r\n\r\n\r\ndef characterize(coords, image, radius, scale_factor=1.):\r\n    \"\"\" Characterize a 2d ndarray of coordinates. Returns a dictionary of 1d\r\n    ndarrays. If the feature region (partly) falls out of the image, then the\r\n    corresponding element in the characterized arrays will be NaN.\"\"\"\r\n    shape = image.shape\r\n    N, ndim = coords.shape\r\n\r\n    radius = validate_tuple(radius, ndim)\r\n    isotropic = is_isotropic(radius)\r\n\r\n    # largely based on trackpy.refine.center_of_mass._refine\r\n    coords_i = np.round(coords).astype(int)\r\n    mass = np.full(N, np.nan)\r\n    signal = np.full(N, np.nan)\r\n    ecc = np.full(N, np.nan)\r\n\r\n    mask = binary_mask(radius, ndim).astype(np.uint8)\r\n    if isotropic:\r\n        Rg = np.full(len(coords), np.nan)\r\n    else:\r\n        Rg = np.full((len(coords), len(radius)), np.nan)\r\n\r\n    for feat, coord in enumerate(coords_i):\r\n        if np.any([c - r < 0 or c + r >= sh\r\n                   for c, r, sh in zip(coord, radius, shape)]):\r\n            continue\r\n        rect = [slice(c - r, c + r + 1) for c, r in zip(coord, radius)]\r\n        neighborhood = mask * image[tuple(rect)]\r\n        mass[feat] = neighborhood.sum() / scale_factor\r\n        signal[feat] = neighborhood.max() / scale_factor\r\n        if isotropic:\r\n            Rg[feat] = np.sqrt(np.sum(r_squared_mask(radius, ndim) *\r\n                                      neighborhood) / mass[feat])\r\n        else:\r\n            Rg[feat] = np.sqrt(ndim * np.sum(x_squared_masks(radius, ndim) *\r\n                                             neighborhood,\r\n                                             axis=tuple(range(1, ndim + 1))) /\r\n                               mass[feat])[::-1]  # change order yx -> xy\r\n        # I only know how to measure eccentricity in 2D.\r\n        if ndim == 2:\r\n            ecc[feat] = np.sqrt(np.sum(neighborhood*cosmask(radius))**2 +\r\n                                np.sum(neighborhood*sinmask(radius))**2)\r\n            ecc[feat] /= (mass[feat] - neighborhood[radius] + 1e-6)\r\n\r\n    result = dict(mass=mass, signal=signal, ecc=ecc)\r\n    if isotropic:\r\n        result['size'] = Rg\r\n    else:\r\n        for _size, key in zip(Rg.T, default_size_columns(ndim, isotropic)):\r\n            result[key] = _size\r\n    return result", "start_char_idx": 24601, "end_char_idx": 26943, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dd337360-80af-4c87-9c5f-b933e04cdf49": {"__data__": {"id_": "dd337360-80af-4c87-9c5f-b933e04cdf49", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\filtering.py", "file_name": "filtering.py", "file_type": "text/x-python", "file_size": 2508, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a2397c02-ef77-4e66-a996-bd92936a906a", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\filtering.py", "file_name": "filtering.py", "file_type": "text/x-python", "file_size": 2508, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "09c0930a2864c26d85c44ceb845db1fad056207fbf7d36be60210724e785aa95", "class_name": "RelatedNodeInfo"}}, "text": "\"\"\"Simple functions that eliminate spurrious trajectories\r\nby wrapping pandas group-by and filter capabilities.\"\"\"\r\n\r\n__all__ = ['filter_stubs', 'filter_clusters', 'filter']\r\n\r\n\r\ndef filter_stubs(tracks, threshold=100):\r\n    \"\"\"Filter out trajectories with few points. They are often spurious.\r\n\r\n    Parameters\r\n    ----------\r\n    tracks : DataFrame\r\n        must include columns named 'frame' and 'particle'\r\n    threshold : integer, default 100\r\n        minimum number of points (video frames) to survive\r\n\r\n    Returns\r\n    -------\r\n    a subset of tracks\r\n    \"\"\"\r\n    try:\r\n        tracks['frame']\r\n        tracks['particle']\r\n    except KeyError:\r\n        raise ValueError(\"Tracks must contain columns 'frame' and 'particle'.\")\r\n    grouped = tracks.reset_index(drop=True).groupby('particle')\r\n    filtered = grouped.filter(lambda x: x.frame.count() >= threshold)\r\n    return filtered.set_index('frame', drop=False)\r\n\r\n\r\ndef filter_clusters(tracks, quantile=0.8, threshold=None):\r\n    \"\"\"Filter out trajectories with a mean particle size above a given quantile.\r\n\r\n    Parameters\r\n    ----------\r\n    tracks : DataFrame\r\n        must include columns named 'particle' and 'size'\r\n    quantile : number between 0 and 1\r\n        quantile of particle 'size' above which to cut off\r\n    threshold : number\r\n        If specified, ignore quantile.\r\n\r\n    Returns\r\n    -------\r\n    a subset of tracks\r\n    \"\"\"\r\n    try:\r\n        tracks['frame']\r\n        tracks['particle']\r\n    except KeyError:\r\n        raise ValueError(\"Tracks must contain columns 'frame' and 'particle'.\")\r\n    if threshold is None:\r\n        threshold = tracks['size'].quantile(quantile)\r\n\r\n    f = lambda x: x['size'].mean() < threshold  # filtering function\r\n    grouped = tracks.reset_index(drop=True).groupby('particle')\r\n    filtered = grouped.filter(f)\r\n    return filtered.set_index('frame', drop=False)\r\n\r\n\r\ndef filter(tracks, condition_func):\r\n    \"\"\"A workaround for a bug in pandas 0.12\r\n\r\n    Parameters\r\n    ----------\r\n    tracks : DataFrame\r\n        must include column named 'particle'\r\n    condition_func : function\r\n        The function is applied to each group of data. It must\r\n        return True or False.\r\n\r\n    Returns\r\n    -------\r\n    DataFrame\r\n        a subset of tracks\r\n    \"\"\"\r\n    grouped = tracks.reset_index(drop=True).groupby('particle')\r\n    filtered = grouped.filter(condition_func)\r\n    return filtered.set_index('frame', drop=False)\r\n\r\n\r\nbust_ghosts = filter_stubs\r\nbust_clusters = filter_clusters", "start_char_idx": 0, "end_char_idx": 2506, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ccc71d38-5a26-47c6-ad36-c889b3ebec78": {"__data__": {"id_": "ccc71d38-5a26-47c6-ad36-c889b3ebec78", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\find.py", "file_name": "find.py", "file_type": "text/x-python", "file_size": 7409, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c8e54ded-0a8c-4735-84cc-717723633d3c", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\find.py", "file_name": "find.py", "file_type": "text/x-python", "file_size": 7409, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "ee4e32c6569b298425ec7c4c9f35fb00774d0a74d74547cf9313db854cbc7fa6", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "667dff72-31cf-45b3-9418-4fba278c21d9", "node_type": "1", "metadata": {}, "hash": "a6d2a54dc1660fd5d4b83a77d0313fe713dd71c1d61bf69356574b37b6241a29", "class_name": "RelatedNodeInfo"}}, "text": "import warnings\r\nimport logging\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom scipy import ndimage\r\nfrom scipy.spatial import cKDTree\r\n\r\nfrom .utils import validate_tuple\r\nfrom .masks import binary_mask\r\nfrom .preprocessing import convert_to_int\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\ndef where_close(pos, separation, intensity=None):\r\n    \"\"\" Returns indices of features that are closer than separation from other\r\n    features. When intensity is given, the one with the lowest intensity is\r\n    returned: else the most topleft is returned (to avoid randomness)\"\"\"\r\n    if len(pos) == 0:\r\n        return []\r\n    separation = validate_tuple(separation, pos.shape[1])\r\n    if any([s == 0 for s in separation]):\r\n        return []\r\n    # Rescale positions, so that pairs are identified below a distance\r\n    # of 1.\r\n    if isinstance(pos, pd.DataFrame):\r\n        pos_rescaled = pos.values / separation\r\n    else:\r\n        pos_rescaled = pos / separation\r\n    duplicates = cKDTree(pos_rescaled, 30).query_pairs(1 - 1e-7)\r\n    if len(duplicates) == 0:\r\n        return []\r\n    index_0 = np.fromiter((x[0] for x in duplicates), dtype=int)\r\n    index_1 = np.fromiter((x[1] for x in duplicates), dtype=int)\r\n    if intensity is None:\r\n        to_drop = np.where(np.sum(pos_rescaled[index_0], 1) >\r\n                           np.sum(pos_rescaled[index_1], 1),\r\n                           index_1, index_0)\r\n    else:\r\n        intensity = np.asarray(intensity)\r\n        intensity_0 = intensity[index_0]\r\n        intensity_1 = intensity[index_1]\r\n        to_drop = np.where(intensity_0 > intensity_1, index_1, index_0)\r\n        edge_cases = intensity_0 == intensity_1\r\n        if np.any(edge_cases):\r\n            index_0 = index_0[edge_cases]\r\n            index_1 = index_1[edge_cases]\r\n            to_drop[edge_cases] = np.where(np.sum(pos_rescaled[index_0], 1) >\r\n                                           np.sum(pos_rescaled[index_1], 1),\r\n                                           index_1, index_0)\r\n    return np.unique(to_drop)\r\n\r\n\r\ndef drop_close(pos, separation, intensity=None):\r\n    \"\"\" Removes features that are closer than separation from other features.\r\n    When intensity is given, the one with the lowest intensity is dropped:\r\n    else the most topleft is dropped (to avoid randomness)\"\"\"\r\n    to_drop = where_close(pos, separation, intensity)\r\n    return np.delete(pos, to_drop, axis=0)\r\n\r\n\r\ndef percentile_threshold(image, percentile):\r\n    \"\"\"Find grayscale threshold based on distribution in image.\"\"\"\r\n\r\n    not_black = image[np.nonzero(image)]\r\n    if len(not_black) == 0:\r\n        return np.nan\r\n    return np.percentile(not_black, percentile)\r\n\r\n\r\ndef grey_dilation(image, separation, percentile=64, margin=None, precise=True):\r\n    \"\"\"Find local maxima whose brightness is above a given percentile.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n        For best performance, provide an integer-type array. If the type is not\r\n        of integer-type, the image will be normalized and coerced to uint8.\r\n    separation : number or tuple of numbers\r\n        Minimum separation between maxima. See precise for more information.\r\n    percentile : float in range of [0,100], optional\r\n        Features must have a peak brighter than pixels in this percentile.\r\n        This helps eliminate spurious peaks. Default 64.\r\n    margin : integer or tuple of integers, optional\r\n        Zone of exclusion at edges of image. Default is ``separation / 2``.\r\n    precise : boolean, optional\r\n        Determines whether there will be an extra filtering step (``drop_close``)\r\n        discarding features that are too close. Degrades performance.\r\n        Because of the square kernel used, too many features are returned when\r\n        precise=False. Default True.\r\n\r\n    See Also\r\n    --------\r\n    drop_close : removes features that are too close to brighter features\r\n    grey_dilation_legacy : local maxima finding routine used until trackpy v0.3\r\n    \"\"\"\r\n    # convert to integer. does nothing if image is already of integer type\r\n    factor, image = convert_to_int(image, dtype=np.uint8)\r\n\r\n    ndim = image.ndim\r\n    separation = validate_tuple(separation, ndim)\r\n    if margin is None:\r\n        margin = tuple([int(s / 2) for s in separation])\r\n\r\n    # Compute a threshold based on percentile.\r\n    threshold = percentile_threshold(image, percentile)\r\n    if np.isnan(threshold):\r\n        warnings.warn(\"Image is completely black.", "start_char_idx": 0, "end_char_idx": 4459, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "667dff72-31cf-45b3-9418-4fba278c21d9": {"__data__": {"id_": "667dff72-31cf-45b3-9418-4fba278c21d9", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\find.py", "file_name": "find.py", "file_type": "text/x-python", "file_size": 7409, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c8e54ded-0a8c-4735-84cc-717723633d3c", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\find.py", "file_name": "find.py", "file_type": "text/x-python", "file_size": 7409, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "ee4e32c6569b298425ec7c4c9f35fb00774d0a74d74547cf9313db854cbc7fa6", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ccc71d38-5a26-47c6-ad36-c889b3ebec78", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\find.py", "file_name": "find.py", "file_type": "text/x-python", "file_size": 7409, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "72a67b003c7452d271ceaedd82d2cc737990ab826173977698111e8015122e05", "class_name": "RelatedNodeInfo"}}, "text": "Degrades performance.\r\n        Because of the square kernel used, too many features are returned when\r\n        precise=False. Default True.\r\n\r\n    See Also\r\n    --------\r\n    drop_close : removes features that are too close to brighter features\r\n    grey_dilation_legacy : local maxima finding routine used until trackpy v0.3\r\n    \"\"\"\r\n    # convert to integer. does nothing if image is already of integer type\r\n    factor, image = convert_to_int(image, dtype=np.uint8)\r\n\r\n    ndim = image.ndim\r\n    separation = validate_tuple(separation, ndim)\r\n    if margin is None:\r\n        margin = tuple([int(s / 2) for s in separation])\r\n\r\n    # Compute a threshold based on percentile.\r\n    threshold = percentile_threshold(image, percentile)\r\n    if np.isnan(threshold):\r\n        warnings.warn(\"Image is completely black.\", UserWarning)\r\n        return np.empty((0, ndim))\r\n\r\n    # Find the largest box that fits inside the ellipse given by separation\r\n    size = [int(2 * s / np.sqrt(ndim)) for s in separation]\r\n\r\n    # The intersection of the image with its dilation gives local maxima.\r\n    dilation = ndimage.grey_dilation(image, size, mode='constant')\r\n    maxima = (image == dilation) & (image > threshold)\r\n    if np.sum(maxima) == 0:\r\n        warnings.warn(\"Image contains no local maxima.\", UserWarning)\r\n        return np.empty((0, ndim))\r\n\r\n    pos = np.vstack(np.where(maxima)).T\r\n\r\n    # Do not accept peaks near the edges.\r\n    shape = np.array(image.shape)\r\n    near_edge = np.any((pos < margin) | (pos > (shape - margin - 1)), 1)\r\n    pos = pos[~near_edge]\r\n\r\n    if len(pos) == 0:\r\n        warnings.warn(\"All local maxima were in the margins.\", UserWarning)\r\n        return np.empty((0, ndim))\r\n\r\n    # Remove local maxima that are too close to each other\r\n    if precise:\r\n        pos = drop_close(pos, separation, image[maxima][~near_edge])\r\n\r\n    return pos\r\n\r\n\r\ndef grey_dilation_legacy(image, separation, percentile=64, margin=None):\r\n    \"\"\"Find local maxima whose brightness is above a given percentile.\r\n\r\n    Parameters\r\n    ----------\r\n    separation : minimum separation between maxima\r\n    percentile : chooses minimum greyscale value for a local maximum\r\n    margin : zone of exclusion at edges of image. Defaults to radius.\r\n            A smarter value is set by locate().\r\n\r\n    See Also\r\n    --------\r\n    grey_dilation : faster local maxima finding routine\r\n    \"\"\"\r\n    if margin is None:\r\n        margin = separation\r\n\r\n    ndim = image.ndim\r\n    # Compute a threshold based on percentile.\r\n    threshold = percentile_threshold(image, percentile)\r\n    if np.isnan(threshold):\r\n        warnings.warn(\"Image is completely black.\", UserWarning)\r\n        return np.empty((0, ndim))\r\n\r\n    if not np.issubdtype(image.dtype, np.integer):\r\n        factor = 255 / image.max()\r\n        image = (factor * image.clip(min=0.)).astype(np.uint8)\r\n\r\n    # The intersection of the image with its dilation gives local maxima\r\n    footprint = binary_mask(separation, ndim)\r\n    dilation = ndimage.grey_dilation(image, footprint=footprint,\r\n                                     mode='constant')\r\n    maxima = np.vstack(np.where((image == dilation) & (image > threshold))).T\r\n    if not np.size(maxima) > 0:\r\n        warnings.warn(\"Image contains no local maxima.\", UserWarning)\r\n        return np.empty((0, ndim))\r\n\r\n    # Do not accept peaks near the edges.\r\n    shape = np.array(image.shape)\r\n    near_edge = np.any((maxima < margin) | (maxima > (shape - margin - 1)), 1)\r\n    maxima = maxima[~near_edge]\r\n    if not np.size(maxima) > 0:\r\n        warnings.warn(\"All local maxima were in the margins.\", UserWarning)\r\n\r\n    # Return coords in as a numpy array shaped so it can be passed directly\r\n    # to the DataFrame constructor.\r\n    return maxima", "start_char_idx": 3645, "end_char_idx": 7407, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "07962b5f-fbf2-4244-b93c-44d043b8ccb8": {"__data__": {"id_": "07962b5f-fbf2-4244-b93c-44d043b8ccb8", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\framewise_data.py", "file_name": "framewise_data.py", "file_type": "text/x-python", "file_size": 10358, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2be2921-7682-4cd6-97ed-f4febdca9ede", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\framewise_data.py", "file_name": "framewise_data.py", "file_type": "text/x-python", "file_size": 10358, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "4729a15fdd5b2933e134fb6c6724105c840b4ab31c3497c5356652521f1b5b39", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "15caced0-bd93-4f15-97dc-2fbf877182c5", "node_type": "1", "metadata": {}, "hash": "4d7a3a9ee4cc4fbc1913bcbd8c246b071f0fa08b82c33f27ff37d755ddc31dbd", "class_name": "RelatedNodeInfo"}}, "text": "import logging\r\nimport os\r\nfrom abc import ABCMeta, abstractmethod, abstractproperty\r\nimport warnings\r\n\r\nimport pandas as pd\r\n\r\nfrom .utils import pandas_concat\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\nclass FramewiseData:\r\n    \"Abstract base class defining a data container with framewise access.\"\r\n\r\n    __metaclass__ = ABCMeta\r\n\r\n    @abstractmethod\r\n    def put(self, df):\r\n        pass\r\n\r\n    @abstractmethod\r\n    def get(self, frame_no):\r\n        pass\r\n\r\n    @abstractproperty\r\n    def frames(self):\r\n        pass\r\n\r\n    @abstractmethod\r\n    def close(self):\r\n        pass\r\n\r\n    @abstractproperty\r\n    def t_column(self):\r\n        pass\r\n\r\n    def __getitem__(self, frame_no):\r\n        return self.get(frame_no)\r\n\r\n    def __len__(self):\r\n        return len(self.frames)\r\n\r\n    def dump(self, N=None):\r\n        \"\"\"Return data from all, or the first N, frames in a single DataFrame\r\n\r\n        Parameters\r\n        ----------\r\n        N : integer\r\n            optional; if None, return all frames\r\n\r\n        Returns\r\n        -------\r\n        DataFrame\r\n        \"\"\"\r\n        if N is None:\r\n            return pandas_concat(iter(self))\r\n        else:\r\n            i = iter(self)\r\n            return pandas_concat(next(i) for _ in range(N))\r\n\r\n    @property\r\n    def max_frame(self):\r\n        return max(self.frames)\r\n\r\n    def _validate(self, df):\r\n        if self.t_column not in df.columns:\r\n            raise ValueError(\"Cannot write frame without a column \"\r\n                             \"called {}\".format(self.t_column))\r\n        if df[self.t_column].nunique() != 1:\r\n            raise ValueError(\"Found multiple values for 'frame'. \"\r\n                             \"Write one frame at a time.\")\r\n\r\n    def __iter__(self):\r\n        return self._build_generator()\r\n\r\n    def _build_generator(self):\r\n        for frame_no in self.frames:\r\n            yield self.get(frame_no)\r\n\r\n    def __enter__(self):\r\n        return self\r\n\r\n    def __exit__(self, type, value, traceback):\r\n        self.close()\r\n\r\nKEY_PREFIX = 'Frame_'\r\nlen_key_prefix = len(KEY_PREFIX)\r\n\r\n\r\ndef code_key(frame_no):\r\n    \"Turn the frame_no into a 'natural name' string idiomatic of HDFStore\"\r\n    key = '{}{}'.format(KEY_PREFIX, frame_no)\r\n    return key\r\n\r\n\r\ndef decode_key(key):\r\n    frame_no = int(key[len_key_prefix:])\r\n    return frame_no\r\n\r\n\r\nclass PandasHDFStore(FramewiseData):\r\n    \"\"\"An interface to an HDF5 file with framewise access, using pandas.\r\n\r\n    Save each frame's data to a node in a pandas HDFStore.\r\n\r\n    Any additional keyword arguments to the constructor are passed to\r\n    pandas.HDFStore().\r\n    \"\"\"\r\n\r\n    def __init__(self, filename, mode='a', t_column='frame', **kwargs):\r\n        self.filename = os.path.abspath(filename)\r\n        self._t_column = t_column\r\n        self.store = pd.HDFStore(self.filename, mode, **kwargs)\r\n\r\n    @property\r\n    def t_column(self):\r\n        return self._t_column\r\n\r\n    @property\r\n    def max_frame(self):\r\n        return max(self.frames)\r\n\r\n    def put(self, df):\r\n        if len(df) == 0:\r\n            warnings.warn('An empty DataFrame was passed to put(). Continuing.')\r\n            return\r\n        frame_no = df[self.t_column].values[0]  # validated to be all the same\r\n        key = code_key(frame_no)\r\n        # Store data as tabular instead of fixed-format.\r\n        # Make sure remove any prexisting data, so don't really 'append'.\r\n        try:\r\n            self.store.remove(key)\r\n        except KeyError:\r\n            pass\r\n        self.store.put(key, df, format='table')\r\n\r\n    def get(self, frame_no):\r\n        key = code_key(frame_no)\r\n        frame = self.store.get(key)\r\n        return frame\r\n\r\n    @property\r\n    def frames(self):\r\n        \"\"\"Returns sorted list of integer frame numbers in file\"\"\"\r\n        return self._get_frame_nos()\r\n\r\n    def _get_frame_nos(self):\r\n        \"\"\"Returns sorted list of integer frame numbers in file\"\"\"\r\n        # Pandas' store.keys() scans the entire file looking for stored Pandas\r\n        # structures. This is very slow for large numbers of frames.\r\n        # Instead, scan the root level of the file for nodes with names\r\n        # matching our scheme; we know they are DataFrames.\r\n        r = [decode_key(key) for key in self.store.root._v_children.keys() if\r\n             key.startswith(KEY_PREFIX)]\r\n        r.sort()\r\n        return r\r\n\r\n    def close(self):\r\n        self.store.close()\r\n\r\n\r\nclass PandasHDFStoreBig(PandasHDFStore):\r\n    \"\"\"Like PandasHDFStore, but keeps a cache of frame numbers.", "start_char_idx": 0, "end_char_idx": 4500, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "15caced0-bd93-4f15-97dc-2fbf877182c5": {"__data__": {"id_": "15caced0-bd93-4f15-97dc-2fbf877182c5", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\framewise_data.py", "file_name": "framewise_data.py", "file_type": "text/x-python", "file_size": 10358, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2be2921-7682-4cd6-97ed-f4febdca9ede", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\framewise_data.py", "file_name": "framewise_data.py", "file_type": "text/x-python", "file_size": 10358, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "4729a15fdd5b2933e134fb6c6724105c840b4ab31c3497c5356652521f1b5b39", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07962b5f-fbf2-4244-b93c-44d043b8ccb8", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\framewise_data.py", "file_name": "framewise_data.py", "file_type": "text/x-python", "file_size": 10358, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "f74395b0ab0f544f77b7c0a179a926cdf5f6064bdd9880529c11b1ed8dfb3686", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e6b0b270-46ac-47b1-8ddb-7461aee811f3", "node_type": "1", "metadata": {}, "hash": "a7105fd08fd2b6c26c74ffb2807458b51241dc2fd5fd818361a92977c2389cea", "class_name": "RelatedNodeInfo"}}, "text": "This is very slow for large numbers of frames.\r\n        # Instead, scan the root level of the file for nodes with names\r\n        # matching our scheme; we know they are DataFrames.\r\n        r = [decode_key(key) for key in self.store.root._v_children.keys() if\r\n             key.startswith(KEY_PREFIX)]\r\n        r.sort()\r\n        return r\r\n\r\n    def close(self):\r\n        self.store.close()\r\n\r\n\r\nclass PandasHDFStoreBig(PandasHDFStore):\r\n    \"\"\"Like PandasHDFStore, but keeps a cache of frame numbers.\r\n\r\n    This can give a large performance boost when a file contains thousands\r\n    of frames.\r\n\r\n    If a file was made in PandasHDFStore, opening it with this class\r\n    and then closing it will add a cache (if mode != 'r').\r\n\r\n    Any additional keyword arguments to the constructor are passed to\r\n    pandas.HDFStore().\r\n    \"\"\"\r\n\r\n    def __init__(self, filename, mode='a', t_column='frame', **kwargs):\r\n        self._CACHE_NAME = '_Frames_Cache'\r\n        self._frames_cache = None\r\n        self._cache_dirty = False  # Whether _frames_cache needs to be written out\r\n        super().__init__(filename, mode, t_column,\r\n                                                **kwargs)\r\n\r\n    @property\r\n    def frames(self):\r\n        # Hit memory cache, then disk cache\r\n        if self._frames_cache is not None:\r\n            return self._frames_cache\r\n        else:\r\n            try:\r\n                self._frames_cache = list(self.store[self._CACHE_NAME].index.values)\r\n                self._cache_dirty = False\r\n            except KeyError:\r\n                self._frames_cache = self._get_frame_nos()\r\n                self._cache_dirty = True # In memory, but not in file\r\n            return self._frames_cache\r\n\r\n    def put(self, df):\r\n        self._invalidate_cache()\r\n        super().put(df)\r\n\r\n    def rebuild_cache(self):\r\n        \"\"\"Delete cache on disk and rebuild it.\"\"\"\r\n        self._invalidate_cache()\r\n        _ = self.frames # Compute cache\r\n        self._flush_cache()\r\n\r\n    def _invalidate_cache(self):\r\n        self._frames_cache = None\r\n        try:\r\n            del self.store[self._CACHE_NAME]\r\n        except KeyError: pass\r\n\r\n    def _flush_cache(self):\r\n        \"\"\"Writes frame cache if dirty and file is writable.\"\"\"\r\n        if (self._frames_cache is not None and self._cache_dirty\r\n                and self.store.root._v_file._iswritable()):\r\n            self.store[self._CACHE_NAME] = pd.DataFrame({'dummy': 1},\r\n                                                        index=self._frames_cache)\r\n            self._cache_dirty = False\r\n\r\n    def close(self):\r\n        \"\"\"Updates cache, writes if necessary, then closes file.\"\"\"\r\n        if self.store.root._v_file._iswritable():\r\n            _ = self.frames # Compute cache\r\n            self._flush_cache()\r\n        super().close()\r\n\r\n\r\nclass PandasHDFStoreSingleNode(FramewiseData):\r\n    \"\"\"An interface to an HDF5 file with framewise access,\r\n    using pandas, that is faster for cross-frame queries.\r\n\r\n    This implementation is more complex than PandasHDFStore,\r\n    but it simplifies (speeds up?) cross-frame queries,\r\n    like queries for a single probe's entire trajectory.\r\n\r\n    Any additional keyword arguments to the constructor are passed to\r\n    pandas.HDFStore().\r\n    \"\"\"\r\n\r\n    def __init__(self, filename, key='FrameData', mode='a', t_column='frame',\r\n                 use_tabular_copy=False, **kwargs):\r\n        self.filename = os.path.abspath(filename)\r\n        self.key = key\r\n        self._t_column = t_column\r\n        self.store = pd.HDFStore(self.filename, mode, **kwargs)\r\n\r\n        store = pd.HDFStore(self.filename)\r\n        try:\r\n            store[self.key]\r\n        except KeyError:\r\n            pass\r\n        else:\r\n            self._validate_node(use_tabular_copy)\r\n        store.close()\r\n\r\n    @property\r\n    def t_column(self):\r\n        return self._t_column\r\n\r\n    def put(self, df):\r\n        if len(df) == 0:\r\n            warnings.warn('An empty DataFrame was passed to put(). Continuing.')", "start_char_idx": 4000, "end_char_idx": 8003, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e6b0b270-46ac-47b1-8ddb-7461aee811f3": {"__data__": {"id_": "e6b0b270-46ac-47b1-8ddb-7461aee811f3", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\framewise_data.py", "file_name": "framewise_data.py", "file_type": "text/x-python", "file_size": 10358, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2be2921-7682-4cd6-97ed-f4febdca9ede", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\framewise_data.py", "file_name": "framewise_data.py", "file_type": "text/x-python", "file_size": 10358, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "4729a15fdd5b2933e134fb6c6724105c840b4ab31c3497c5356652521f1b5b39", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "15caced0-bd93-4f15-97dc-2fbf877182c5", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\framewise_data.py", "file_name": "framewise_data.py", "file_type": "text/x-python", "file_size": 10358, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "167fc74427e28aefe13ba3b6ed7851a4a59c2bc47d7bd6fa14422386f0566bfd", "class_name": "RelatedNodeInfo"}}, "text": "Any additional keyword arguments to the constructor are passed to\r\n    pandas.HDFStore().\r\n    \"\"\"\r\n\r\n    def __init__(self, filename, key='FrameData', mode='a', t_column='frame',\r\n                 use_tabular_copy=False, **kwargs):\r\n        self.filename = os.path.abspath(filename)\r\n        self.key = key\r\n        self._t_column = t_column\r\n        self.store = pd.HDFStore(self.filename, mode, **kwargs)\r\n\r\n        store = pd.HDFStore(self.filename)\r\n        try:\r\n            store[self.key]\r\n        except KeyError:\r\n            pass\r\n        else:\r\n            self._validate_node(use_tabular_copy)\r\n        store.close()\r\n\r\n    @property\r\n    def t_column(self):\r\n        return self._t_column\r\n\r\n    def put(self, df):\r\n        if len(df) == 0:\r\n            warnings.warn('An empty DataFrame was passed to put(). Continuing.')\r\n            return\r\n        self._validate(df)\r\n        self.store.append(self.key, df, data_columns=True)\r\n\r\n    def get(self, frame_no):\r\n        frame = self.store.select(self.key, '{} == {}'.format(\r\n            self._t_column, frame_no))\r\n        return frame\r\n\r\n    def dump(self, N=None):\r\n        \"\"\"Return data from all, or the first N, frames in a single DataFrame\r\n\r\n        Parameters\r\n        ----------\r\n        N : integer\r\n            optional; if None, return all frames\r\n\r\n        Returns\r\n        -------\r\n        DataFrame\r\n        \"\"\"\r\n        if N is None:\r\n            return self.store.select(self.key)\r\n        else:\r\n            Nth_frame = self.frames[N - 1]\r\n            return self.store.select(self.key, '{} <= {}'.format(\r\n                self._t_column, Nth_frame))\r\n\r\n    def close(self):\r\n        self.store.close()\r\n\r\n    def __del__(self):\r\n        if hasattr(self, 'store'):\r\n            self.close()\r\n\r\n    @property\r\n    def frames(self):\r\n        \"\"\"Returns sorted list of integer frame numbers in file\"\"\"\r\n        # I assume one column can fit in memory, which is not ideal.\r\n        # Chunking does not seem to be implemented for select_column.\r\n        frame_nos = self.store.select_column(self.key, self.t_column).unique()\r\n        frame_nos.sort()\r\n        return frame_nos\r\n\r\n    def _validate_node(self, use_tabular_copy):\r\n        # The HDFStore might be non-tabular, which means we cannot select a\r\n        # subset, and this whole structure will not work.\r\n        # For convenience, this can rewrite the table into a tabular node.\r\n        if use_tabular_copy:\r\n            self.key = _make_tabular_copy(self.filename, self.key)\r\n\r\n        pandas_type = getattr(getattr(getattr(\r\n            self.store._handle.root, self.key, None), '_v_attrs', None),\r\n            'pandas_type', None)\r\n        if not pandas_type == 'frame_table':\r\n            raise ValueError(\"This node is not tabular. Call with \"\r\n                             \"use_tabular_copy=True to proceed.\")\r\n\r\n\r\ndef _make_tabular_copy(store, key):\r\n    \"\"\"Copy the contents nontabular node in a pandas HDFStore\r\n    into a tabular node\"\"\"\r\n    tabular_key = key + '/tabular'\r\n    logger.info(\"Making a tabular copy of %s at %s\", (key, tabular_key))\r\n    store.append(tabular_key, store.get(key), data_columns=True)\r\n    return tabular_key", "start_char_idx": 7167, "end_char_idx": 10356, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6a8056b6-ec31-4b40-9466-2bbbf6f2ab54": {"__data__": {"id_": "6a8056b6-ec31-4b40-9466-2bbbf6f2ab54", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\masks.py", "file_name": "masks.py", "file_type": "text/x-python", "file_size": 7781, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5042ea56-9bd0-42bd-972f-b469bdc85dd3", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\masks.py", "file_name": "masks.py", "file_type": "text/x-python", "file_size": 7781, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "1245188b856c2847b116f54445a1a71d0b175113484fa5881b2b3b3cf041dd43", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c6266478-f7d5-497c-b2d1-bbfd69f585e4", "node_type": "1", "metadata": {}, "hash": "9ef6e58da93e3528af8bc07bae2490d1e5b648f37882ae13fff3e7f7ffb21ceb", "class_name": "RelatedNodeInfo"}}, "text": "import numpy as np\r\nfrom .utils import memo, validate_tuple\r\n\r\n__all__ = ['binary_mask', 'r_squared_mask', 'cosmask', 'sinmask',\r\n           'theta_mask']\r\n\r\n\r\n@memo\r\ndef binary_mask(radius, ndim):\r\n    \"Elliptical mask in a rectangular array\"\r\n    radius = validate_tuple(radius, ndim)\r\n    points = [np.arange(-rad, rad + 1) for rad in radius]\r\n    if len(radius) > 1:\r\n        coords = np.array(np.meshgrid(*points, indexing=\"ij\"))\r\n    else:\r\n        coords = np.array([points[0]])\r\n    r = [(coord/rad)**2 for (coord, rad) in zip(coords, radius)]\r\n    return sum(r) <= 1\r\n\r\n\r\n@memo\r\ndef N_binary_mask(radius, ndim):\r\n    return np.sum(binary_mask(radius, ndim))\r\n\r\n\r\n@memo\r\ndef r_squared_mask(radius, ndim):\r\n    \"Mask with values r^2 inside radius and 0 outside\"\r\n    radius = validate_tuple(radius, ndim)\r\n    points = [np.arange(-rad, rad + 1) for rad in radius]\r\n    if len(radius) > 1:\r\n        coords = np.array(np.meshgrid(*points, indexing=\"ij\"))\r\n    else:\r\n        coords = np.array([points[0]])\r\n    r = [(coord/rad)**2 for (coord, rad) in zip(coords, radius)]\r\n    r2 = np.sum(coords**2, 0).astype(int)\r\n    r2[sum(r) > 1] = 0\r\n    return r2\r\n    \r\n\r\n@memo\r\ndef x_squared_masks(radius, ndim):\r\n    \"Returns ndim masks with values x^2 inside radius and 0 outside\"\r\n    radius = validate_tuple(radius, ndim)\r\n    points = [np.arange(-rad, rad + 1) for rad in radius]\r\n    if len(radius) > 1:\r\n        coords = np.array(np.meshgrid(*points, indexing=\"ij\"))\r\n    else:\r\n        coords = np.array([points[0]])\r\n    r = [(coord/rad)**2 for (coord, rad) in zip(coords, radius)]\r\n    masks = np.asarray(coords**2, dtype=int)\r\n    masks[:, sum(r) > 1] = 0\r\n    return masks\r\n\r\n\r\n@memo\r\ndef theta_mask(radius):\r\n    \"\"\"Mask of values giving angular position relative to center. The angle is\r\n    defined according to ISO standards in which the angle is measured counter-\r\n    clockwise from the x axis, measured in a normal coordinate system with y-\r\n    axis pointing up and x axis pointing right.\r\n\r\n    In other words: for increasing angle, the coordinate moves counterclockwise\r\n    around the feature center starting on the right side.\r\n\r\n    However, in most images, the y-axis will point down so that the coordinate\r\n    will appear to move clockwise around the feature center.\r\n    \"\"\"", "start_char_idx": 0, "end_char_idx": 2300, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c6266478-f7d5-497c-b2d1-bbfd69f585e4": {"__data__": {"id_": "c6266478-f7d5-497c-b2d1-bbfd69f585e4", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\masks.py", "file_name": "masks.py", "file_type": "text/x-python", "file_size": 7781, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5042ea56-9bd0-42bd-972f-b469bdc85dd3", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\masks.py", "file_name": "masks.py", "file_type": "text/x-python", "file_size": 7781, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "1245188b856c2847b116f54445a1a71d0b175113484fa5881b2b3b3cf041dd43", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6a8056b6-ec31-4b40-9466-2bbbf6f2ab54", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\masks.py", "file_name": "masks.py", "file_type": "text/x-python", "file_size": 7781, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "5ec0c1d715c12931dd776ae29097e55084cf6bca6e66eabcf3608c148e497dcb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fddc9aef-13f1-4501-97bd-5c8857c46ed4", "node_type": "1", "metadata": {}, "hash": "d475879e24a25dc9d11d9984b12bf2cb163b31656c40fcf01d4b2561ccf01008", "class_name": "RelatedNodeInfo"}}, "text": "The angle is\r\n    defined according to ISO standards in which the angle is measured counter-\r\n    clockwise from the x axis, measured in a normal coordinate system with y-\r\n    axis pointing up and x axis pointing right.\r\n\r\n    In other words: for increasing angle, the coordinate moves counterclockwise\r\n    around the feature center starting on the right side.\r\n\r\n    However, in most images, the y-axis will point down so that the coordinate\r\n    will appear to move clockwise around the feature center.\r\n    \"\"\"\r\n    # 2D only\r\n    radius = validate_tuple(radius, 2)\r\n    tan_of_coord = lambda y, x: np.arctan2(y - radius[0], x - radius[1])\r\n    return np.fromfunction(tan_of_coord, [r * 2 + 1 for r in radius])\r\n\r\n\r\n@memo\r\ndef sinmask(radius):\r\n    \"Sin of theta_mask\"\r\n    return np.sin(2*theta_mask(radius))\r\n\r\n\r\n@memo\r\ndef cosmask(radius):\r\n    \"Sin of theta_mask\"\r\n    return np.cos(2*theta_mask(radius))\r\n\r\n\r\n@memo\r\ndef gaussian_kernel(sigma, truncate=4.0):\r\n    \"1D discretized gaussian\"\r\n    lw = int(truncate * sigma + 0.5)\r\n    x = np.arange(-lw, lw+1)\r\n    result = np.exp(x**2/(-2*sigma**2))\r\n    return result / np.sum(result)\r\n\r\n\r\ndef get_slice(coords, shape, radius):\r\n    \"\"\"Returns the slice and origin that belong to ``slice_image``\"\"\"\r\n    # interpret parameters\r\n    ndim = len(shape)\r\n    radius = validate_tuple(radius, ndim)\r\n    coords = np.atleast_2d(np.round(coords).astype(int))\r\n    # drop features that have no pixels inside the image\r\n    in_bounds = np.array([(coords[:, i] >= -r) & (coords[:, i] < sh + r)\r\n                         for i, sh, r in zip(range(ndim), shape, radius)])\r\n    coords = coords[np.all(in_bounds, axis=0)]\r\n    # return if no coordinates are left\r\n    if len(coords) == 0:\r\n        return tuple([slice(None, 0)] * ndim), None\r\n    # calculate the box\r\n    lower = coords.min(axis=0) - radius\r\n    upper = coords.max(axis=0) + radius + 1\r\n    # calculate the slices\r\n    origin = [None] * ndim\r\n    slices = [None] * ndim\r\n    for i, sh, low, up in zip(range(ndim), shape, lower, upper):\r\n        lower_bound_trunc = max(0, low)\r\n        upper_bound_trunc = min(sh, up)\r\n        slices[i] = slice(int(round(lower_bound_trunc)),\r\n                          int(round(upper_bound_trunc)))\r\n        origin[i] = lower_bound_trunc\r\n    return tuple(slices), origin\r\n\r\n\r\ndef slice_image(pos, image, radius):\r\n    \"\"\" Slice a box around a group of features from an image.\r\n\r\n    The box is the smallest box that contains all coordinates up to `radius`\r\n    from any coordinate.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n        The image that will be sliced\r\n    pos : iterable\r\n        An iterable (e.g. list or ndarray) that contains the feature positions\r\n    radius : number or tuple of numbers\r\n        Defines the size of the slice. Every pixel that has a distance lower or\r\n        equal to `radius` to a feature position is included.\r\n\r\n    Returns\r\n    -------\r\n    tuple of:\r\n    - the sliced image\r\n    - the coordinate of the slice origin (top-left pixel)\r\n    \"\"\"\r\n    slices, origin = get_slice(pos, image.shape,  radius)\r\n    return image[slices], origin\r\n\r\n\r\ndef get_mask(pos, shape, radius, include_edge=True, return_masks=False):\r\n    \"\"\" Create a binary mask that masks pixels farther than radius to all\r\n    given feature positions.\r\n\r\n    Optionally returns the masks that recover the individual feature pixels from\r\n    a masked image, as follows: ``image[mask][masks_single[i]]``\r\n\r\n    Parameters\r\n    ----------\r\n    pos : ndarray (N x 2 or N x 3)\r\n        Feature positions\r\n    shape : tuple\r\n        The shape of the image\r\n    radius : number or tuple\r\n        Radius of the individual feature masks\r\n    include_edge : boolean, optional\r\n        Determine whether pixels at exactly one radius from a position are\r\n        included. Default True.\r\n    return_masks : boolean, optional\r\n        Also return masks that recover the single features from a masked image.\r\n        Default False.", "start_char_idx": 1785, "end_char_idx": 5768, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fddc9aef-13f1-4501-97bd-5c8857c46ed4": {"__data__": {"id_": "fddc9aef-13f1-4501-97bd-5c8857c46ed4", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\masks.py", "file_name": "masks.py", "file_type": "text/x-python", "file_size": 7781, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5042ea56-9bd0-42bd-972f-b469bdc85dd3", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\masks.py", "file_name": "masks.py", "file_type": "text/x-python", "file_size": 7781, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "1245188b856c2847b116f54445a1a71d0b175113484fa5881b2b3b3cf041dd43", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c6266478-f7d5-497c-b2d1-bbfd69f585e4", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\masks.py", "file_name": "masks.py", "file_type": "text/x-python", "file_size": 7781, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "880a19e3a7bcd79d888ba686aa4f078f3013edd21cfdfac71dd8f530dd676f26", "class_name": "RelatedNodeInfo"}}, "text": "Optionally returns the masks that recover the individual feature pixels from\r\n    a masked image, as follows: ``image[mask][masks_single[i]]``\r\n\r\n    Parameters\r\n    ----------\r\n    pos : ndarray (N x 2 or N x 3)\r\n        Feature positions\r\n    shape : tuple\r\n        The shape of the image\r\n    radius : number or tuple\r\n        Radius of the individual feature masks\r\n    include_edge : boolean, optional\r\n        Determine whether pixels at exactly one radius from a position are\r\n        included. Default True.\r\n    return_masks : boolean, optional\r\n        Also return masks that recover the single features from a masked image.\r\n        Default False.\r\n\r\n    Returns\r\n    -------\r\n    ndarray containing a binary mask\r\n    if return_masks==True, returns a tuple of [masks, masks_singles]\r\n    \"\"\"\r\n    ndim = len(shape)\r\n    radius = validate_tuple(radius, ndim)\r\n    pos = np.atleast_2d(pos)\r\n\r\n    if include_edge:\r\n        in_mask = [np.sum(((np.indices(shape).T - p) / radius)**2, -1) <= 1\r\n                   for p in pos]\r\n    else:\r\n        in_mask = [np.sum(((np.indices(shape).T - p) / radius)**2, -1) < 1\r\n                   for p in pos]\r\n    mask_total = np.any(in_mask, axis=0).T\r\n    if return_masks:\r\n        masks_single = np.empty((len(pos), mask_total.sum()), dtype=bool)\r\n        for i, _in_mask in enumerate(in_mask):\r\n            masks_single[i] = _in_mask.T[mask_total]\r\n        return mask_total, masks_single\r\n    else:\r\n        return mask_total\r\n\r\n\r\ndef mask_image(pos, image, radius, origin=None, invert=False,\r\n               include_edge=None):\r\n    \"\"\" Masks an image so that pixels farther than radius to all given feature\r\n    positions become 0.\r\n\r\n    Parameters\r\n    ----------\r\n    pos : ndarray\r\n        Feature positions (N x 2 or N x 3)\r\n    image : ndarray\r\n    radius : number or tuple\r\n        Radius of the individual feature masks\r\n    origin : tuple, optional\r\n        The topleft coordinate (origin) of the image.\r\n    invert : boolean, optional\r\n        If invert==True, the features instead of the background will become 0.\r\n    include_edge : boolean, optional\r\n        Determine whether pixels at exactly one radius from a position are\r\n        included in the feature mask.\r\n        Defaults to True if invert==False, and to False if invert==True.\r\n    \"\"\"\r\n    if origin is not None:\r\n        pos = np.atleast_2d(pos) - np.array(origin)[np.newaxis, :]\r\n\r\n    if include_edge is None:\r\n        include_edge = not invert\r\n\r\n    mask_cluster = get_mask(pos, image.shape, radius, include_edge=include_edge)\r\n\r\n    if invert:\r\n        mask_cluster = ~mask_cluster\r\n\r\n    return image * mask_cluster.astype(np.uint8)", "start_char_idx": 5110, "end_char_idx": 7779, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3887f856-f3bb-4ec9-afba-a4d4b730a96b": {"__data__": {"id_": "3887f856-f3bb-4ec9-afba-a4d4b730a96b", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04960000-bdbb-4945-9b63-1b573c1547ff", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d974dcb70743ac7bb2dd502589feb63b5437683b542353158ad07a9c047e8950", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d1245507-4d09-436e-a832-69b255e4acf3", "node_type": "1", "metadata": {}, "hash": "4982163207b1be483176c1114004d3ec1fa45dae7841dc836d98f6d4ddb19770", "class_name": "RelatedNodeInfo"}}, "text": "import numpy as np\r\nimport pandas as pd\r\nfrom pandas import DataFrame, Series\r\n\r\nimport warnings\r\nfrom warnings import warn\r\nfrom .utils import pandas_sort, pandas_concat, guess_pos_columns\r\n\r\n\r\ndef msd(traj, mpp, fps, max_lagtime=100, detail=False, pos_columns=None):\r\n    \"\"\"Compute the mean displacement and mean squared displacement of one\r\n    trajectory over a range of time intervals.\r\n\r\n    Parameters\r\n    ----------\r\n    traj : DataFrame with one trajectory, including columns frame, x, and y\r\n    mpp : microns per pixel\r\n    fps : frames per second\r\n    max_lagtime : intervals of frames out to which MSD is computed\r\n        Default: 100\r\n    detail : See below. Default False.\r\n\r\n    Returns\r\n    -------\r\n    DataFrame([<x>, <y>, <x^2>, <y^2>, msd], index=t)\r\n\r\n        If detail is True, the DataFrame also contains a column N,\r\n        the estimated number of statistically independent measurements\r\n        that comprise the result at each lagtime.\r\n\r\n    Notes\r\n    -----\r\n    Input units are pixels and frames. Output units are microns and seconds.\r\n\r\n    See also\r\n    --------\r\n    imsd\r\n    emsd\r\n    \"\"\"\r\n    if traj['frame'].max() - traj['frame'].min() + 1 == len(traj):\r\n        # no gaps: use fourier-transform algorithm\r\n        return _msd_fft(traj, mpp, fps, max_lagtime, detail, pos_columns)\r\n    else:\r\n        # there are gaps in the trajectory: use slower algorithm\r\n        return _msd_gaps(traj, mpp, fps, max_lagtime, detail, pos_columns)\r\n\r\n\r\ndef _msd_N(N, t):\r\n    \"\"\"Computes the effective number of statistically independent measurements\r\n    of the mean square displacement of a single trajectory.\r\n\r\n    Parameters\r\n    ----------\r\n    N : integer\r\n        the number of positions in the trajectory (=number of steps + 1)\r\n    t : iterable\r\n        an iterable of lagtimes (integers)\r\n\r\n    References\r\n    ----------\r\n    Derived from Equation B4 in:\r\n    Qian, Hong, Michael P. Sheetz, and Elliot L. Elson. \"Single particle\r\n    tracking. Analysis of diffusion and flow in two-dimensional systems.\"\r\n    Biophysical journal 60.4 (1991): 910.\r\n    \"\"\"\r\n    t = np.array(t, dtype=float)\r\n    return np.where(t > N/2,\r\n                    1/(1+((N-t)**3+5*t-4*(N-t)**2*t-N)/(6*(N-t)*t**2)),\r\n                    6*(N-t)**2*t/(2*N-t+4*N*t**2-5*t**3))\r\n\r\n\r\ndef _msd_iter(pos, lagtimes):\r\n    with warnings.catch_warnings():\r\n        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\r\n        for lt in lagtimes:\r\n            diff = pos[lt:] - pos[:-lt]\r\n            yield np.concatenate((np.nanmean(diff, axis=0),\r\n                                  np.nanmean(diff**2, axis=0)))\r\n\r\n\r\n\r\ndef _msd_gaps(traj, mpp, fps, max_lagtime=100, detail=False, pos_columns=None):\r\n    \"\"\"Compute the mean displacement and mean squared displacement of one\r\n    trajectory over a range of time intervals.\"\"\"\r\n    if pos_columns is None:\r\n        pos_columns = ['x', 'y']\r\n    result_columns = ['<{}>'.format(p) for p in pos_columns] + \\\r\n                     ['<{}^2>'.format(p) for p in pos_columns]\r\n\r\n    # The following fails if > 1 record per particle (cannot reindex):\r\n    try:\r\n        # Reindex with consecutive frames, placing NaNs in the gaps.\r\n        pos = traj.set_index('frame')[pos_columns] * mpp\r\n        pos = pos.reindex(np.arange(pos.index[0], 1 + pos.index[-1]))\r\n    except ValueError:\r\n        if traj['frame'].nunique()!=len(traj['frame']):\r\n            # Reindex failed due to duplicate index values\r\n            raise Exception(\"Cannot use msd_gaps, more than one trajectory \"\r\n                            \"per particle found.\")", "start_char_idx": 0, "end_char_idx": 3585, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d1245507-4d09-436e-a832-69b255e4acf3": {"__data__": {"id_": "d1245507-4d09-436e-a832-69b255e4acf3", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04960000-bdbb-4945-9b63-1b573c1547ff", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d974dcb70743ac7bb2dd502589feb63b5437683b542353158ad07a9c047e8950", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3887f856-f3bb-4ec9-afba-a4d4b730a96b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "12f4e214b06f504cdd1085fb7ba5bdcb7133dfb1f6edf732db3fb6565a716d3f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bfa5e719-3f1c-4a82-8b2d-c7e1b0c8d716", "node_type": "1", "metadata": {}, "hash": "4ce0393ea6321ba662b2f51a7924827f053724c229a769bc44c763a5b665aaea", "class_name": "RelatedNodeInfo"}}, "text": "if pos_columns is None:\r\n        pos_columns = ['x', 'y']\r\n    result_columns = ['<{}>'.format(p) for p in pos_columns] + \\\r\n                     ['<{}^2>'.format(p) for p in pos_columns]\r\n\r\n    # The following fails if > 1 record per particle (cannot reindex):\r\n    try:\r\n        # Reindex with consecutive frames, placing NaNs in the gaps.\r\n        pos = traj.set_index('frame')[pos_columns] * mpp\r\n        pos = pos.reindex(np.arange(pos.index[0], 1 + pos.index[-1]))\r\n    except ValueError:\r\n        if traj['frame'].nunique()!=len(traj['frame']):\r\n            # Reindex failed due to duplicate index values\r\n            raise Exception(\"Cannot use msd_gaps, more than one trajectory \"\r\n                            \"per particle found.\")\r\n        else:\r\n            raise\r\n\r\n\r\n\r\n    max_lagtime = min(max_lagtime, len(pos) - 1)  # checking to be safe\r\n\r\n    lagtimes = np.arange(1, max_lagtime + 1)\r\n\r\n    result = pd.DataFrame(_msd_iter(pos.values, lagtimes),\r\n                          columns=result_columns, index=lagtimes)\r\n    result['msd'] = result[result_columns[-len(pos_columns):]].sum(1)\r\n    if detail:\r\n        # effective number of measurements\r\n        # approximately corrected with number of gaps\r\n        result['N'] = _msd_N(len(pos), lagtimes) * len(traj) / len(pos)\r\n    result['lagt'] = result.index.values/float(fps)\r\n    result.index.name = 'lagt'\r\n    return result\r\n\r\n\r\ndef _msd_fft(traj, mpp, fps, max_lagtime=100, detail=False, pos_columns=None):\r\n    \"\"\"Compute the mean displacement and mean squared displacement of one\r\n    trajectory over a range of time intervals using FFT transformation.\r\n\r\n    The original Python implementation comes from a SO answer :\r\n    http://stackoverflow.com/questions/34222272/computing-mean-square-displacement-using-python-and-fft#34222273.\r\n    The algorithm is described in this paper : http://dx.doi.org/10.1051/sfn/201112010.\r\n    \"\"\"\r\n    if pos_columns is None:\r\n        pos_columns = ['x', 'y']\r\n    result_columns = ['<{}>'.format(p) for p in pos_columns] + \\\r\n                     ['<{}^2>'.format(p) for p in pos_columns]\r\n\r\n    r = traj[pos_columns].values * mpp\r\n    t = traj['frame']\r\n\r\n    max_lagtime = min(max_lagtime, len(t) - 1)  # checking to be safe\r\n    lagtimes = np.arange(1, max_lagtime + 1)\r\n    N = len(r)\r\n\r\n    # calculate the mean displacements\r\n    r_diff = r[:-max_lagtime-1:-1] - r[:max_lagtime]\r\n    disp = np.cumsum(r_diff, axis=0) / (N - lagtimes[:, np.newaxis])\r\n\r\n    # below is a vectorized version of the original code\r\n    D = r**2\r\n    D_sum = D[:max_lagtime] + D[:-max_lagtime-1:-1]\r\n    S1 = 2*D.sum(axis=0) - np.cumsum(D_sum, axis=0)\r\n    F = np.fft.fft(r, n=2*N, axis=0)  # 2*N because of zero-padding\r\n    PSD = F * F.conjugate()\r\n    # this is the autocorrelation in convention B:\r\n    S2 = np.fft.ifft(PSD, axis=0)[1:max_lagtime+1].real\r\n    squared_disp = S1 - 2 * S2\r\n    squared_disp /= N - lagtimes[:, np.newaxis]  # divide res(m) by (N-m)\r\n\r\n    results = pd.DataFrame(np.concatenate((disp, squared_disp), axis=1),\r\n                           index=lagtimes, columns=result_columns)\r\n    results['msd'] = squared_disp.sum(axis=1)\r\n    if detail:\r\n        results['N'] = _msd_N(N, lagtimes)\r\n    results['lagt'] = lagtimes / float(fps)\r\n    results.index.name = 'lagt'\r\n\r\n    return results\r\n\r\n\r\ndef imsd(traj, mpp, fps, max_lagtime=100, statistic='msd', pos_columns=None):\r\n    \"\"\"Compute the mean squared displacement of each particle.", "start_char_idx": 2844, "end_char_idx": 6301, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bfa5e719-3f1c-4a82-8b2d-c7e1b0c8d716": {"__data__": {"id_": "bfa5e719-3f1c-4a82-8b2d-c7e1b0c8d716", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04960000-bdbb-4945-9b63-1b573c1547ff", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d974dcb70743ac7bb2dd502589feb63b5437683b542353158ad07a9c047e8950", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d1245507-4d09-436e-a832-69b255e4acf3", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "2a8a4f5d9eeb6aa58b0690f2d7005ae8377e44bc1de96a15550d69a1c19498cc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c1ee8682-6045-4237-840c-176bf074517e", "node_type": "1", "metadata": {}, "hash": "77ab88e8ad15550b9598710bd4e84712e945de72708c4bd63ace0420a1b98d33", "class_name": "RelatedNodeInfo"}}, "text": "Parameters\r\n    ----------\r\n    traj : DataFrame of trajectories of multiple particles, including\r\n        columns particle, frame, x, and y\r\n    mpp : microns per pixel\r\n    fps : frames per second\r\n    max_lagtime : intervals of frames out to which MSD is computed\r\n        Default: 100\r\n    statistic : {'msd', '<x>', '<y>', '<x^2>', '<y^2>'}, default is 'msd'\r\n        The functions msd() and emsd() return all these as columns. For\r\n        imsd() you have to pick one.\r\n\r\n    Returns\r\n    -------\r\n    DataFrame([Probe 1 msd, Probe 2 msd, ...], index=t)\r\n\r\n    Notes\r\n    -----\r\n    Input units are pixels and frames. Output units are microns and seconds.\r\n    \"\"\"\r\n    ids = []\r\n    msds = []\r\n    # Note: Index is set by msd, so we don't need to worry\r\n    # about conformity here.\r\n    for pid, ptraj in traj.groupby('particle'):\r\n        msds.append(msd(ptraj, mpp, fps, max_lagtime, False, pos_columns))\r\n        ids.append(pid)\r\n    results = pandas_concat(msds, keys=ids)\r\n    # Swap MultiIndex levels so that unstack() makes particles into columns.\r\n    results = results.swaplevel(0, 1)[statistic].unstack()\r\n    lagt = results.index.values.astype('float64')/float(fps)\r\n    results.set_index(lagt, inplace=True)\r\n    results.index.name = 'lag time [s]'\r\n    return results\r\n\r\n\r\ndef emsd(traj, mpp, fps, max_lagtime=100, detail=False, pos_columns=None):\r\n    \"\"\"Compute the ensemble mean squared displacements of many particles.\r\n\r\n    Parameters\r\n    ----------\r\n    traj : DataFrame of trajectories of multiple particles, including\r\n        columns particle, frame, x, and y\r\n    mpp : microns per pixel\r\n    fps : frames per second\r\n    max_lagtime : intervals of frames out to which MSD is computed\r\n        Default: 100\r\n    detail : Set to True to include <x>, <y>, <x^2>, <y^2>. Returns\r\n        only <r^2> by default.\r\n\r\n    Returns\r\n    -------\r\n    Series[msd, index=t] or, if detail=True,\r\n    DataFrame([<x>, <y>, <x^2>, <y^2>, msd], index=t)\r\n\r\n    Notes\r\n    -----\r\n    Input units are pixels and frames. Output units are microns and seconds.\r\n    \"\"\"\r\n    ids = []\r\n    msds = []\r\n    for pid, ptraj in traj.reset_index(drop=True).groupby('particle'):\r\n        msds.append(msd(ptraj, mpp, fps, max_lagtime, True, pos_columns))\r\n        ids.append(pid)\r\n    msds = pandas_concat(msds, keys=ids, names=['particle', 'frame'])\r\n    results = msds.mul(msds['N'], axis=0).groupby(level=1).mean()  # weighted average\r\n    results = results.div(msds['N'].groupby(level=1).mean(), axis=0)  # weights normalized\r\n    # Above, lagt is lumped in with the rest for simplicity and speed.\r\n    # Here, rebuild it from the frame index.\r\n    if not detail:\r\n        return results.set_index('lagt')['msd']\r\n    # correctly compute the effective number of independent measurements\r\n    results['N'] = msds['N'].sum(level=1)\r\n    return results\r\n\r\n\r\ndef compute_drift(traj, smoothing=0, pos_columns=None):\r\n    \"\"\"Return the ensemble drift, xy(t).\r\n\r\n    Parameters\r\n    ----------\r\n    traj : DataFrame\r\n        trajectories, including position columns, 'frame', and 'particle'\r\n    smoothing : integer, optional\r\n        Smooth the drift using a forward-looking rolling mean over\r\n        this many frames. Default: 0.\r\n    pos_columns : list, optional\r\n        The names of the position columns.\r\n        Default ['y', 'x'] or ['z', 'y', 'x'] if 'z' is present in traj.\r\n\r\n    Returns\r\n    -------\r\n    drift : DataFrame(pos_columns, index=frame)\r\n\r\n    Examples\r\n    --------\r\n    >>> compute_drift(traj).plot()\r\n    >>> compute_drift(traj, 0, ['x', 'y']).plot() # not smoothed, equivalent to default.\r\n    >>> compute_drift(traj, 15).plot() # Try various smoothing values.\r\n    >>> drift = compute_drift(traj, 15) # Save good drift curves.\r\n    >>> corrected_traj = subtract_drift(traj, drift) # Apply them.\r\n    \"\"\"", "start_char_idx": 6309, "end_char_idx": 10141, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c1ee8682-6045-4237-840c-176bf074517e": {"__data__": {"id_": "c1ee8682-6045-4237-840c-176bf074517e", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04960000-bdbb-4945-9b63-1b573c1547ff", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d974dcb70743ac7bb2dd502589feb63b5437683b542353158ad07a9c047e8950", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bfa5e719-3f1c-4a82-8b2d-c7e1b0c8d716", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "56b21a41dd961d0f5d186c90d145b5335f0021d0761306e4d00f021246183456", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "84651a80-f1ca-469f-a720-0323ac01dfa2", "node_type": "1", "metadata": {}, "hash": "e65abfbf01c4b5d01d0add2f8ef03134cce5cc826c0b272f30fb74732c462c44", "class_name": "RelatedNodeInfo"}}, "text": "Default: 0.\r\n    pos_columns : list, optional\r\n        The names of the position columns.\r\n        Default ['y', 'x'] or ['z', 'y', 'x'] if 'z' is present in traj.\r\n\r\n    Returns\r\n    -------\r\n    drift : DataFrame(pos_columns, index=frame)\r\n\r\n    Examples\r\n    --------\r\n    >>> compute_drift(traj).plot()\r\n    >>> compute_drift(traj, 0, ['x', 'y']).plot() # not smoothed, equivalent to default.\r\n    >>> compute_drift(traj, 15).plot() # Try various smoothing values.\r\n    >>> drift = compute_drift(traj, 15) # Save good drift curves.\r\n    >>> corrected_traj = subtract_drift(traj, drift) # Apply them.\r\n    \"\"\"\r\n    if pos_columns is None:\r\n        # swap the order for backwards compatibility\r\n        pos_columns = guess_pos_columns(traj)\r\n    f_sort = pandas_sort(traj, ['particle', 'frame'])\r\n\r\n    # Compute the difference list of positions, particle, and frame columns.\r\n    f_diff = f_sort[list(pos_columns) + ['particle', 'frame']].diff()\r\n\r\n    # Rename the frame column and insert the original frame column back in.\r\n    f_diff.rename(columns={'frame': 'frame_diff'}, inplace=True)\r\n    f_diff['frame'] = f_sort['frame']\r\n\r\n    # Compute the per frame averages. Keep only deltas of the same particle,\r\n    # and between frames that are consecutive.\r\n    mask = (f_diff['particle'] == 0) & (f_diff['frame_diff'] == 1)\r\n    dx = f_diff.loc[mask, list(pos_columns) + ['frame']].groupby('frame').mean()\r\n    if smoothing > 0:\r\n        dx = dx.rolling(smoothing, min_periods=0).mean()\r\n    return dx.cumsum()\r\n\r\n\r\ndef subtract_drift(traj, drift=None, inplace=False):\r\n    \"\"\"Return a copy of particle trajectories with the overall drift subtracted\r\n    out.\r\n\r\n    Parameters\r\n    ----------\r\n    traj : DataFrame of trajectories, including columns x, y, frame,\r\n           and particle (if there is more than one particle).\r\n    drift : optional DataFrame([x, y], index=frame) like output of\r\n         compute_drift(). If no drift is passed, drift is computed from traj.\r\n\r\n    Returns\r\n    -------\r\n    traj : a copy, having modified columns x and y\r\n    \"\"\"\r\n    if drift is None:\r\n        drift = compute_drift(traj)\r\n    if not inplace:\r\n        traj = traj.copy()\r\n    if 'particle' in traj.columns:\r\n        traj.set_index(['frame', 'particle'], inplace=True, drop=False)\r\n    else:\r\n        traj.set_index(['frame'], inplace=True, drop=False)\r\n    # Order of particles is irrelevant for performance\r\n    traj.sort_index(level='frame', inplace=True)\r\n    for col in drift.columns:\r\n        traj[col] = traj[col].sub(drift[col], fill_value=0, level='frame')\r\n    return traj\r\n\r\n\r\ndef is_typical(msds, frame, lower=0.1, upper=0.9):\r\n    \"\"\"Identify which paritcles' MSDs are in the central quantile.\r\n\r\n    Parameters\r\n    ----------\r\n    msds : DataFrame\r\n        This should be organized like the output of imsd().\r\n        Columns correspond to particles, indexed by lagtime in frames.\r\n    frame : integer\r\n        Compare MSDs at this lag interval.\r\n    lower : float between 0 and 1, default 0.1\r\n        Probes with MSD up to this quantile are deemed outliers.\r\n    upper : float between 0 and 1, default 0.9\r\n        Probes with MSD above this quantile are deemed outliers.\r\n\r\n    Returns\r\n    -------\r\n    Series of boolean values, indexed by particle number\r\n    True = typical particle, False = outlier particle\r\n\r\n    Examples\r\n    --------\r\n\r\n    >>> m = tp.imsd(traj, MPP, FPS)\r\n    >>> # Index by particle ID, slice using boolean output from is_typical(), and then\r\n    >>> # restore the original index, frame number.\r\n    >>> typical_traj = traj.set_index('particle').ix[is_typical(m)]\\\r\n    .reset_index().set_index('frame', drop=False)\r\n    \"\"\"\r\n    a, b = msds.iloc[frame].quantile(lower), msds.iloc[frame].quantile(upper)\r\n    return (msds.iloc[frame] > a) & (msds.iloc[frame] < b)\r\n\r\n\r\ndef vanhove(pos, lagtime, mpp=1, ensemble=False, bins=24):\r\n    \"\"\"Compute the van Hove correlation (histogram of displacements).\r\n\r\n    The van Hove correlation function is simply a histogram of particle\r\n    displacements.", "start_char_idx": 9529, "end_char_idx": 13572, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "84651a80-f1ca-469f-a720-0323ac01dfa2": {"__data__": {"id_": "84651a80-f1ca-469f-a720-0323ac01dfa2", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04960000-bdbb-4945-9b63-1b573c1547ff", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d974dcb70743ac7bb2dd502589feb63b5437683b542353158ad07a9c047e8950", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c1ee8682-6045-4237-840c-176bf074517e", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "4c36e322796eade0960873b990cd092a61cb2b6ad7e6214529d1a6cad7fe7994", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "eb670015-50de-45f3-87d3-9a81932f56ba", "node_type": "1", "metadata": {}, "hash": "ef0f0899901ccce31451037cf14f45f689dda539dc88bd4c68a746c337efce33", "class_name": "RelatedNodeInfo"}}, "text": ">>> typical_traj = traj.set_index('particle').ix[is_typical(m)]\\\r\n    .reset_index().set_index('frame', drop=False)\r\n    \"\"\"\r\n    a, b = msds.iloc[frame].quantile(lower), msds.iloc[frame].quantile(upper)\r\n    return (msds.iloc[frame] > a) & (msds.iloc[frame] < b)\r\n\r\n\r\ndef vanhove(pos, lagtime, mpp=1, ensemble=False, bins=24):\r\n    \"\"\"Compute the van Hove correlation (histogram of displacements).\r\n\r\n    The van Hove correlation function is simply a histogram of particle\r\n    displacements. It is useful for detecting physical heterogeneity\r\n    (or tracking errors).\r\n\r\n    Parameters\r\n    ----------\r\n    pos : DataFrame\r\n        x or (or!) y positions, one column per particle, indexed by frame\r\n    lagtime : integer interval of frames\r\n        Compare the correlation function at this lagtime.\r\n    mpp : microns per pixel, DEFAULT TO 1 because it is usually fine to use\r\n        pixels for this analysis\r\n    ensemble : boolean, defaults False\r\n    bins : integer or sequence\r\n        Specify a number of equally spaced bins, or explicitly specifiy a\r\n        sequence of bin edges. See np.histogram docs.\r\n\r\n    Returns\r\n    -------\r\n    vh : DataFrame or Series\r\n        If ensemble=True, a DataFrame with each particle's van Hove correlation\r\n        function, indexed by displacement. If ensemble=False, a Series with\r\n        the van Hove correlation function of the whole ensemble.\r\n\r\n    Examples\r\n    --------\r\n    >>> pos = traj.set_index(['frame', 'particle'])['x'].unstack() # particles as columns\r\n    >>> vh = vanhove(pos)\r\n    \"\"\"\r\n    # Reindex with consecutive frames, placing NaNs in the gaps.\r\n    pos = pos.reindex(np.arange(pos.index[0], 1 + pos.index[-1]))\r\n    assert lagtime <= pos.index.values.max(), \\\r\n        \"There is a no data out to frame %s. \" % pos.index.values.max()\r\n    disp = mpp*pos.sub(pos.shift(lagtime))\r\n    # Let np.histogram choose the best bins for all the data together.\r\n    values = disp.values.flatten()\r\n    values = values[np.isfinite(values)]\r\n    global_bins = np.histogram(values, bins=bins)[1]\r\n    # Use those bins to histogram each column by itself.\r\n    vh = disp.apply(\r\n        lambda x: Series(np.histogram(x, bins=global_bins, density=True)[0]))\r\n    vh.index = global_bins[:-1]\r\n    if ensemble:\r\n        return vh.sum(1)/len(vh.columns)\r\n    else:\r\n        return vh\r\n\r\n\r\ndef diagonal_size(single_trajectory, pos_columns=None, t_column='frame'):\r\n    \"\"\"Measure the diagonal size of a trajectory.\r\n\r\n    Parameters\r\n    ----------\r\n    single_trajectory : DataFrame containing a single trajectory\r\n    pos_columns = list\r\n        names of column with position ['x', 'y']\r\n    t_column = 'frame'\r\n\r\n    Returns\r\n    -------\r\n    float : length of diangonal of rectangular box containing the trajectory\r\n\r\n    Examples\r\n    --------\r\n    >>> diagonal_size(single_trajectory)\r\n\r\n    >>> many_trajectories.groupby('particle').agg(tp.diagonal_size)\r\n\r\n    >>> many_trajectories.groupby('particle').filter(lambda x: tp.diagonal_size(x) > 5)\r\n    \"\"\"\r\n    if pos_columns is None:\r\n        pos_columns = ['x', 'y']\r\n    pos = single_trajectory.set_index(t_column)[pos_columns]\r\n    return np.sqrt(np.sum(pos.apply(np.ptp)**2))\r\n\r\n\r\ndef is_localized(traj, threshold=0.4):\r\n    raise NotImplementedError(\"This function has been removed.\")\r\n\r\n\r\ndef is_diffusive(traj, threshold=0.9):\r\n    raise NotImplementedError(\"This function has been removed.\")\r\n\r\n\r\ndef relate_frames(t, frame1, frame2, pos_columns=None):\r\n    \"\"\"Find the displacement vector of all particles between two frames.\r\n\r\n    Parameters\r\n    ----------\r\n    t : DataFrame\r\n        trajectories\r\n    pos_columns = list\r\n        names of column with position ['x', 'y']\r\n    frame1 : integer\r\n    frame2 : integer\r\n\r\n    Returns\r\n    -------\r\n    DataFrame\r\n        indexed by particle, containing:\r\n        x, y, etc. (corresponding to frame1)\r\n        x_b, y_b, etc. (corresponding to frame2)\r\n        dx, dy, etc.", "start_char_idx": 13079, "end_char_idx": 17020, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eb670015-50de-45f3-87d3-9a81932f56ba": {"__data__": {"id_": "eb670015-50de-45f3-87d3-9a81932f56ba", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04960000-bdbb-4945-9b63-1b573c1547ff", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d974dcb70743ac7bb2dd502589feb63b5437683b542353158ad07a9c047e8950", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "84651a80-f1ca-469f-a720-0323ac01dfa2", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "06a9c6a607ddf81d98dbde9859069d20cefb1accb7c013a339b7a41e1136a03c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "065feb0e-d739-455b-b15a-1c3f6009134c", "node_type": "1", "metadata": {}, "hash": "628f1d7184b91a20cd8c458b68fe3f4928d8a68f1c5b5952dff9d9485a922134", "class_name": "RelatedNodeInfo"}}, "text": "def is_diffusive(traj, threshold=0.9):\r\n    raise NotImplementedError(\"This function has been removed.\")\r\n\r\n\r\ndef relate_frames(t, frame1, frame2, pos_columns=None):\r\n    \"\"\"Find the displacement vector of all particles between two frames.\r\n\r\n    Parameters\r\n    ----------\r\n    t : DataFrame\r\n        trajectories\r\n    pos_columns = list\r\n        names of column with position ['x', 'y']\r\n    frame1 : integer\r\n    frame2 : integer\r\n\r\n    Returns\r\n    -------\r\n    DataFrame\r\n        indexed by particle, containing:\r\n        x, y, etc. (corresponding to frame1)\r\n        x_b, y_b, etc. (corresponding to frame2)\r\n        dx, dy, etc.\r\n        dr\r\n        direction (only if pos_columns=['x', 'y'])\r\n    \"\"\"\r\n    if pos_columns is None:\r\n        pos_columns = ['x', 'y']\r\n    a = t[t.frame == frame1]\r\n    b = t[t.frame == frame2]\r\n    j = a.set_index('particle')[pos_columns].join(\r\n         b.set_index('particle')[pos_columns], rsuffix='_b')\r\n    for pos in pos_columns:\r\n        j['d' + pos] = j[pos + '_b'] - j[pos]\r\n    j['dr'] = np.sqrt(np.sum([j['d' + pos]**2 for pos in pos_columns], 0))\r\n    if pos_columns == ['x', 'y']:\r\n        j['direction'] = np.arctan2(j.dy, j.dx)\r\n    return j\r\n\r\n\r\ndef direction_corr(t, frame1, frame2):\r\n    \"\"\"Compute the cosine between every pair of particles' displacements.\r\n\r\n    Parameters\r\n    ----------\r\n    t : DataFrame\r\n        trajectories, containing columns particle, frame, x, and y\r\n    frame1 : frame number\r\n    frame2 : frame number\r\n\r\n    Returns\r\n    -------\r\n    DataFrame for all particle pairs, including dx, dy, and direction\r\n    \"\"\"\r\n    j = relate_frames(t, frame1, frame2)\r\n    cosine = np.cos(np.subtract.outer(j.direction.values, j.direction.values))\r\n    r = np.sqrt(np.subtract.outer(j.x.values, j.x.values)**2 +\r\n                np.subtract.outer(j.y.values, j.y.values)**2)\r\n    upper_triangle = np.triu_indices_from(r, 1)\r\n    result = DataFrame({'r': r[upper_triangle],\r\n                        'cos': cosine[upper_triangle]})\r\n    return result\r\n\r\n\r\ndef velocity_corr(t, frame1, frame2):\r\n    \"\"\"Compute the velocity correlation between\r\n    every pair of particles' displacements.\r\n\r\n    Parameters\r\n    ----------\r\n    t : DataFrame\r\n        trajectories, containing columns particle, frame, x, and y\r\n    frame1 : frame number\r\n    frame2 : frame number\r\n\r\n    Returns\r\n    -------\r\n    DataFrame, indexed by particle, including dx, dy, and direction\r\n    \"\"\"\r\n    j = relate_frames(t, frame1, frame2)\r\n    cosine = np.cos(np.subtract.outer(j.direction.values, j.direction.values))\r\n    r = np.sqrt(np.subtract.outer(j.x.values, j.x.values)**2 +\r\n                np.subtract.outer(j.y.values, j.y.values)**2)\r\n    dot_product = cosine*np.abs(np.multiply.outer(j.dr.values, j.dr.values))\r\n    upper_triangle = np.triu_indices_from(r, 1)\r\n    result = DataFrame({'r': r[upper_triangle],\r\n                        'dot_product': dot_product[upper_triangle]})\r\n    return result\r\n\r\n\r\ndef theta_entropy(pos, bins=24, plot=True):\r\n    \"\"\"Plot the distribution of directions and return its Shannon entropy.\r\n\r\n    Parameters\r\n    ----------\r\n    pos : DataFrame with columns x and y, indexed by frame\r\n    bins : number of equally-spaced bins in distribution. Default 24.\r\n    plot : plot direction histogram if True\r\n\r\n    Returns\r\n    -------\r\n    float : Shannon entropy\r\n\r\n    Examples\r\n    --------\r\n    >>> theta_entropy(t[t['particle'] == 3].set_index('frame'))\r\n\r\n    >>> S = t.set_index('frame').groupby('particle').apply(tp.theta_entropy)\r\n    \"\"\"\r\n\r\n    disp = pos - pos.shift(1)\r\n    direction = np.arctan2(disp['y'], disp['x'])\r\n    bins = np.linspace(-np.pi, np.pi, bins + 1)\r\n    if plot:\r\n        Series(direction).hist(bins=bins)\r\n    return shannon_entropy(direction.dropna(), bins)\r\n\r\n\r\ndef shannon_entropy(x, bins):\r\n    \"\"\"Compute the Shannon entropy of the distribution of x.\"\"\"\r\n    hist = np.histogram(x, bins)[0]\r\n    hist = hist.astype('float64')/hist.sum()  # normalize probablity dist.", "start_char_idx": 16385, "end_char_idx": 20369, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "065feb0e-d739-455b-b15a-1c3f6009134c": {"__data__": {"id_": "065feb0e-d739-455b-b15a-1c3f6009134c", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04960000-bdbb-4945-9b63-1b573c1547ff", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d974dcb70743ac7bb2dd502589feb63b5437683b542353158ad07a9c047e8950", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "eb670015-50de-45f3-87d3-9a81932f56ba", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "87110de9d34b6326d83e14f61f7d4c4412d5b1e8ead930d6ff6caf8d80bd738b", "class_name": "RelatedNodeInfo"}}, "text": "Default 24.\r\n    plot : plot direction histogram if True\r\n\r\n    Returns\r\n    -------\r\n    float : Shannon entropy\r\n\r\n    Examples\r\n    --------\r\n    >>> theta_entropy(t[t['particle'] == 3].set_index('frame'))\r\n\r\n    >>> S = t.set_index('frame').groupby('particle').apply(tp.theta_entropy)\r\n    \"\"\"\r\n\r\n    disp = pos - pos.shift(1)\r\n    direction = np.arctan2(disp['y'], disp['x'])\r\n    bins = np.linspace(-np.pi, np.pi, bins + 1)\r\n    if plot:\r\n        Series(direction).hist(bins=bins)\r\n    return shannon_entropy(direction.dropna(), bins)\r\n\r\n\r\ndef shannon_entropy(x, bins):\r\n    \"\"\"Compute the Shannon entropy of the distribution of x.\"\"\"\r\n    hist = np.histogram(x, bins)[0]\r\n    hist = hist.astype('float64')/hist.sum()  # normalize probablity dist.\r\n    with np.errstate(all='ignore'):\r\n        entropy = -np.sum(np.nan_to_num(hist*np.log(hist)))\r\n    return entropy\r\n\r\n\r\ndef min_rolling_theta_entropy(pos, window=24, bins=24):\r\n    \"\"\"Compute the minimum Shannon entropy in any window.\r\n\r\n    Parameters\r\n    ----------\r\n    pos : DataFrame with columns x and y, indexed by frame\r\n    window : number of observations per window\r\n    bins : number of equally-spaced bins in distribution. Default 24.\r\n\r\n    Returns\r\n    -------\r\n    float : Shannon entropy\r\n\r\n    Examples\r\n    --------\r\n    >>> theta_entropy(t[t['particle'] == 3].set_index('frame'))\r\n\r\n    >>> S = t.set_index('frame').groupby('particle').apply(\r\n    ...     tp.min_rolling_theta_entropy)\r\n    \"\"\"\r\n\r\n    disp = pos - pos.shift(1)\r\n    direction = np.arctan2(disp['y'], disp['x'])\r\n    bins = np.linspace(-np.pi, np.pi, bins + 1)\r\n    f = lambda x: shannon_entropy(x, bins)\r\n    return pd.rolling_apply(direction.dropna(), window, f).min()\r\n\r\n\r\ndef proximity(*args, **kwargs):\r\n    \"\"\"\r\n    Deprecated\r\n\r\n    See also\r\n    --------\r\n    trackpy.static.proximity\r\n    \"\"\"\r\n    warn('This function has been moved to `trackpy.static', DeprecationWarning)\r\n    from trackpy.static import proximity\r\n    return proximity(*args, **kwargs)", "start_char_idx": 19616, "end_char_idx": 21622, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "adb90f85-b90a-40bd-99f9-d0d3dd1d2166": {"__data__": {"id_": "adb90f85-b90a-40bd-99f9-d0d3dd1d2166", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "398b5d0b-9007-47da-b894-fa0ab1e4a092", "node_type": "1", "metadata": {}, "hash": "02a9ebba254a5827d0e183f56016502ca6c9d71eb1b91fa687ce971e8e65699f", "class_name": "RelatedNodeInfo"}}, "text": "\"\"\"These functions generate handy plots.\"\"\"\r\nfrom collections.abc import Iterable\r\nfrom itertools import tee\r\nfrom functools import wraps\r\nimport warnings\r\nimport logging\r\n\r\nimport numpy as np\r\n\r\ntry:\r\n    from pims import plot_to_frame, plots_to_frame, normalize\r\nexcept ImportError:\r\n    plot_to_frame = None\r\n    plots_to_frame = None\r\n    normalize = None\r\n\r\n\r\n__all__ = ['annotate', 'scatter', 'plot_traj', 'ptraj',\r\n           'annotate3d', 'scatter3d', 'plot_traj3d', 'ptraj3d',\r\n           'plot_displacements', 'subpx_bias', 'mass_size', 'mass_ecc',\r\n           'plot_density_profile']\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\n\r\ndef make_axes(func):\r\n    \"\"\"\r\n    A decorator for plotting functions.\r\n    NORMALLY: Direct the plotting function to the current axes, gca().\r\n              When it's done, make the legend and show that plot.\r\n              (Instant gratificaiton!) The axes have to be 2d or else the\r\n              current figure will be cleared.\r\n    BUT:      If the uses passes axes to plotting function, write on those axes\r\n              and return them. The user has the option to draw a more complex\r\n              plot in multiple steps.\r\n    \"\"\"\r\n    @wraps(func)\r\n    def wrapper(*args, **kwargs):\r\n        import matplotlib.pyplot as plt\r\n        if kwargs.get('ax') is None:\r\n            kwargs['ax'] = plt.gca()\r\n            # show plot unless the matplotlib backend is headless\r\n            show_plot = (plt.get_backend() != \"agg\")\r\n        else:\r\n            show_plot = False\r\n\r\n        # Delete legend keyword so remaining ones can be passed to plot().\r\n        legend = kwargs.pop('legend', False)\r\n\r\n        result = func(*args, **kwargs)\r\n\r\n        if legend:\r\n            handles, labels = kwargs['ax'].get_legend_handles_labels()\r\n            if len(labels) > 0:\r\n                kwargs['ax'].legend(handles, labels, loc='best')\r\n\r\n        if show_plot:\r\n            plt.show()\r\n\r\n        return result\r\n    return wrapper\r\n\r\n\r\ndef make_axes3d(func):\r\n    \"\"\"\r\n    A decorator for plotting 3d functions.\r\n    NORMALLY: Direct the plotting function to the current axes, gca().\r\n              When it's done, make the legend and show that plot.\r\n              (Instant gratificaiton!) The axes have to be 3d or else the\r\n              current figure will be cleared.\r\n    BUT:      If the uses passes axes to plotting function, write on those axes\r\n              and return them. The user has the option to draw a more complex\r\n              plot in multiple steps.\r\n    \"\"\"\r\n    @wraps(func)\r\n    def wrapper(*args, **kwargs):\r\n        import matplotlib.pyplot as plt\r\n        from mpl_toolkits.mplot3d import Axes3D\r\n\r\n        if kwargs.get('ax') is None:\r\n            if not hasattr(plt.gca(), 'zaxis'):\r\n                plt.figure()  # initialize new Fig when current axis is not 3d\r\n            kwargs['ax'] = plt.gca(projection='3d')\r\n            show_plot = True\r\n        else:\r\n            if not hasattr(plt.gca(), 'zaxis'):\r\n                raise ValueError(\"The provided axis object is not 3d. Please \"\r\n                                 \"consult the mplot3d documentation.\")\r\n            show_plot = False\r\n\r\n        # Delete legend keyword so remaining ones can be passed to plot().\r\n        legend = kwargs.pop('legend', False)\r\n\r\n        result = func(*args, **kwargs)\r\n\r\n        if legend:\r\n            handles, labels = kwargs['ax'].get_legend_handles_labels()\r\n            if len(labels) > 0:\r\n                kwargs['ax'].legend(handles, labels, loc='best')\r\n\r\n        if show_plot:\r\n            plt.show()\r\n\r\n        return result\r\n    return wrapper\r\n\r\n\r\ndef make_fig(func):\r\n    \"\"\"See make_axes.\"\"\"\r\n    import matplotlib.pyplot as plt\r\n    @wraps(func)\r\n    def wrapper(*args, **kwargs):\r\n        if 'fig' not in kwargs:\r\n            kwargs['fig'] = plt.gcf()\r\n            func(*args, **kwargs)\r\n            plt.show()\r\n        else:\r\n            return func(*args, **kwargs)\r\n    return wrapper\r\n\r\n\r\ndef invert_yaxis(ax):\r\n    \"\"\"Inverts the y-axis of an axis object.\"\"\"\r\n    bottom, top = ax.get_ylim()\r\n    if top > bottom:\r\n        ax.set_ylim(top, bottom, auto=None)\r\n    return ax\r\n\r\n\r\ndef _plot(ax, coords, pos_columns, **plot_style):\r\n    \"\"\" This function wraps Axes.plot to make its call signature the same for\r\n    2D and 3D plotting. The y axis is inverted for 2D plots, but not for 3D\r\n    plots.", "start_char_idx": 0, "end_char_idx": 4377, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "398b5d0b-9007-47da-b894-fa0ab1e4a092": {"__data__": {"id_": "398b5d0b-9007-47da-b894-fa0ab1e4a092", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "adb90f85-b90a-40bd-99f9-d0d3dd1d2166", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "8d5ed17e384fa5b6ed6c9223aa1aa79f0ac9618b5562327c477564dcd6e13a22", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "bd877776-d1ba-4c2a-8182-cf6857fe1788", "node_type": "1", "metadata": {}, "hash": "2f066a1c414258dcfb7ebcaedb7fae1f027d1203e7c0ddbbbc4370f11ce13d52", "class_name": "RelatedNodeInfo"}}, "text": "import matplotlib.pyplot as plt\r\n    @wraps(func)\r\n    def wrapper(*args, **kwargs):\r\n        if 'fig' not in kwargs:\r\n            kwargs['fig'] = plt.gcf()\r\n            func(*args, **kwargs)\r\n            plt.show()\r\n        else:\r\n            return func(*args, **kwargs)\r\n    return wrapper\r\n\r\n\r\ndef invert_yaxis(ax):\r\n    \"\"\"Inverts the y-axis of an axis object.\"\"\"\r\n    bottom, top = ax.get_ylim()\r\n    if top > bottom:\r\n        ax.set_ylim(top, bottom, auto=None)\r\n    return ax\r\n\r\n\r\ndef _plot(ax, coords, pos_columns, **plot_style):\r\n    \"\"\" This function wraps Axes.plot to make its call signature the same for\r\n    2D and 3D plotting. The y axis is inverted for 2D plots, but not for 3D\r\n    plots.\r\n\r\n    Parameters\r\n    ----------\r\n    ax : Axes object\r\n        The axes object on which the plot will be called\r\n    coords : DataFrame\r\n        DataFrame of coordinates that will be plotted\r\n    pos_columns : list of strings\r\n        List of column names in x, y(, z) order.\r\n    plot_style : keyword arguments\r\n        Keyword arguments passed through to the `Axes.plot(...)` method\r\n\r\n    Returns\r\n    -------\r\n    Axes object\r\n    \"\"\"\r\n    if len(pos_columns) == 3:\r\n        return ax.plot(coords[pos_columns[0]], coords[pos_columns[1]],\r\n                       zs=coords[pos_columns[2]], **plot_style)\r\n    elif len(pos_columns) == 2:\r\n        return ax.plot(coords[pos_columns[0]], coords[pos_columns[1]],\r\n                       **plot_style)\r\n\r\n\r\ndef _set_labels(ax, label_format, pos_columns):\r\n    \"\"\"This sets axes labels according to a label format and position column\r\n    names. Applicable to 2D and 3D plotting.\r\n\r\n    Parameters\r\n    ----------\r\n    ax : Axes object\r\n        The axes object on which the plot will be called\r\n    label_format : string\r\n        Format that is compatible with ''.format (e.g.: '{} px')\r\n    pos_columns : list of strings\r\n        List of column names in x, y(, z) order.\r\n\r\n    Returns\r\n    -------\r\n    None\r\n    \"\"\"\r\n    ax.set_xlabel(label_format.format(pos_columns[0]))\r\n    ax.set_ylabel(label_format.format(pos_columns[1]))\r\n    if hasattr(ax, 'set_zlabel') and len(pos_columns) > 2:\r\n        ax.set_zlabel(label_format.format(pos_columns[2]))\r\n\r\n\r\n@make_axes\r\ndef scatter(centroids, mpp=None, cmap=None, ax=None, pos_columns=None,\r\n            plot_style={}):\r\n    \"\"\"Scatter plot of all particles.\r\n\r\n    Parameters\r\n    ----------\r\n    centroids : DataFrame\r\n        The DataFrame should include time and spatial coordinate columns.\r\n    mpp : float, optional\r\n        Microns per pixel. If omitted, the labels will have units of pixels.\r\n    cmap : colormap, optional\r\n        This is only used in colorby='frame' mode. Default = mpl.cm.winter\r\n    ax : matplotlib axes object, optional\r\n        Defaults to current axes\r\n    pos_columns : list of strings, optional\r\n        Dataframe column names for spatial coordinates. Default is ['x', 'y'].\r\n\r\n    Returns\r\n    -------\r\n    Axes object\r\n    \r\n    See Also\r\n    --------\r\n    scatter3d : the 3D equivalent of `scatter`\r\n    \"\"\"\r\n    import matplotlib as mpl\r\n    import matplotlib.pyplot as plt\r\n\r\n    if cmap is None:\r\n        cmap = plt.cm.winter\r\n    if pos_columns is None:\r\n        pos_columns = ['x', 'y']\r\n    if len(centroids) == 0:\r\n        raise ValueError(\"DataFrame of centroids is empty.\")\r\n    _plot_style = dict(marker='o', linestyle='none')\r\n    _plot_style.update(**_normalize_kwargs(plot_style, 'line2d'))\r\n\r\n    # Axes labels\r\n    if mpp is None:\r\n        _set_labels(ax, '{} [px]', pos_columns)\r\n        mpp = 1.  # for computations of image extent below\r\n    else:\r\n        if mpl.rcParams['text.usetex']:\r\n            _set_labels(ax, r'{} [\\textmu m]', pos_columns)\r\n        else:\r\n            _set_labels(ax, r'{} [\\xb5m]', pos_columns)\r\n\r\n    _plot(ax, centroids, pos_columns, **_plot_style)\r\n    return invert_yaxis(ax)\r\n\r\n\r\n@make_axes3d\r\ndef scatter3d(*args, **kwargs):\r\n    \"\"\"The 3D equivalent of `scatter`.\r\n\r\n    Parameters\r\n    ----------\r\n    centroids : DataFrame\r\n        The DataFrame should include time and spatial coordinate columns.\r\n    mpp : float, optional\r\n        Microns per pixel. If omitted, the labels will have units of pixels.", "start_char_idx": 3671, "end_char_idx": 7868, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd877776-d1ba-4c2a-8182-cf6857fe1788": {"__data__": {"id_": "bd877776-d1ba-4c2a-8182-cf6857fe1788", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "398b5d0b-9007-47da-b894-fa0ab1e4a092", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e17baf45dc8a782a3b08f9d3420ba1eb77a5e72cda93f1905dc3f6828dfd8dd7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b9f62199-5805-4461-a2d5-67f69642edd4", "node_type": "1", "metadata": {}, "hash": "53fc1f800fa0ab12d853fb79e29b8bb49bca20105c63a45cde74c52827b4a2f8", "class_name": "RelatedNodeInfo"}}, "text": "# for computations of image extent below\r\n    else:\r\n        if mpl.rcParams['text.usetex']:\r\n            _set_labels(ax, r'{} [\\textmu m]', pos_columns)\r\n        else:\r\n            _set_labels(ax, r'{} [\\xb5m]', pos_columns)\r\n\r\n    _plot(ax, centroids, pos_columns, **_plot_style)\r\n    return invert_yaxis(ax)\r\n\r\n\r\n@make_axes3d\r\ndef scatter3d(*args, **kwargs):\r\n    \"\"\"The 3D equivalent of `scatter`.\r\n\r\n    Parameters\r\n    ----------\r\n    centroids : DataFrame\r\n        The DataFrame should include time and spatial coordinate columns.\r\n    mpp : float, optional\r\n        Microns per pixel. If omitted, the labels will have units of pixels.\r\n    cmap : colormap, optional\r\n        This is only used in colorby='frame' mode. Default = mpl.cm.winter\r\n    ax : matplotlib axes object, optional\r\n        Defaults to current axes\r\n    pos_columns : list of strings, optional\r\n        Dataframe column names for spatial coords. Default is ['x', 'y', 'z'].\r\n\r\n    Returns\r\n    -------\r\n    Axes object\r\n    \r\n    See Also\r\n    --------\r\n    scatter : the 2D equivalent of `scatter3d`\r\n    \"\"\"\r\n    if kwargs.get('pos_columns') is None:\r\n        kwargs['pos_columns'] = ['x', 'y', 'z']\r\n    return scatter(*args, **kwargs)\r\n\r\n\r\n@make_axes\r\ndef plot_traj(traj, colorby='particle', mpp=None, label=False,\r\n              superimpose=None, cmap=None, ax=None, t_column=None,\r\n              pos_columns=None, plot_style={}, **kwargs):\r\n    \"\"\"Plot traces of trajectories for each particle.\r\n    Optionally superimpose it on a frame from the video.\r\n\r\n    Parameters\r\n    ----------\r\n    traj : DataFrame\r\n        The DataFrame should include time and spatial coordinate columns.\r\n    colorby : {'particle', 'frame'}, optional\r\n    mpp : float, optional\r\n        Microns per pixel. If omitted, the labels will have units of pixels.\r\n    label : boolean, optional\r\n        Set to True to write particle ID numbers next to trajectories.\r\n    superimpose : ndarray, optional\r\n        Background image, default None\r\n    cmap : colormap, optional\r\n        This is only used in colorby='frame' mode. Default = mpl.cm.winter\r\n    ax : matplotlib axes object, optional\r\n        Defaults to current axes\r\n    t_column : string, optional\r\n        DataFrame column name for time coordinate. Default is 'frame'.\r\n    pos_columns : list of strings, optional\r\n        Dataframe column names for spatial coordinates. Default is ['x', 'y'].\r\n    plot_style : dictionary\r\n        Keyword arguments passed through to the `Axes.plot(...)` command\r\n\r\n    Returns\r\n    -------\r\n    Axes object\r\n    \r\n    See Also\r\n    --------\r\n    plot_traj3d : the 3D equivalent of `plot_traj`\r\n    \"\"\"\r\n    import matplotlib as mpl\r\n    import matplotlib.pyplot as plt\r\n    from matplotlib.collections import LineCollection\r\n\r\n    if cmap is None:\r\n        cmap = plt.cm.winter\r\n    if t_column is None:\r\n        t_column = 'frame'\r\n    if pos_columns is None:\r\n        pos_columns = ['x', 'y']\r\n    if len(traj) == 0:\r\n        raise ValueError(\"DataFrame of trajectories is empty.\")\r\n    _plot_style = dict(linewidth=1)\r\n    _plot_style.update(**_normalize_kwargs(plot_style, 'line2d'))\r\n\r\n    # Axes labels\r\n    if mpp is None:\r\n        _set_labels(ax, '{} [px]', pos_columns)\r\n        mpp = 1.  # for computations of image extent below\r\n    else:\r\n        if mpl.rcParams['text.usetex']:\r\n            _set_labels(ax, r'{} [\\textmu m]', pos_columns)\r\n        else:\r\n            _set_labels(ax, r'{} [\\xb5m]', pos_columns)\r\n    # Background image\r\n    if superimpose is not None:\r\n        ax.imshow(superimpose, cmap=plt.cm.gray,\r\n                  origin='lower', interpolation='nearest',\r\n                  vmin=kwargs.get('vmin'), vmax=kwargs.get('vmax'))\r\n        ax.set_xlim(-0.5 * mpp, (superimpose.shape[1] - 0.5) * mpp)\r\n        ax.set_ylim(-0.5 * mpp, (superimpose.shape[0] - 0.5) * mpp)\r\n    # Trajectories\r\n    if colorby == 'particle':\r\n        # Unstack particles into columns.", "start_char_idx": 7226, "end_char_idx": 11172, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b9f62199-5805-4461-a2d5-67f69642edd4": {"__data__": {"id_": "b9f62199-5805-4461-a2d5-67f69642edd4", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bd877776-d1ba-4c2a-8182-cf6857fe1788", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cb4615d0e5f5fd30aae4d6d801bc51d0208d4549da201cfec360a7d58158cc4e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "564888d8-ef72-4be8-8c44-ed42371db73d", "node_type": "1", "metadata": {}, "hash": "f9d80097a16f1778372b5311328f527cb615e1ca23ac26c3126f733a5b184b7f", "class_name": "RelatedNodeInfo"}}, "text": "# for computations of image extent below\r\n    else:\r\n        if mpl.rcParams['text.usetex']:\r\n            _set_labels(ax, r'{} [\\textmu m]', pos_columns)\r\n        else:\r\n            _set_labels(ax, r'{} [\\xb5m]', pos_columns)\r\n    # Background image\r\n    if superimpose is not None:\r\n        ax.imshow(superimpose, cmap=plt.cm.gray,\r\n                  origin='lower', interpolation='nearest',\r\n                  vmin=kwargs.get('vmin'), vmax=kwargs.get('vmax'))\r\n        ax.set_xlim(-0.5 * mpp, (superimpose.shape[1] - 0.5) * mpp)\r\n        ax.set_ylim(-0.5 * mpp, (superimpose.shape[0] - 0.5) * mpp)\r\n    # Trajectories\r\n    if colorby == 'particle':\r\n        # Unstack particles into columns.\r\n        unstacked = traj.set_index(['particle', t_column])[pos_columns].unstack()\r\n        for i, trajectory in unstacked.iterrows():\r\n            _plot(ax, mpp*trajectory, pos_columns, **_plot_style)\r\n    if colorby == 'frame':\r\n        # Read http://www.scipy.org/Cookbook/Matplotlib/MulticoloredLine\r\n        x = traj.set_index([t_column, 'particle'])['x'].unstack()\r\n        y = traj.set_index([t_column, 'particle'])['y'].unstack()\r\n        color_numbers = traj[t_column].values/float(traj[t_column].max())\r\n        logger.info(\"Drawing multicolor lines takes awhile. \"\r\n                    \"Come back in a minute.\")\r\n        for particle in x:\r\n            points = np.array(\r\n                [x[particle].values, y[particle].values]).T.reshape(-1, 1, 2)\r\n            segments = np.concatenate([points[:-1], points[1:]], axis=1)\r\n            lc = LineCollection(segments, cmap=cmap)\r\n            lc.set_array(color_numbers)\r\n            ax.add_collection(lc)\r\n            ax.set_xlim(x.apply(np.min).min(), x.apply(np.max).max())\r\n            ax.set_ylim(y.apply(np.min).min(), y.apply(np.max).max())\r\n    if label:\r\n        unstacked = traj.set_index([t_column, 'particle'])[pos_columns].unstack()\r\n        first_frame = int(traj[t_column].min())\r\n        coords = unstacked.fillna(method='backfill').stack().loc[first_frame]\r\n        for particle_id, coord in coords.iterrows():\r\n            ax.text(*coord.tolist(), s=\"%d\" % particle_id,\r\n                    horizontalalignment='center',\r\n                    verticalalignment='center')\r\n    return invert_yaxis(ax)\r\n\r\nptraj = plot_traj  # convenience alias\r\n\r\n@make_axes3d\r\ndef plot_traj3d(*args, **kwargs):\r\n    \"\"\"The 3D equivalent of `plot_traj`.\r\n    \r\n    Parameters\r\n    ----------\r\n    traj : DataFrame\r\n        The DataFrame should include time and spatial coordinate columns.\r\n    mpp : float, optional\r\n        Microns per pixel. If omitted, the labels will have units of pixels.\r\n    label : boolean, optional\r\n        Set to True to write particle ID numbers next to trajectories.\r\n    superimpose : ndarray, optional\r\n        Background image, default None\r\n    cmap : colormap, optional\r\n        This is only used in colorby='frame' mode. Default = mpl.cm.winter\r\n    ax : matplotlib axes object, optional\r\n        Defaults to current axes\r\n    t_column : string, optional\r\n        DataFrame column name for time coordinate. Default is 'frame'.\r\n    pos_columns : list of strings, optional\r\n        Dataframe column names for spatial coords. Default is ['x', 'y', 'z'].\r\n    plot_style : dictionary\r\n        Keyword arguments passed through to the `Axes.plot(...)` command\r\n\r\n    Returns\r\n    -------\r\n    Axes object\r\n\r\n    See Also\r\n    --------\r\n    plot_traj : plot 2D trajectories\"\"\"\r\n\r\n    if kwargs.get('pos_columns') is None:\r\n        kwargs['pos_columns'] = ['x', 'y', 'z']\r\n    if kwargs.get('colorby') == 'frame':\r\n        raise NotImplemented(\"3d trajectory plots cannot be colored by frame\")\r\n    return plot_traj(*args, **kwargs)\r\n\r\nptraj3d = plot_traj3d\r\n\r\n@make_axes\r\ndef annotate(centroids, image, circle_size=None, color=None,\r\n             invert=False, ax=None, split_category=None, split_thresh=None,\r\n             imshow_style={}, plot_style={}):\r\n    \"\"\"Mark identified features with white circles.\r\n\r\n    Parameters\r\n    ----------\r\n    centroids : DataFrame including columns x and y\r\n    image : image array (or string path to image file)\r\n    circle_size : Deprecated.", "start_char_idx": 10479, "end_char_idx": 14644, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "564888d8-ef72-4be8-8c44-ed42371db73d": {"__data__": {"id_": "564888d8-ef72-4be8-8c44-ed42371db73d", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b9f62199-5805-4461-a2d5-67f69642edd4", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "66029d7ec1bfa58b270503614caef627d0f5dff8ceb3ef4356e9f75282d20a05", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a260fdeb-846a-470b-9d3b-1e1d7e53bb34", "node_type": "1", "metadata": {}, "hash": "dd00dd6a0e976a4072972699056b4df011813eea24aa085d10bc5f740322c77b", "class_name": "RelatedNodeInfo"}}, "text": "Parameters\r\n    ----------\r\n    centroids : DataFrame including columns x and y\r\n    image : image array (or string path to image file)\r\n    circle_size : Deprecated.\r\n        This will be removed in a future version of trackpy.\r\n        Use `plot_style={'markersize': ...}` instead.\r\n    color : single matplotlib color or a list of multiple colors\r\n        default None\r\n    invert : If you give a filepath as the image, specify whether to invert\r\n        black and white. Default True.\r\n    ax : matplotlib axes object, defaults to current axes\r\n    split_category : string, parameter to use to split the data into sections\r\n        default None\r\n    split_thresh : single value or list of ints or floats to split\r\n        particles into sections for plotting in multiple colors.\r\n        List items should be ordered by increasing value.\r\n        default None\r\n    imshow_style : dictionary of keyword arguments passed through to\r\n        the `Axes.imshow(...)` command the displays the image\r\n    plot_style : dictionary of keyword arguments passed through to\r\n        the `Axes.plot(...)` command that marks the features\r\n\r\n    Returns\r\n    -------\r\n    Axes object\r\n    \r\n    See Also\r\n    --------\r\n    annotate3d : The 3D equivalent that returns a scrollable stack.\r\n    \"\"\"\r\n    import matplotlib.pyplot as plt\r\n\r\n    if image.ndim != 2 and not (image.ndim == 3 and image.shape[-1] in (3, 4)):\r\n        raise ValueError(\"image has incorrect dimensions. Please input a 2D \"\r\n                         \"grayscale or RGB(A) image. For 3D image annotation, \"\r\n                         \"use annotate3d. Multichannel images can be \"\r\n                         \"converted to RGB using pims.display.to_rgb.\")\r\n\r\n    if circle_size is not None:\r\n        warnings.warn(\"circle_size will be removed in future version of \"\r\n                      \"trackpy. Use plot_style={'markersize': ...} instead.\")\r\n        if 'marker_size' not in plot_style:\r\n            plot_style['marker_size'] = np.sqrt(circle_size)  # area vs. dia.\r\n        else:\r\n            raise ValueError(\"passed in both 'marker_size' and 'circle_size'\")\r\n\r\n    _plot_style = dict(markersize=15, markeredgewidth=2,\r\n                       markerfacecolor='none', markeredgecolor='r',\r\n                       marker='o', linestyle='none')\r\n    _plot_style.update(**_normalize_kwargs(plot_style, 'line2d'))\r\n    _imshow_style = dict(origin='lower', interpolation='nearest',\r\n                         cmap=plt.cm.gray)\r\n    _imshow_style.update(imshow_style)\r\n\r\n    # https://docs.python.org/2/library/itertools.html\r\n    def pairwise(iterable):\r\n        \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\r\n        a, b = tee(iterable)\r\n        next(b, None)\r\n        return zip(a, b)\r\n\r\n    if color is None:\r\n        color = ['r']\r\n    if isinstance(color, str):\r\n        color = [color]\r\n    if not isinstance(split_thresh, Iterable):\r\n        split_thresh = [split_thresh]\r\n\r\n    # The parameter image can be an image object or a filename.", "start_char_idx": 14478, "end_char_idx": 17468, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a260fdeb-846a-470b-9d3b-1e1d7e53bb34": {"__data__": {"id_": "a260fdeb-846a-470b-9d3b-1e1d7e53bb34", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "564888d8-ef72-4be8-8c44-ed42371db73d", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "1c39eb69105c245c0b1b64dedbfb1ada41c4c09dacaf050825cd1598cfc9dc8a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2115b34a-a52e-4c77-8f05-1354636b69ff", "node_type": "1", "metadata": {}, "hash": "58fd2ff7202c5545bb2a1b68f4a1a77a381fc96fde5f9d24062cc44e7fa4058b", "class_name": "RelatedNodeInfo"}}, "text": "if isinstance(image, str):\r\n        image = plt.imread(image)\r\n    if invert:\r\n        ax.imshow(1-image, **_imshow_style)\r\n    else:\r\n        ax.imshow(image, **_imshow_style)\r\n    ax.set_xlim(-0.5, image.shape[1] - 0.5)\r\n    ax.set_ylim(-0.5, image.shape[0] - 0.5)\r\n\r\n    if split_category is None:\r\n        if np.size(color) > 1:\r\n            raise ValueError(\"multiple colors specified, no split category \"\r\n                             \"specified\")\r\n        _plot_style.update(markeredgecolor=color[0])\r\n        ax.plot(centroids['x'], centroids['y'],\r\n                **_plot_style)\r\n    else:\r\n        if len(color) != len(split_thresh) + 1:\r\n            raise ValueError(\"number of colors must be number of thresholds \"\r\n                             \"plus 1\")\r\n        low = centroids[split_category] < split_thresh[0]\r\n        _plot_style.update(markeredgecolor=color[0])\r\n        ax.plot(centroids['x'][low], centroids['y'][low],\r\n                **_plot_style)\r\n\r\n        for c, (bot, top) in zip(color[1:-1], pairwise(split_thresh)):\r\n            indx = ((centroids[split_category] >= bot) &\r\n                    (centroids[split_category] < top))\r\n            _plot_style.update(markeredgecolor=c)\r\n            ax.plot(centroids['x'][indx], centroids['y'][indx],\r\n                    **_plot_style)\r\n\r\n        high = centroids[split_category] >= split_thresh[-1]\r\n        _plot_style.update(markeredgecolor=color[-1])\r\n        ax.plot(centroids['x'][high], centroids['y'][high],\r\n                **_plot_style)\r\n    return invert_yaxis(ax)\r\n\r\n\r\ndef annotate3d(centroids, image, **kwargs):\r\n    \"\"\"Annotates a 3D image and returns a scrollable stack for display in\r\n    IPython.\r\n    \r\n    Parameters\r\n    ----------\r\n    centroids : DataFrame including columns x and y\r\n    image : image array (or string path to image file)\r\n    circle_size : Deprecated.\r\n        This will be removed in a future version of trackpy.\r\n        Use `plot_style={'markersize': ...}` instead.\r\n    color : single matplotlib color or a list of multiple colors\r\n        default None\r\n    invert : If you give a filepath as the image, specify whether to invert\r\n        black and white. Default True.\r\n    ax : matplotlib axes object, defaults to current axes\r\n    split_category : string, parameter to use to split the data into sections\r\n        default None\r\n    split_thresh : single value or list of ints or floats to split\r\n        particles into sections for plotting in multiple colors.\r\n        List items should be ordered by increasing value.\r\n        default None\r\n    imshow_style : dictionary of keyword arguments passed through to\r\n        the `Axes.imshow(...)` command the displays the image\r\n    plot_style : dictionary of keyword arguments passed through to\r\n        the `Axes.plot(...)` command that marks the features\r\n\r\n    Returns\r\n    -------\r\n    pims.Frame object containing a three-dimensional RGBA image\r\n\r\n    See Also\r\n    --------\r\n    annotate : annotation of 2D images\r\n    \"\"\"\r\n    if plots_to_frame is None:\r\n        raise ImportError('annotate3d requires pims 0.3 or later. Please '\r\n                          'install/update pims')\r\n\r\n    import matplotlib as mpl\r\n    import matplotlib.pyplot as plt\r\n\r\n    if image.ndim != 3 and not (image.ndim == 4 and image.shape[-1] in (3, 4)):\r\n        raise ValueError(\"image has incorrect dimensions. Please input a 3D \"\r\n                         \"grayscale or RGB(A) image. For 2D image annotation, \"\r\n                         \"use annotate. Multichannel images can be \"\r\n                         \"converted to RGB using pims.display.to_rgb.\")\r\n\r\n    # We want to normalize on the full image and stop imshow from normalizing.", "start_char_idx": 17474, "end_char_idx": 21169, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2115b34a-a52e-4c77-8f05-1354636b69ff": {"__data__": {"id_": "2115b34a-a52e-4c77-8f05-1354636b69ff", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a260fdeb-846a-470b-9d3b-1e1d7e53bb34", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "f6a04a38ef8e66dc905237ccb65094cbc9dcede7a7c8576da2fe18f80bb519ca", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a43c2e60-0840-4ea9-9115-d5d3f2bf2a1c", "node_type": "1", "metadata": {}, "hash": "0f2f04ea4d8b5c0f0cffe9ed9e8d931f4b3e176aaf6b0a691d1a5e74de13b860", "class_name": "RelatedNodeInfo"}}, "text": "Please '\r\n                          'install/update pims')\r\n\r\n    import matplotlib as mpl\r\n    import matplotlib.pyplot as plt\r\n\r\n    if image.ndim != 3 and not (image.ndim == 4 and image.shape[-1] in (3, 4)):\r\n        raise ValueError(\"image has incorrect dimensions. Please input a 3D \"\r\n                         \"grayscale or RGB(A) image. For 2D image annotation, \"\r\n                         \"use annotate. Multichannel images can be \"\r\n                         \"converted to RGB using pims.display.to_rgb.\")\r\n\r\n    # We want to normalize on the full image and stop imshow from normalizing.\r\n    normalized = (normalize(image) * 255).astype(np.uint8)\r\n    imshow_style = dict(vmin=0, vmax=255)\r\n    if '_imshow_style' in kwargs:\r\n        kwargs['imshow_style'].update(imshow_style)\r\n    else:\r\n        kwargs['imshow_style'] = imshow_style\r\n\r\n    max_open_warning = mpl.rcParams['figure.max_open_warning']\r\n    was_interactive = plt.isinteractive()\r\n    try:\r\n        # Suppress warning when many figures are opened\r\n        mpl.rc('figure', max_open_warning=0)\r\n        # Turn off interactive mode (else the closed plots leave emtpy space)\r\n        plt.ioff()\r\n\r\n        figures = [None] * len(normalized)\r\n        for i, imageZ in enumerate(normalized):\r\n            fig = plt.figure()\r\n            kwargs['ax'] = fig.gca()\r\n            centroidsZ = centroids[(centroids['z'] > i - 0.5) &\r\n                                   (centroids['z'] < i + 0.5)]\r\n            annotate(centroidsZ, imageZ, **kwargs)\r\n            figures[i] = fig\r\n\r\n        result = plots_to_frame(figures, width=512, close_fig=True,\r\n                                bbox_inches='tight')\r\n    finally:\r\n        # put matplotlib back in original state\r\n        if was_interactive:\r\n            plt.ion()\r\n        mpl.rc('figure', max_open_warning=max_open_warning)\r\n\r\n    return result\r\n\r\n\r\n@make_axes\r\ndef mass_ecc(f, ax=None):\r\n    \"\"\"Plot each particle's mass versus eccentricity.\"\"\"\r\n    ax.plot(f['mass'], f['ecc'], 'ko', alpha=0.3)\r\n    ax.set_xlabel('mass')\r\n    ax.set_ylabel('eccentricity (0=circular)')\r\n    return ax\r\n\r\n@make_axes\r\ndef mass_size(f, ax=None):\r\n    \"\"\"Plot each particle's mass versus size.\"\"\"\r\n    ax.plot(f['mass'], f['size'], 'ko', alpha=0.1)\r\n    ax.set_xlabel('mass')\r\n    ax.set_ylabel('size')\r\n    return ax\r\n\r\ndef subpx_bias(f, pos_columns=None):\r\n    \"\"\"Histogram the fractional part of the x and y position.\r\n\r\n    Parameters\r\n    ----------\r\n    f : DataFrame\r\n    pos_columns : list of column names, optional\r\n\r\n    Notes\r\n    -----\r\n    If subpixel accuracy is good, this should be flat. If it depressed in the\r\n    middle, try using a larger value for feature diameter.\"\"\"\r\n    if pos_columns is None:\r\n        if 'z' in f:\r\n            pos_columns = ['x', 'y', 'z']\r\n        else:\r\n            pos_columns = ['x', 'y']\r\n    axlist = f[pos_columns].applymap(lambda x: x % 1).hist()\r\n    return axlist\r\n\r\n@make_axes\r\ndef fit(data, fits, inverted_model=False, logx=False, logy=False, ax=None,\r\n        **kwargs):\r\n    data = data.dropna()\r\n    x, y = data.index.values.astype('float64'), data.values\r\n    datalines = ax.plot(x, y, 'o', label=data.name, **kwargs)\r\n    if logx:\r\n        ax.set_xscale('log')\r\n    if logy:\r\n        ax.set_yscale('log')\r\n    if not inverted_model:\r\n        fitlines = ax.plot(fits.index, fits, **kwargs)\r\n    else:\r\n        fitlines = ax.plot(fits.reindex(data.dropna().index),\r\n                           data.dropna(), **kwargs)\r\n    # Restrict plot axis to domain of the data, not domain of the fit.\r\n    xmin = data.index.values[data.index.values > 0].min() if logx \\\r\n        else data.index.values.min()\r\n    ax.set_xlim(xmin, data.index.values.max())\r\n    # Match colors of data and corresponding fits.\r\n    [f.set_color(d.get_color()) for d, f in zip(datalines, fitlines)]\r\n    if logx:\r\n        ax.set_xscale('log')  # logx kwarg does not always take. Bug?\r\n\r\n@make_axes\r\ndef plot_principal_axes(img, x_bar, y_bar, cov, ax=None):\r\n    \"\"\"Plot bars with a length of 2 stddev along the principal axes.", "start_char_idx": 20574, "end_char_idx": 24629, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a43c2e60-0840-4ea9-9115-d5d3f2bf2a1c": {"__data__": {"id_": "a43c2e60-0840-4ea9-9115-d5d3f2bf2a1c", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2115b34a-a52e-4c77-8f05-1354636b69ff", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "ab0c6ed08f93acc69475669f447092ae4c2b144a7bf5c30c73d9b42dc1676e14", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b0131a46-10dd-4d1f-a083-3b2e3e31ef72", "node_type": "1", "metadata": {}, "hash": "4e747dc1c5e4682e55ce9c5e50a28c2f60f624e8e65ce7befc6f3d851c4eb905", "class_name": "RelatedNodeInfo"}}, "text": "xmin = data.index.values[data.index.values > 0].min() if logx \\\r\n        else data.index.values.min()\r\n    ax.set_xlim(xmin, data.index.values.max())\r\n    # Match colors of data and corresponding fits.\r\n    [f.set_color(d.get_color()) for d, f in zip(datalines, fitlines)]\r\n    if logx:\r\n        ax.set_xscale('log')  # logx kwarg does not always take. Bug?\r\n\r\n@make_axes\r\ndef plot_principal_axes(img, x_bar, y_bar, cov, ax=None):\r\n    \"\"\"Plot bars with a length of 2 stddev along the principal axes.\r\n\r\n    Attribution\r\n    -----------\r\n    This function is based on a solution by Joe Kington, posted on Stack\r\n    Overflow at http://stackoverflow.com/questions/5869891/\r\n    how-to-calculate-the-axis-of-orientation/5873296#5873296\r\n    \"\"\"\r\n    def make_lines(eigvals, eigvecs, mean, i):\r\n        \"\"\"Make lines a length of 2 stddev.\"\"\"\r\n        std = np.sqrt(eigvals[i])\r\n        vec = 2 * std * eigvecs[:, i] / np.hypot(*eigvecs[:, i])\r\n        x, y = np.vstack((mean-vec, mean, mean+vec)).T\r\n        return x, y\r\n    mean = np.array([x_bar, y_bar])\r\n    eigvals, eigvecs = np.linalg.eigh(cov)\r\n    ax.plot(*make_lines(eigvals, eigvecs, mean, 0), marker='o', color='white')\r\n    ax.plot(*make_lines(eigvals, eigvecs, mean, -1), marker='o', color='red')\r\n    ax.imshow(img)\r\n\r\ndef examine_jumps(data, jumps):\r\n    import matplotlib.pyplot as plt\r\n\r\n    fig, axes = plt.subplots(len(jumps), 1)\r\n    for i, jump in enumerate(jumps):\r\n        roi = data.ix[jump-10:jump+10]\r\n        axes[i].plot(roi.index, roi, 'g.')\r\n        axes[i].plot(jump, data[jump], 'ko')\r\n    fig.show()\r\n    fig2, axes2 = plt.subplots(1, 1)\r\n    axes2.plot(data.index, data, 'g.')\r\n    for jump in jumps:\r\n        axes2.plot(jump, data[jump], 'ko')\r\n    fig2.show()\r\n\r\n@make_axes  \r\ndef plot_density_profile(f, binsize, blocks=None, mpp=None, fps=None,\r\n                         normed=True, t_column='frame', pos_column='z',\r\n                         ax=None, **kwargs):\r\n    \"\"\"Plot a histogram showing the density profile in one direction.\r\n\r\n    Parameters\r\n    ----------\r\n    f : DataFrame\r\n        positions, including columns 'frame' and 'z'\r\n    binsize : integer\r\n        histogram binsize, if mpp is set, this is in in units of microns\r\n    blocks : integer, optional\r\n        number of density profiles to plot\r\n    mpp : number, optional\r\n        microns per pixel\r\n    fps : number, optional\r\n        frames per second\r\n    normed : boolean\r\n        if true, the histogram is normalized\r\n    t_column : string, default 'frame'\r\n    pos_column : string, default 'z'\r\n    ax : matplotlib axes (optional)\r\n    \r\n    Returns\r\n    -------\r\n    Axes object\r\n\r\n    Notes\r\n    -----\r\n    Any other keyword arguments will pass through to matplotlib's `plot`.\r\n    \"\"\"\r\n    import matplotlib as mpl\r\n    lastframe = f[t_column].max()\r\n\r\n    if blocks is None:\r\n        framesperblock = lastframe\r\n    else:\r\n        framesperblock = lastframe // blocks\r\n        if framesperblock == 0:\r\n            raise ValueError('Blocktime too low.')\r\n\r\n    if mpp is None:\r\n        ax.set_ylabel('{} [px]'.format(pos_column))\r\n        mpp = 1.", "start_char_idx": 24129, "end_char_idx": 27241, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b0131a46-10dd-4d1f-a083-3b2e3e31ef72": {"__data__": {"id_": "b0131a46-10dd-4d1f-a083-3b2e3e31ef72", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a43c2e60-0840-4ea9-9115-d5d3f2bf2a1c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "2fa1bd60513d896b1b55973229df2d0525f3fefaa42fe7b4334802eba1273716", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10483143-2734-4430-8a32-8e0cb6a47761", "node_type": "1", "metadata": {}, "hash": "04585897f938d5e6c225baf1f29aad909c2aaa59e8bd290616b7e10b02dd91f5", "class_name": "RelatedNodeInfo"}}, "text": "import matplotlib as mpl\r\n    lastframe = f[t_column].max()\r\n\r\n    if blocks is None:\r\n        framesperblock = lastframe\r\n    else:\r\n        framesperblock = lastframe // blocks\r\n        if framesperblock == 0:\r\n            raise ValueError('Blocktime too low.')\r\n\r\n    if mpp is None:\r\n        ax.set_ylabel('{} [px]'.format(pos_column))\r\n        mpp = 1.  # for computations of image extent below\r\n    else:\r\n        if mpl.rcParams['text.usetex']:\r\n            ax.set_ylabel(r'{} [\\textmu m]'.format(pos_column))\r\n        else:\r\n            ax.set_ylabel('{} [\\xb5m]'.format(pos_column))\r\n\r\n    if normed:\r\n        ax.set_xlabel('N / Ntot')\r\n    else:\r\n        ax.set_xlabel('N')\r\n\r\n    if fps is None:\r\n        timeunit = ''\r\n        fps = 1.\r\n    else:\r\n        timeunit = ' s'\r\n\r\n    ts = f[t_column].values\r\n    zs = f[pos_column].values * mpp\r\n    bins = np.arange(0, np.max(zs), binsize)\r\n    x_coord = (bins[:-1] + bins[1:])/2\r\n    plotlabel = None\r\n\r\n    for first in np.arange(0, lastframe, framesperblock):\r\n        mask = np.logical_and(ts >= first, ts < first + framesperblock)\r\n        count, bins = np.histogram(zs[mask], bins=bins, normed=normed)\r\n        if framesperblock != lastframe:\r\n            plotlabel = '{0:.1f}{2} <= t < {1:.1f}{2}'.format(first / fps,\r\n                           (first + framesperblock) / fps, timeunit)\r\n        ax.plot(count * mpp, x_coord, label=plotlabel, **kwargs)\r\n\r\n    return ax\r\n\r\n\r\n@make_axes\r\ndef plot_displacements(t, frame1, frame2, scale=1, ax=None, pos_columns=None,\r\n                       **kwargs):\r\n    \"\"\"Plot arrows showing particles displacements between two frames.\r\n\r\n    Parameters\r\n    ----------\r\n    t : DataFrame\r\n        trajectories, including columns 'frame' and 'particle'\r\n    frame1 : integer\r\n        frame number\r\n    frame2 : integer\r\n        frame number\r\n    scale : float\r\n        scale factor, if 1 (default) then arrow end is placed at particle\r\n        destination; if any other number arrows are rescaled\r\n    pos_columns : list of strings, optional\r\n        Dataframe column names for spatial coordinates. Default is ['x', 'y'].\r\n    ax : matplotlib axes (optional)\r\n\r\n    Notes\r\n    -----\r\n    Any other keyword arguments will pass through to matplotlib's `annotate`.\r\n    \"\"\"\r\n    if pos_columns is None:\r\n        pos_columns = ['x', 'y']\r\n    a = t[t.frame == frame1]\r\n    b = t[t.frame == frame2]\r\n    j = (a.set_index('particle')[pos_columns].join(\r\n        b.set_index('particle')[pos_columns], rsuffix='_b'))\r\n    for i in pos_columns:\r\n        j['d' + i] = j[i + '_b'] - j[i]\r\n    arrow_specs = j[pos_columns + ['d' + i for i in pos_columns]].dropna()\r\n\r\n    # Arrow defaults\r\n    default_arrow_props = dict(arrowstyle='->', connectionstyle='arc3',\r\n                               linewidth=2)\r\n    kwargs['arrowprops'] = kwargs.get('arrowprops', default_arrow_props)\r\n    for _, row in arrow_specs.iterrows():\r\n        xy = row[pos_columns]  # arrow start\r\n        xytext = xy.values + scale*row[['d' + i for i in pos_columns]].values\r\n        # Use ax.annotate instead of ax.arrow because it is allows more\r\n        # control over arrow style.\r\n        ax.annotate(\"\",\r\n                    xy=xy, xycoords='data',\r\n                    xytext=xytext, textcoords='data',\r\n                    **kwargs)\r\n    ax.set_xlim(min(j[pos_columns[0]].min(), j[pos_columns[0] + '_b'].min()),\r\n                max(j[pos_columns[0]].max(), j[pos_columns[0] + '_b'].max()))\r\n    ax.set_ylim(min(j[pos_columns[1]].min(), j[pos_columns[1] + '_b'].min()),\r\n                max(j[pos_columns[1]].max(), j[pos_columns[1] + '_b'].max()))\r\n    _set_labels(ax, '{} [px]', pos_columns)\r\n\r\n    return ax\r\n\r\n\r\ndef _normalize_kwargs(kwargs, kind='patch'):\r\n    \"\"\"Convert matplotlib keywords from short to long form.\"\"\"", "start_char_idx": 26884, "end_char_idx": 30680, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "10483143-2734-4430-8a32-8e0cb6a47761": {"__data__": {"id_": "10483143-2734-4430-8a32-8e0cb6a47761", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9a72acd-14d0-438c-966b-ae3f50a604d0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cba9bbe1cfee1951e2c9fdcaad038f4709c8383cbdab255ba8f459a535dfc98b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b0131a46-10dd-4d1f-a083-3b2e3e31ef72", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "3f423df69636003df052f704798b9a3a65ef660ae5f6ae9211860101e7f12881", "class_name": "RelatedNodeInfo"}}, "text": "ax.annotate(\"\",\r\n                    xy=xy, xycoords='data',\r\n                    xytext=xytext, textcoords='data',\r\n                    **kwargs)\r\n    ax.set_xlim(min(j[pos_columns[0]].min(), j[pos_columns[0] + '_b'].min()),\r\n                max(j[pos_columns[0]].max(), j[pos_columns[0] + '_b'].max()))\r\n    ax.set_ylim(min(j[pos_columns[1]].min(), j[pos_columns[1] + '_b'].min()),\r\n                max(j[pos_columns[1]].max(), j[pos_columns[1] + '_b'].max()))\r\n    _set_labels(ax, '{} [px]', pos_columns)\r\n\r\n    return ax\r\n\r\n\r\ndef _normalize_kwargs(kwargs, kind='patch'):\r\n    \"\"\"Convert matplotlib keywords from short to long form.\"\"\"\r\n    # Source:\r\n    # github.com/tritemio/FRETBursts/blob/fit_experim/fretbursts/burst_plot.py\r\n    if kind == 'line2d':\r\n        long_names = dict(c='color', ls='linestyle', lw='linewidth',\r\n                          mec='markeredgecolor', mew='markeredgewidth',\r\n                          mfc='markerfacecolor', ms='markersize',)\r\n    elif kind == 'patch':\r\n        long_names = dict(c='color', ls='linestyle', lw='linewidth',\r\n                          ec='edgecolor', fc='facecolor',)\r\n    for short_name in long_names:\r\n        if short_name in kwargs:\r\n            kwargs[long_names[short_name]] = kwargs.pop(short_name)\r\n    return kwargs", "start_char_idx": 30042, "end_char_idx": 31326, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aa83e7ed-7fe7-41c8-b76d-87c18ed9c522": {"__data__": {"id_": "aa83e7ed-7fe7-41c8-b76d-87c18ed9c522", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4028d764-4d2a-43ab-b597-c78ea8082de0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "c99bf9fd479b4c0341b97e93ba5fe1bc1e3e84d797d5fc3c37e377ddaa2c38f7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "53fc4b1f-5534-4133-9725-7a8394a76498", "node_type": "1", "metadata": {}, "hash": "75b24a30d56e807656d5fad2a07e13ddeb1ee016fc0c4a734edc63f81c60dadc", "class_name": "RelatedNodeInfo"}}, "text": "# Copyright 2014, Nathan C. Keim\r\n# keimnathan@gmail.com\r\n\r\n\"\"\"Tools to improve tracking performance by guessing where a particle will appear next.\"\"\"\r\nfrom warnings import warn\r\nfrom collections import deque\r\nimport functools, itertools\r\n\r\nimport numpy as np\r\nfrom scipy.interpolate import NearestNDInterpolator, interp1d\r\nimport pandas as pd\r\n\r\nfrom trackpy import linking\r\n\r\nfrom trackpy.utils import pandas_concat, guess_pos_columns\r\n\r\n\r\ndef predictor(predict_func):\r\n    \"\"\"Decorator to vectorize a predictor function for a single particle.\r\n\r\n    Converts P(t1, particle) into Pvec(t1, particles), where 'particles' is a list\r\n    of particle instances, and 'Pvec' can be passed to a linking function\r\n    (e.g. link_df_iter()) via its 'predictor' argument.\r\n    \"\"\"\r\n    def Pvec(t1, particles):\r\n        targeted_p = functools.partial(predict_func, t1)\r\n        return map(targeted_p, particles)\r\n    return Pvec\r\n\r\n\r\n@predictor\r\ndef null_predict(t1, particle):\r\n    return (particle.pos)\r\n\r\n\r\nclass NullPredict:\r\n    \"\"\"Predict that particles will not move.\r\n\r\n    (Equivalent to standard behavior of linker.)\r\n    \"\"\"\r\n    def wrap(self, linking_fcn, *args, **kw):\r\n        \"\"\"Wrapper for an arbitrary linking function that causes it to use this predictor.\r\n\r\n        The linking function must accept a 'predictor' keyword argument.\r\n\r\n        The linking function must accept a 'predictor' keyword argument. It\r\n        must return an iterator of DataFrames, emitting a DataFrame each time\r\n        a frame is linked.\r\n        \"\"\"\r\n        if getattr(self, '_already_linked', False):\r\n            warn('Perform tracking with a fresh predictor instance to avoid surprises.')\r\n        self._already_linked = True\r\n        kw['predictor'] = self.predict\r\n\r\n        # Sample the first frame of data to get position columns, if needed\r\n        args = list(args)\r\n        frames = iter(args[0])\r\n        f0 = next(frames)\r\n        args[0] = itertools.chain([f0], frames)\r\n\r\n        # Sort out pos_columns, which must match what the linker is using.\r\n        # The user may have already specified it, especially if they are giving\r\n        # an initial guess to a velocity predictor. If so, make sure that the\r\n        # value given to the linker matches.\r\n        if getattr(self, 'pos_columns', None) is not None:\r\n            pos_columns = self.pos_columns\r\n            if 'pos_columns' in kw and kw['pos_columns'] is not None and any(\r\n                    [spc != ppc for (spc, ppc) in\r\n                     zip(pos_columns, kw['pos_columns'])]):\r\n                    raise ValueError('The optional pos_columns given to the linker '\r\n                                     'conflicts with the pos_columns used to initialize '\r\n                                     'this predictor.')\r\n        else:\r\n            # If no explicit pos_columns has been given anywhere, now is the time\r\n            # to guess.\r\n            pos_columns = kw.get('pos_columns', guess_pos_columns(f0))\r\n            self.pos_columns = pos_columns\r\n        # No matter what, ensure that the linker uses the same pos_columns.\r\n        # (This maintains compatibility with the legacy linkers)\r\n        kw['pos_columns'] = self.pos_columns\r\n\r\n        self.t_column = kw.get('t_column', 'frame')\r\n        for frame in linking_fcn(*args, **kw):\r\n            self.observe(frame)\r\n            yield frame\r\n\r\n    def wrap_single(self, linking_fcn, *args, **kw):\r\n        \"\"\"Wrapper for an arbitrary linking function that causes it to use this predictor.\r\n\r\n        This wrapper causes the linker to accept and return a single DataFrame\r\n        with coordinates for all frames. Because it wraps functions that use\r\n        iterators of DataFrames, it should not necessarily be considered a drop-in replacement\r\n        for another single-DataFrame linking function.\r\n\r\n        The linking function must accept a 'predictor' keyword argument. It\r\n        must return an iterator of DataFrames, emitting a DataFrame each time\r\n        a frame is linked.\r\n        \"\"\"\r\n        # TODO: Properly handle empty frames by adopting more sophisticated\r\n        # logic in e.g. linking._gen_levels_df()\r\n        args = list(args)\r\n        features = args.pop(0)\r\n        if kw.get('t_column') is None:\r\n            kw['t_column'] = 'frame'\r\n        kw['predictor'] = self.predict\r\n        features_iter = (frame for fnum, frame in features.groupby(kw['t_column']))\r\n        return pandas_concat(self.wrap(linking_fcn, features_iter, *args, **kw))\r\n\r\n    def link_df_iter(self, *args, **kw):\r\n        \"\"\"Wrapper for linking.link_df_iter() that causes it to use this predictor.\"\"\"", "start_char_idx": 0, "end_char_idx": 4639, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "53fc4b1f-5534-4133-9725-7a8394a76498": {"__data__": {"id_": "53fc4b1f-5534-4133-9725-7a8394a76498", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4028d764-4d2a-43ab-b597-c78ea8082de0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "c99bf9fd479b4c0341b97e93ba5fe1bc1e3e84d797d5fc3c37e377ddaa2c38f7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aa83e7ed-7fe7-41c8-b76d-87c18ed9c522", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "f9d1d88c65b9e66368534c877d8ddfffd5faa1ff7a866bda8c7161ec37152a4d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8ae21b56-433b-47d4-acb2-8bc98f2c745c", "node_type": "1", "metadata": {}, "hash": "727fe54bf1dfd49ae2d6252e5e65c72ca8e382303c56e2458e1f68404d0bb4f0", "class_name": "RelatedNodeInfo"}}, "text": "The linking function must accept a 'predictor' keyword argument. It\r\n        must return an iterator of DataFrames, emitting a DataFrame each time\r\n        a frame is linked.\r\n        \"\"\"\r\n        # TODO: Properly handle empty frames by adopting more sophisticated\r\n        # logic in e.g. linking._gen_levels_df()\r\n        args = list(args)\r\n        features = args.pop(0)\r\n        if kw.get('t_column') is None:\r\n            kw['t_column'] = 'frame'\r\n        kw['predictor'] = self.predict\r\n        features_iter = (frame for fnum, frame in features.groupby(kw['t_column']))\r\n        return pandas_concat(self.wrap(linking_fcn, features_iter, *args, **kw))\r\n\r\n    def link_df_iter(self, *args, **kw):\r\n        \"\"\"Wrapper for linking.link_df_iter() that causes it to use this predictor.\"\"\"\r\n        return self.wrap(linking.link_df_iter, *args, **kw)\r\n\r\n    def link_df(self, *args, **kw):\r\n        \"\"\"Wrapper for linking.link_df_iter() that causes it to use this predictor.\r\n\r\n        As with linking.link_df(), the features data is a single DataFrame.\r\n\r\n        Note that this does not wrap linking.link_df(), and does not accept the same\r\n        options as that function. However in most cases it is functionally equivalent.\r\n        \"\"\"\r\n        return self.wrap_single(linking.link_df_iter, *args, **kw)\r\n\r\n    def observe(self, frame):\r\n        \"\"\"Examine the latest output of the linker, to update our predictions.\"\"\"\r\n        pass\r\n\r\n    def state(self):\r\n        \"\"\"Return a representation of the predictor's internal state.\r\n\r\n        For diagnostic purposes.\r\n        \"\"\"\r\n        return None\r\n\r\n    def predict(self, t1, particles):\r\n        \"\"\"Predict the positions of 'particles' at time 't1'\"\"\"\r\n        return map(lambda p: p.pos, particles)\r\n\r\n\r\nclass _RecentVelocityPredict(NullPredict):\r\n    def __init__(self, span=1, pos_columns=None):\r\n        \"\"\"Use the 'span'+1 most recent frames to make a velocity field.\r\n\r\n        pos_columns should be specified if you will not be using the\r\n        link_df() or link_df_iter() method for linking with prediction.\r\n        \"\"\"\r\n        self.recent_frames = deque([], span + 1)\r\n        self.pos_columns = pos_columns\r\n\r\n    def state(self):\r\n        return list(self.recent_frames)\r\n\r\n    def _check_pos_columns(self):\r\n        \"\"\"Depending on how the predictor is used, it's possible for pos_columns to be missing.\r\n        This raises a helpful error message in that case.\"\"\"\r\n        if self.pos_columns is None:\r\n            raise AttributeError('If you are not using the link_df() or link_df_iter() methods of the predictor, '\r\n                                 'you must specify pos_columns when you initialize the predictor object.')\r\n\r\n    def _compute_velocities(self, frame):\r\n        \"\"\"Compute velocity field based on a newly-tracked frame.\"\"\"\r\n        self._check_pos_columns()\r\n        pframe = frame.set_index('particle')\r\n        self.recent_frames.append(pframe)\r\n        if len(self.recent_frames) == 1:\r\n            # Double the first frame. Velocity field will be zero.\r\n            self.recent_frames.append(pframe)\r\n            dt = 1. # Avoid dividing by zero\r\n        else: # Not the first frame\r\n            dt = float(self.recent_frames[-1][self.t_column].values[0] -\r\n                 self.recent_frames[0][self.t_column].values[0])\r\n\r\n        # Compute velocity field\r\n        disps = self.recent_frames[-1][self.pos_columns].join(\r\n            self.recent_frames[-1][self.pos_columns] -\r\n                self.recent_frames[0][self.pos_columns], rsuffix='_disp_').dropna()\r\n        positions = disps[self.pos_columns]\r\n        vels = disps[[cn + '_disp_' for cn in self.pos_columns]] / dt\r\n        # 'vels' will have same column names as 'positions'\r\n        vels = vels.rename(columns=lambda n: n[:-6])\r\n        return dt, positions, vels\r\n\r\n\r\nclass NearestVelocityPredict(_RecentVelocityPredict):\r\n    \"\"\"Predict a particle's position based on the most recent nearby velocity.\r\n\r\n    Parameters\r\n    ----------\r\n    initial_guess_positions : Nxd array, optional\r\n        Columns should be in the same order used by the linking function.\r\n    initial_guess_vels : Nxd array, optional\r\n        If specified, these initialize the velocity field with velocity\r\n        samples at the given points.\r\n    pos_columns : list of d strings, optional\r\n        Names of coordinate columns corresponding to the columns of\r\n        the initial_guess arrays, e.g. ['y', 'x']. Required if a guess\r\n        is specified.", "start_char_idx": 3849, "end_char_idx": 8347, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8ae21b56-433b-47d4-acb2-8bc98f2c745c": {"__data__": {"id_": "8ae21b56-433b-47d4-acb2-8bc98f2c745c", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4028d764-4d2a-43ab-b597-c78ea8082de0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "c99bf9fd479b4c0341b97e93ba5fe1bc1e3e84d797d5fc3c37e377ddaa2c38f7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "53fc4b1f-5534-4133-9725-7a8394a76498", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "aed5251020538361ed0430c3251a0f69087c5f143beaefa7a9fa05d6fc5c9ec1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4f83db66-c900-48be-9738-5a55289ca695", "node_type": "1", "metadata": {}, "hash": "ec06cc8bb3990a9280a5d9a3232d5f0d4ae862cd42ef2885ebf47f4185dcb297", "class_name": "RelatedNodeInfo"}}, "text": "Parameters\r\n    ----------\r\n    initial_guess_positions : Nxd array, optional\r\n        Columns should be in the same order used by the linking function.\r\n    initial_guess_vels : Nxd array, optional\r\n        If specified, these initialize the velocity field with velocity\r\n        samples at the given points.\r\n    pos_columns : list of d strings, optional\r\n        Names of coordinate columns corresponding to the columns of\r\n        the initial_guess arrays, e.g. ['y', 'x']. Required if a guess\r\n        is specified.\r\n    span : integer, default 1\r\n        Compute velocity field from the most recent span+1 frames.\r\n    \"\"\"\r\n\r\n    def __init__(self, initial_guess_positions=None,\r\n                 initial_guess_vels=None, pos_columns=None, span=1):\r\n        if initial_guess_positions is not None and pos_columns is None:\r\n            raise ValueError('The order of the position columns in your initial '\r\n                             \"guess is ambiguous. Specify the coordinate names \"\r\n                             \"with your guess, using e.g. pos_columns=['y', 'x']\")\r\n        super().__init__(span=span, pos_columns=pos_columns)\r\n        if initial_guess_positions is not None:\r\n            self.use_initial_guess = True\r\n            self.interpolator = NearestNDInterpolator(\r\n                np.asarray(initial_guess_positions),\r\n                np.asarray(initial_guess_vels))\r\n        else:\r\n            self.use_initial_guess = False\r\n\r\n    def observe(self, frame):\r\n        dt, positions, vels = self._compute_velocities(frame)\r\n        if self.use_initial_guess:\r\n            self.use_initial_guess = False\r\n        else:\r\n            if positions.values.shape[0] > 0:\r\n                self.interpolator = NearestNDInterpolator(\r\n                    positions[self.pos_columns].values,\r\n                    vels[self.pos_columns].values)\r\n            else:\r\n                # Sadly, the 2 most recent frames had no points in common.\r\n                warn('Could not generate velocity field for prediction: no tracks')\r\n\r\n                def null_interpolator(*x):\r\n                    return np.zeros((len(x),))\r\n\r\n                self.interpolator = null_interpolator\r\n\r\n    def state(self):\r\n        return {'recent_frames': list(self.recent_frames),\r\n                'interpolator': self.interpolator,\r\n                'using_initial_guess': self.use_initial_guess,\r\n                }\r\n\r\n    def predict(self, t1, particles):\r\n        poslist, tlist = zip(*[(p.pos, p.t) for p in particles])\r\n        positions = np.array(poslist)\r\n        times = np.array(tlist)\r\n        return (positions + self.interpolator(positions) *\r\n               np.tile(t1 - times, (positions.shape[1], 1)).T)\r\n\r\n\r\nclass DriftPredict(_RecentVelocityPredict):\r\n    \"\"\"Predict a particle's position based on the mean velocity of all particles.\r\n\r\n    Parameters\r\n    ----------\r\n    initial_guess : Array of length d, optional\r\n        Velocity vector initially used for prediction.\r\n        Default is to assume zero velocity.\r\n    pos_columns : list of d strings, optional\r\n        Names of coordinate columns corresponding to the elements of\r\n        initial_guess, e.g. ['y', 'x']. Required if a guess is specified.\r\n    span : integer, default 1\r\n        Compute velocity field from the most recent span+1 frames.\r\n    \"\"\"\r\n    def __init__(self, initial_guess=None, pos_columns=None, span=1):\r\n        if initial_guess is not None and pos_columns is None:\r\n            raise ValueError('The order of the position columns in your initial '\r\n                             \"guess is ambiguous. Specify the coordinate names \"\r\n                             \"with your guess, using e.g. pos_columns=['y', 'x']\")\r\n        super().__init__(pos_columns=pos_columns, span=span)\r\n        self.initial_guess = initial_guess\r\n\r\n    def observe(self, frame):\r\n        dt, positions, vels = self._compute_velocities(frame)\r\n        if self.initial_guess is not None:\r\n            self.vel = np.asarray(self.initial_guess)\r\n            self.initial_guess = None\r\n        else:\r\n            self.vel = vels.mean().values\r\n\r\n    def predict(self, t1, particles):\r\n        poslist, tlist = zip(*[(p.pos, p.t) for p in particles])\r\n        positions = np.array(poslist)\r\n        times = np.array(tlist)\r\n        return (positions + self.vel *\r\n                np.tile(t1 - times, (positions.shape[1], 1)).T)\r\n\r\n\r\nclass ChannelPredict(_RecentVelocityPredict):\r\n    \"\"\"Predict a particle's position based on its spanwise coordinate in a channel.\r\n\r\n    This operates by binning particles according to their spanwise coordinate and\r\n    averaging velocity, to make an instantaneous velocity profile.\r\n\r\n    Parameters\r\n    ----------\r\n    bin_size : Size of bins, in units of spanwise length, over which to average\r\n        streamwise velocity.", "start_char_idx": 7827, "end_char_idx": 12650, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f83db66-c900-48be-9738-5a55289ca695": {"__data__": {"id_": "4f83db66-c900-48be-9738-5a55289ca695", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4028d764-4d2a-43ab-b597-c78ea8082de0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "c99bf9fd479b4c0341b97e93ba5fe1bc1e3e84d797d5fc3c37e377ddaa2c38f7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8ae21b56-433b-47d4-acb2-8bc98f2c745c", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "02bbe8ebd30cbda52d6f5f6a33382cef39fd6123b35df630c24d697bb33ec69d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "db1e61d0-568f-4a5b-95d3-748be1b2c1af", "node_type": "1", "metadata": {}, "hash": "7c22fd3a2b572c089dec9eaf7f7bd454f58cf2956bc869eee8134a417401626e", "class_name": "RelatedNodeInfo"}}, "text": "This operates by binning particles according to their spanwise coordinate and\r\n    averaging velocity, to make an instantaneous velocity profile.\r\n\r\n    Parameters\r\n    ----------\r\n    bin_size : Size of bins, in units of spanwise length, over which to average\r\n        streamwise velocity.\r\n    flow_axis : Name of coordinate along which particles are flowing (default \"x\")\r\n    minsamples : Minimum number of particles in a bin for its average\r\n        velocity to be valid.\r\n    initial_profile_guess : Nx2 array (optional)\r\n        (spanwise coordinate, streamwise velocity) samples specifying\r\n        initial velocity profile. Samples must be sufficiently dense to account\r\n        for variation in the velocity profile. If omitted, initial velocities are\r\n        assumed to be zero.\r\n    pos_columns : list of d strings, optional\r\n        Names of coordinate columns. Required only if not using link_df or link_df_iter.\r\n    span : integer, default 1\r\n        Compute velocity field from the most recent span+1 frames.\r\n\r\n    Notes\r\n    -----\r\n    - This currently only works for 2D data.\r\n    - Where there were not enough data to make an average velocity (N < minsamples),\r\n        we borrow from the nearest valid bin.\r\n    \"\"\"\r\n    def __init__(self, bin_size, flow_axis='x', minsamples=20,\r\n                 initial_profile_guess=None, pos_columns=None, span=1):\r\n        super().__init__(pos_columns=pos_columns, span=span)\r\n        self.bin_size = bin_size\r\n        self.flow_axis = flow_axis\r\n        self.minsamples = minsamples\r\n        self.initial_profile_guess = initial_profile_guess\r\n\r\n    def observe(self, frame):\r\n        # Sort out dimensions and axes\r\n        self._check_pos_columns()\r\n        if len(self.pos_columns) != 2:\r\n            raise ValueError('Implemented for 2 dimensions only')\r\n        if self.flow_axis not in self.pos_columns:\r\n            raise ValueError('pos_columns (%r) does not include the specified flow_axis (%s)!' %\r\n                             (self.pos_columns, self.flow_axis))\r\n        poscols = self.pos_columns[:]\r\n        flow_axis_position = poscols.index(self.flow_axis)\r\n        poscols.remove(self.flow_axis)\r\n        span_axis = poscols[0]\r\n\r\n        # Make velocity profile\r\n        dt, positions, vels = self._compute_velocities(frame)\r\n\r\n        if self.initial_profile_guess is not None:\r\n            ipg = np.asarray(self.initial_profile_guess)\r\n            prof = pd.Series(ipg[:, 1], index=ipg[:, 0])\r\n            self.initial_profile_guess = None  # Don't reuse\r\n        else:\r\n            # Bin centers\r\n            vels['bin'] = (positions[span_axis] - positions[span_axis]\r\n                                                 % self.bin_size + self.bin_size / 2.)", "start_char_idx": 12360, "end_char_idx": 15099, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "db1e61d0-568f-4a5b-95d3-748be1b2c1af": {"__data__": {"id_": "db1e61d0-568f-4a5b-95d3-748be1b2c1af", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4028d764-4d2a-43ab-b597-c78ea8082de0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "c99bf9fd479b4c0341b97e93ba5fe1bc1e3e84d797d5fc3c37e377ddaa2c38f7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4f83db66-c900-48be-9738-5a55289ca695", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "3a209058064ffcb7fe8000c9e9eb66f1740168c054b6e3ba97e8be57df8f980c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2525f3b0-a618-4880-a597-0ff9ea4a4639", "node_type": "1", "metadata": {}, "hash": "109d444c3afd3c11f3285c421781a41e41215c8236f9d05791f371c810a8493d", "class_name": "RelatedNodeInfo"}}, "text": "%\r\n                             (self.pos_columns, self.flow_axis))\r\n        poscols = self.pos_columns[:]\r\n        flow_axis_position = poscols.index(self.flow_axis)\r\n        poscols.remove(self.flow_axis)\r\n        span_axis = poscols[0]\r\n\r\n        # Make velocity profile\r\n        dt, positions, vels = self._compute_velocities(frame)\r\n\r\n        if self.initial_profile_guess is not None:\r\n            ipg = np.asarray(self.initial_profile_guess)\r\n            prof = pd.Series(ipg[:, 1], index=ipg[:, 0])\r\n            self.initial_profile_guess = None  # Don't reuse\r\n        else:\r\n            # Bin centers\r\n            vels['bin'] = (positions[span_axis] - positions[span_axis]\r\n                                                 % self.bin_size + self.bin_size / 2.)\r\n            grpvels = vels.groupby('bin')[self.flow_axis]\r\n            # Only use bins that have enough samples\r\n            profcount = grpvels.count()\r\n            prof = grpvels.mean()[profcount >= self.minsamples]\r\n\r\n        if len(prof) > 0:\r\n            # Handle boundary conditions for interpolator\r\n            prof_ind, prof_vals = list(prof.index), list(prof)\r\n            prof_ind.insert(0, -np.inf)\r\n            prof_ind.append(np.inf)\r\n            prof_vals.insert(0, prof.values[0])\r\n            prof_vals.append(prof.values[-1])\r\n            prof_vels = pd.DataFrame({self.flow_axis: pd.Series(prof_vals, index=prof_ind),\r\n                                      span_axis: 0})\r\n            prof_interp = interp1d(prof_vels.index.values, prof_vels[self.pos_columns].values,\r\n                                   'nearest', axis=0)\r\n            if flow_axis_position == 0:\r\n                self.interpolator = lambda x: prof_interp(x[:, 1])\r\n            else:\r\n                self.interpolator = lambda x: prof_interp(x[:, 0])\r\n        else:\r\n            # Not enough samples in any bin\r\n            warn('Could not generate velocity field for prediction: '\r\n                 'not enough tracks or bin_size too small')\r\n            nullvel = np.zeros((len(self.pos_columns),))\r\n\r\n            def null_interpolator(x):\r\n                return nullvel\r\n\r\n            self.interpolator = null_interpolator\r\n\r\n    def state(self):\r\n        return {'recent_frames': list(self.recent_frames),\r\n                'interpolator': self.interpolator,\r\n                'initial_profile_guess': self.initial_profile_guess,\r\n                }\r\n\r\n    def predict(self, t1, particles):\r\n        poslist, tlist = zip(*[(p.pos, p.t) for p in particles])\r\n        positions = np.array(poslist)\r\n        times = np.array(tlist)\r\n        return (positions + self.interpolator(positions) *\r\n               np.tile(t1 - times, (positions.shape[1], 1)).T)\r\n\r\n\r\ndef instrumented(limit=None):\r\n    \"\"\"Decorate a predictor class and allow it to record inputs and outputs.\r\n\r\n    Use when diagnosing prediction.\r\n\r\n    limit : maximum number of recent frames to retain. If None, keep all.\r\n\r\n    Examples\r\n    --------\r\n\r\n    >>> pred = instrumented()(ChannelPredict)(50, flow_axis='y')\r\n    >>> pred.link_df_iter(...)\r\n    >>> diagnostics = pred.dump()\r\n    \"\"\"\r\n    def instrumentor(cls):\r\n        class InstrumentedPredictor(cls):\r\n            def __init__(self, *args, **kw):\r\n                super().__init__(*args, **kw)\r\n                self.diag_observations = deque([], maxlen=limit)\r\n                self.diag_predictions = deque([], maxlen=limit)\r\n\r\n            def observe(self, frame):\r\n                self.diag_observations.append(frame)\r\n                return super().observe(frame)\r\n\r\n            def predict(self, t1, particles):\r\n                poslist, tlist, tracklist = zip(*[\r\n                    (p.pos, p.t, p.track.id) for p in particles])\r\n                pdf = pd.DataFrame(np.array(poslist), columns=self.pos_columns)\r\n                pdf[self.t_column] = tlist\r\n                pdf['particle'] = np.array(tracklist, dtype=int)\r\n\r\n                prediction = super().predict(t1, particles)\r\n                pred_df = pd.DataFrame(prediction, columns=self.pos_columns)\r\n                dd = {'t1': t1,\r\n                      'particledf': pdf.join(pred_df, rsuffix='_pred'),\r\n                      'state': self.state()}\r\n                self.diag_predictions.append(dd)\r\n\r\n                return prediction\r\n\r\n            def dump(self):\r\n                \"\"\"Report predicted and actual positions.\r\n\r\n                Returns list of dictionaries, each containing items\r\n                    \"t1\": Frame prediction was made *for*\r\n                    \"state\": Internal state of the predictor, if any\r\n                    \"particledf\": DataFrame containing positions and\r\n                        predicted positions.\r\n                \"\"\"\r\n                results = []\r\n                # Latest observation corresponds to the outcome of the\r\n                # most recent linking operation, which corresponds to the\r\n                # most recent element of self.diag_predictions.", "start_char_idx": 14329, "end_char_idx": 19290, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2525f3b0-a618-4880-a597-0ff9ea4a4639": {"__data__": {"id_": "2525f3b0-a618-4880-a597-0ff9ea4a4639", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4028d764-4d2a-43ab-b597-c78ea8082de0", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "c99bf9fd479b4c0341b97e93ba5fe1bc1e3e84d797d5fc3c37e377ddaa2c38f7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "db1e61d0-568f-4a5b-95d3-748be1b2c1af", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "4cb1b0f74b72e1a2292ecca86cbe64a1ec43f0853a2d1afefd173e4ae31964af", "class_name": "RelatedNodeInfo"}}, "text": "Returns list of dictionaries, each containing items\r\n                    \"t1\": Frame prediction was made *for*\r\n                    \"state\": Internal state of the predictor, if any\r\n                    \"particledf\": DataFrame containing positions and\r\n                        predicted positions.\r\n                \"\"\"\r\n                results = []\r\n                # Latest observation corresponds to the outcome of the\r\n                # most recent linking operation, which corresponds to the\r\n                # most recent element of self.diag_predictions.\r\n                # There may be an extra observation from the beginning\r\n                # of the tracking process, which zip() will ignore.\r\n                for obs, pred in zip(\r\n                        reversed(self.diag_observations),\r\n                        reversed(self.diag_predictions)):\r\n                    dd = pred.copy()\r\n                    dd['particledf'] = dd['particledf'].join(\r\n                        obs.set_index('particle')[self.pos_columns],\r\n                        on='particle', rsuffix='_act')\r\n                    results.append(dd)\r\n                results.reverse()  # Back to chronological order\r\n                return results\r\n\r\n        return InstrumentedPredictor\r\n    return instrumentor", "start_char_idx": 18731, "end_char_idx": 20018, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3e754b4c-01d4-4040-8fdb-8beb3cdd70a8": {"__data__": {"id_": "3e754b4c-01d4-4040-8fdb-8beb3cdd70a8", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict_test_llama370b.py", "file_name": "predict_test_llama370b.py", "file_type": "text/x-python", "file_size": 776, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e692095b-711d-46c7-b7b8-8a052dc2e6a1", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict_test_llama370b.py", "file_name": "predict_test_llama370b.py", "file_type": "text/x-python", "file_size": 776, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "66ffd3950c82d43e3fffd066dd69c9075f5a075b863d7c8de79611726e9fc21a", "class_name": "RelatedNodeInfo"}}, "text": "import unittest\r\nfrom predict import NullPredict, DriftPredict\r\n\r\nclass TestPredictFunction(unittest.TestCase):\r\n\r\n    def test_NullPredict(self):\r\n        predictor = NullPredict()\r\n        particles = [{'pos': [1, 2], 't': 0}, {'pos': [3, 4], 't': 0}]\r\n        result = predictor.predict(1, particles)\r\n        expected_result = [[1, 2], [3, 4]]\r\n        self.assertEqual(result.tolist(), expected_result)\r\n\r\n    def test_DriftPredict(self):\r\n        predictor = DriftPredict(initial_guess=[1, 2])\r\n        particles = [{'pos': [1, 2], 't': 0}, {'pos': [3, 4], 't': 0}]\r\n        result = predictor.predict(1, particles)\r\n        expected_result = [[2, 4], [4, 6]]\r\n        self.assertEqual(result.tolist(), expected_result)\r\n\r\nif __name__ == '__main__':\r\n    unittest.main()", "start_char_idx": 0, "end_char_idx": 776, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f62be28f-ba87-424e-977a-d644aac7eef8": {"__data__": {"id_": "f62be28f-ba87-424e-977a-d644aac7eef8", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6eff1c77-d741-4887-84c3-a75c26a30af4", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "38e43daf146d33b3b3995ad84573e930081e2e61d39ac0427f3b3ccedf7439ad", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b12ee25d-cb1a-4b8f-af02-42f38a09f449", "node_type": "1", "metadata": {}, "hash": "1e25113efb49f019051c5094734375cebb6d25a7232d1a2ca1ebddcb81008c24", "class_name": "RelatedNodeInfo"}}, "text": "import logging\r\n\r\nimport numpy as np\r\nfrom scipy.ndimage import uniform_filter1d, correlate1d, fourier_gaussian\r\n\r\nfrom .utils import validate_tuple\r\nfrom .masks import gaussian_kernel\r\ntry:\r\n    from pims import pipeline\r\nexcept ImportError:\r\n    pipeline = lambda x: x\r\n\r\ndef lowpass(image, sigma=1, truncate=4):\r\n    \"\"\"Remove noise by convolving with a Gaussian.\r\n\r\n    Convolve with a Gaussian to remove short-wavelength noise.\r\n\r\n    The lowpass implementation relies on scipy.ndimage.filters.gaussian_filter,\r\n    and it is the fastest way known to the authors of performing a bandpass in\r\n    Python.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n    sigma : number or tuple, optional\r\n        Size of the gaussian kernel with which the image is convolved.\r\n        Provide a tuple for different sizes per dimension. Default 1.\r\n    truncate : number, optional\r\n        Determines the truncation size of the convolution kernel. Default 4.\r\n\r\n    Returns\r\n    -------\r\n    result : array\r\n        the processed image, as float\r\n\r\n    See Also\r\n    --------\r\n    bandpass\r\n    \"\"\"\r\n    sigma = validate_tuple(sigma, image.ndim)\r\n    result = np.array(image, dtype=float)\r\n    for axis, _sigma in enumerate(sigma):\r\n        if _sigma > 0:\r\n            correlate1d(result, gaussian_kernel(_sigma, truncate), axis,\r\n                        output=result, mode='constant', cval=0.0)\r\n    return result\r\n\r\n\r\ndef boxcar(image, size):\r\n    \"\"\"Compute a rolling (boxcar) average of an image.\r\n\r\n    The kernel is square or rectangular.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n    size : number or tuple\r\n        Size of rolling average (square or rectangular kernel) filter. Should\r\n        be odd and larger than the particle diameter.\r\n        Provide a tuple for different sizes per dimension.\r\n\r\n    Returns\r\n    -------\r\n    result : array\r\n        the rolling average image\r\n\r\n    See Also\r\n    --------\r\n    bandpass\r\n    \"\"\"\r\n    size = validate_tuple(size, image.ndim)\r\n    if not np.all([x & 1 for x in size]):\r\n        raise ValueError(\"Smoothing size must be an odd integer. Round up.\")\r\n    result = image.copy()\r\n    for axis, _size in enumerate(size):\r\n        if _size > 1:\r\n            uniform_filter1d(result, _size, axis, output=result,\r\n                             mode='nearest', cval=0)\r\n    return result\r\n\r\n\r\ndef bandpass(image, lshort, llong, threshold=None, truncate=4):\r\n    \"\"\"Remove noise and background variation.\r\n\r\n    Convolve with a Gaussian to remove short-wavelength noise and subtract out\r\n    long-wavelength variations by subtracting a running average. This retains\r\n    features of intermediate scale.\r\n\r\n    The lowpass implementation relies on scipy.ndimage.filters.gaussian_filter,\r\n    and it is the fastest way known to the authors of performing a bandpass in\r\n    Python.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n    lshort : number or tuple\r\n        Size of the gaussian kernel with which the image is convolved.\r\n        Provide a tuple for different sizes per dimension.\r\n    llong : integer or tuple\r\n        The size of rolling average (square or rectangular kernel) filter.\r\n        Should be odd and larger than the particle diameter.\r\n        When llong <= lshort, an error is raised.\r\n        Provide a tuple for different sizes per dimension.\r\n    threshold : float or integer\r\n        Clip bandpass result below this value. Thresholding is done on the\r\n        already background-subtracted image.\r\n        By default, 1 for integer images and 1/255 for float images.\r\n    truncate : number, optional\r\n        Determines the truncation size of the gaussian kernel. Default 4.\r\n\r\n    Returns\r\n    -------\r\n    result : array\r\n        the bandpassed image\r\n\r\n    See Also\r\n    --------\r\n    lowpass, boxcar, legacy_bandpass, legacy_bandpass_fftw\r\n\r\n    Notes\r\n    -----\r\n    The boxcar size and shape changed in v0.4: before, the boxcar had a\r\n    circular kernel with radius `llong`, now it is has a square kernel that\r\n    has an edge length of `llong` (twice as small!).\r\n    \"\"\"\r\n    lshort = validate_tuple(lshort, image.ndim)\r\n    llong = validate_tuple(llong, image.ndim)\r\n    if np.any([x >= y for (x, y) in zip(lshort, llong)]):\r\n        raise ValueError(\"The smoothing length scale must be larger than \" +\r\n                         \"the noise length scale.\")\r\n    if threshold is None:\r\n        if np.issubdtype(image.dtype, np.integer):\r\n            threshold = 1\r\n        else:\r\n            threshold = 1/255.", "start_char_idx": 0, "end_char_idx": 4516, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b12ee25d-cb1a-4b8f-af02-42f38a09f449": {"__data__": {"id_": "b12ee25d-cb1a-4b8f-af02-42f38a09f449", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6eff1c77-d741-4887-84c3-a75c26a30af4", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "38e43daf146d33b3b3995ad84573e930081e2e61d39ac0427f3b3ccedf7439ad", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f62be28f-ba87-424e-977a-d644aac7eef8", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "fade4a1f8f69bfe0d67620a3d8b6e6dc9ccf98ad726eebeb76d3712c904e1c24", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b3d4e32-ddb3-4eda-b1d7-bd348c98b8c9", "node_type": "1", "metadata": {}, "hash": "df7adccc5c6971acf969816401d34268d1a91151acaed5fc4a4180fc3f703005", "class_name": "RelatedNodeInfo"}}, "text": "lshort = validate_tuple(lshort, image.ndim)\r\n    llong = validate_tuple(llong, image.ndim)\r\n    if np.any([x >= y for (x, y) in zip(lshort, llong)]):\r\n        raise ValueError(\"The smoothing length scale must be larger than \" +\r\n                         \"the noise length scale.\")\r\n    if threshold is None:\r\n        if np.issubdtype(image.dtype, np.integer):\r\n            threshold = 1\r\n        else:\r\n            threshold = 1/255.\r\n    background = boxcar(image, llong)\r\n    result = lowpass(image, lshort, truncate)\r\n    result -= background\r\n    return np.where(result >= threshold, result, 0)\r\n\r\n@pipeline\r\ndef invert_image(raw_image, max_value=None):\r\n    \"\"\"Invert the image.\r\n\r\n    Use this to convert dark features on a bright background to bright features\r\n    on a dark background.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n    max_value : number\r\n        The maximum value of the image. Optional. If not given, this will is\r\n        (for integers) the highest possible value and (for floats) 1.\r\n\r\n    Returns\r\n    -------\r\n    inverted image\r\n    \"\"\"\r\n    if max_value is None:\r\n        if np.issubdtype(raw_image.dtype, np.integer):\r\n            max_value = np.iinfo(raw_image.dtype).max\r\n        else:\r\n            # To avoid degrading performance, assume gamut is zero to one.\r\n            # Have you ever encountered an image of unnormalized floats?\r\n            max_value = 1.\r\n\r\n    # It is tempting to do this in place, but if it is called multiple\r\n    # times on the same image, chaos reigns.\r\n    if np.issubdtype(raw_image.dtype, np.integer):\r\n        result = raw_image ^ max_value\r\n    else:\r\n        result = max_value - raw_image\r\n    return result\r\n\r\n\r\ndef convert_to_int(image, dtype='uint8'):\r\n    \"\"\"Convert the image to integer and normalize if applicable.\r\n\r\n    Clips all negative values to 0. Does nothing if the image is already\r\n    of integer type.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n    dtype : numpy dtype\r\n        dtype to convert to. If the image is already of integer type, this\r\n        argument is ignored. Must be integer-subdtype. Default 'uint8'.\r\n\r\n    Returns\r\n    -------\r\n    tuple of (scale_factor, image)\r\n    \"\"\"\r\n    if np.issubdtype(image.dtype, np.integer):\r\n        # Do nothing, image is already of integer type.\r\n        return 1., image\r\n    max_value = np.iinfo(dtype).max\r\n    image_max = image.max()\r\n    if image_max == 0:  # protect against division by zero\r\n        scale_factor = 1.\r\n    else:\r\n        scale_factor = max_value / image_max\r\n    return scale_factor, (scale_factor * image.clip(min=0.)).astype(dtype)\r\n\r\n\r\n# Below are two older implementations of bandpass. Formerly, they were lumped\r\n# into one function, ``bandpass``, that used pyfftw if it was available and\r\n# numpy otherwise. Now there are separate functions for the pyfftw and numpy\r\n# code paths.\r\n\r\n# Both of these have been found to be slower than the new ``bandpass`` above\r\n# when benchmarked on typical inputs. Nonetheless, they are retained in case\r\n# they offer some advantage unforeseen by the authors.\r\n\r\n# All three functions give identical results, up to small numerical errors.\r\n\r\n\r\nlogger = logging.getLogger(__name__)\r\n\r\ntry:\r\n    import pyfftw\r\nexcept ImportError:\r\n    # Use numpy.\r\n    FFTW_AVAILABLE = False\r\nelse:\r\n    FFTW_AVAILABLE = True\r\n    pyfftw.interfaces.cache.enable()\r\n    planned = False\r\n\r\n    def fftn(a):\r\n        global planned\r\n        if not planned:\r\n            logger.info(\"Note: FFTW is configuring itself. This will take \" +\r\n                        \"several seconds, but subsequent calls will run \" +\r\n                        \"*much* faster.\")\r\n            planned = True\r\n        a = pyfftw.n_byte_align(a, a.dtype.alignment)\r\n        return pyfftw.interfaces.numpy_fft.fftn(a).astype(np.complex128)\r\n\r\n    def ifftn(a):\r\n        a = pyfftw.n_byte_align(a, a.dtype.alignment)\r\n        return pyfftw.interfaces.numpy_fft.ifftn(a)\r\n\r\n\r\ndef legacy_bandpass(image, lshort, llong, threshold=None):\r\n    \"\"\"Remove noise and background variation.\r\n\r\n    Convolve with a Gaussian to remove short-wavelength noise and subtract out\r\n    long-wavelength variations, retaining features of intermediate scale.\r\n\r\n    This implementation performs a Fourier transform using numpy.", "start_char_idx": 4083, "end_char_idx": 8370, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8b3d4e32-ddb3-4eda-b1d7-bd348c98b8c9": {"__data__": {"id_": "8b3d4e32-ddb3-4eda-b1d7-bd348c98b8c9", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6eff1c77-d741-4887-84c3-a75c26a30af4", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "38e43daf146d33b3b3995ad84573e930081e2e61d39ac0427f3b3ccedf7439ad", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b12ee25d-cb1a-4b8f-af02-42f38a09f449", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d8816b0043fa6f647a78c59664a85163c3aaeaf49ce4bca1837fcda98a6e9676", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ed31e661-e370-4374-89ad-42f25ea4d794", "node_type": "1", "metadata": {}, "hash": "b6ecdfab3f7a7abd2974b75b14f8cf62b3928e2440a0e26b70630dc7d3d0aba9", "class_name": "RelatedNodeInfo"}}, "text": "This will take \" +\r\n                        \"several seconds, but subsequent calls will run \" +\r\n                        \"*much* faster.\")\r\n            planned = True\r\n        a = pyfftw.n_byte_align(a, a.dtype.alignment)\r\n        return pyfftw.interfaces.numpy_fft.fftn(a).astype(np.complex128)\r\n\r\n    def ifftn(a):\r\n        a = pyfftw.n_byte_align(a, a.dtype.alignment)\r\n        return pyfftw.interfaces.numpy_fft.ifftn(a)\r\n\r\n\r\ndef legacy_bandpass(image, lshort, llong, threshold=None):\r\n    \"\"\"Remove noise and background variation.\r\n\r\n    Convolve with a Gaussian to remove short-wavelength noise and subtract out\r\n    long-wavelength variations, retaining features of intermediate scale.\r\n\r\n    This implementation performs a Fourier transform using numpy.\r\n    In benchmarks using typical inputs, it was found to be slower than the\r\n    ``bandpass`` function in this module.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n    lshort : small-scale cutoff (noise)\r\n    llong : large-scale cutoff\r\n    for both lshort and llong:\r\n        give a tuple value for different sizes per dimension\r\n        give int value for same value for all dimensions\r\n        when 2*lshort >= llong, no noise filtering is applied\r\n    threshold : float or integer\r\n        By default, 1 for integer images and 1/256. for float images.\r\n\r\n    Returns\r\n    -------\r\n    result : array\r\n        the bandpassed image\r\n\r\n    See Also\r\n    --------\r\n    bandpass, legacy_bandpass_fftw\r\n    \"\"\"\r\n    fftn = np.fft.fftn\r\n    ifftn = np.fft.ifftn\r\n    lshort = validate_tuple(lshort, image.ndim)\r\n    llong = validate_tuple(llong, image.ndim)\r\n    if np.any([x*2 >= y for (x, y) in zip(lshort, llong)]):\r\n        raise ValueError(\"The smoothing length scale must be more\" +\r\n                         \"than twice the noise length scale.\")\r\n    if threshold is None:\r\n        if np.issubdtype(image.dtype, np.integer):\r\n            threshold = 1\r\n        else:\r\n            threshold = 1/256.\r\n    # Perform a rolling average (boxcar) with kernel size = 2*llong + 1\r\n    boxcar = np.asarray(image)\r\n    for (axis, size) in enumerate(llong):\r\n        boxcar = uniform_filter1d(boxcar, size*2+1, axis, mode='nearest',\r\n                                  cval=0)\r\n    # Perform a gaussian filter\r\n    gaussian = ifftn(fourier_gaussian(fftn(image), lshort)).real\r\n\r\n    result = gaussian - boxcar\r\n    return np.where(result > threshold, result, 0)\r\n\r\n\r\ndef legacy_bandpass_fftw(image, lshort, llong, threshold=None):\r\n    \"\"\"Remove noise and background variation.\r\n\r\n    Convolve with a Gaussian to remove short-wavelength noise and subtract out\r\n    long-wavelength variations, retaining features of intermediate scale.\r\n\r\n    This implementation performs a Fourier transform using FFTW\r\n    (Fastest Fourier Transform in the West). Without FFTW and pyfftw, it\r\n    will raise an ImportError\r\n\r\n    In benchmarks using typical inputs, it was found to be slower than the\r\n    ``bandpass`` function in this module.\r\n\r\n    Parameters\r\n    ----------\r\n    image : ndarray\r\n    lshort : small-scale cutoff (noise)\r\n    llong : large-scale cutoff\r\n    for both lshort and llong:\r\n        give a tuple value for different sizes per dimension\r\n        give int value for same value for all dimensions\r\n        when 2*lshort >= llong, no noise filtering is applied\r\n    threshold : float or integer\r\n        By default, 1 for integer images and 1/256. for float images.\r\n\r\n    Returns\r\n    -------\r\n    result : array\r\n        the bandpassed image\r\n\r\n    See Also\r\n    --------\r\n    bandpass, legacy_bandpass\r\n    \"\"\"\r\n    if not FFTW_AVAILABLE:\r\n        raise ImportError(\"This implementation requires pyfftw.\")\r\n    lshort = validate_tuple(lshort, image.ndim)\r\n    llong = validate_tuple(llong, image.ndim)\r\n    if np.any([x*2 >= y for (x, y) in zip(lshort, llong)]):\r\n        raise ValueError(\"The smoothing length scale must be more\" +\r\n                         \"than twice the noise length scale.\")\r\n    if threshold is None:\r\n        if np.issubdtype(image.dtype, np.integer):\r\n            threshold = 1\r\n        else:\r\n            threshold = 1/256.", "start_char_idx": 7609, "end_char_idx": 11736, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ed31e661-e370-4374-89ad-42f25ea4d794": {"__data__": {"id_": "ed31e661-e370-4374-89ad-42f25ea4d794", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6eff1c77-d741-4887-84c3-a75c26a30af4", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "38e43daf146d33b3b3995ad84573e930081e2e61d39ac0427f3b3ccedf7439ad", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8b3d4e32-ddb3-4eda-b1d7-bd348c98b8c9", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "09f816394a267cd8fecf9de8ace23475f6df54e994b09d5652ec74612bf1f04f", "class_name": "RelatedNodeInfo"}}, "text": "for float images.\r\n\r\n    Returns\r\n    -------\r\n    result : array\r\n        the bandpassed image\r\n\r\n    See Also\r\n    --------\r\n    bandpass, legacy_bandpass\r\n    \"\"\"\r\n    if not FFTW_AVAILABLE:\r\n        raise ImportError(\"This implementation requires pyfftw.\")\r\n    lshort = validate_tuple(lshort, image.ndim)\r\n    llong = validate_tuple(llong, image.ndim)\r\n    if np.any([x*2 >= y for (x, y) in zip(lshort, llong)]):\r\n        raise ValueError(\"The smoothing length scale must be more\" +\r\n                         \"than twice the noise length scale.\")\r\n    if threshold is None:\r\n        if np.issubdtype(image.dtype, np.integer):\r\n            threshold = 1\r\n        else:\r\n            threshold = 1/256.\r\n    # Perform a rolling average (boxcar) with kernel size = 2*llong + 1\r\n    boxcar = np.asarray(image)\r\n    for (axis, size) in enumerate(llong):\r\n        boxcar = uniform_filter1d(boxcar, size*2+1, axis, mode='nearest',\r\n                                  cval=0)\r\n    # Perform a gaussian filter\r\n    gaussian = ifftn(fourier_gaussian(fftn(image), lshort)).real\r\n\r\n    result = gaussian - boxcar\r\n    return np.where(result > threshold, result, 0)\r\n\r\n\r\ndef scalefactor_to_gamut(image, original_dtype):\r\n    return np.iinfo(original_dtype).max / image.max()\r\n\r\n\r\ndef scale_to_gamut(image, original_dtype, scale_factor=None):\r\n    if scale_factor is None:\r\n        scale_factor = scalefactor_to_gamut(image, original_dtype)\r\n    scaled = (scale_factor * image.clip(min=0.)).astype(original_dtype)\r\n    return scaled", "start_char_idx": 11032, "end_char_idx": 12553, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "328deb55-38b7-4c8d-9612-96dd37f39df8": {"__data__": {"id_": "328deb55-38b7-4c8d-9612-96dd37f39df8", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "33475eeb-211e-4d3b-bea8-9814bb151a88", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "882c66e2c0cb98fd636e85ce85aabd4fe6892aa2177e599b298bbc39f33fd350", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fa7e52b2-6abb-4f84-ab65-484b24861dc5", "node_type": "1", "metadata": {}, "hash": "f6e487bc53dfcbbbb1fe0e9d824ebf172aba1f54239a66a79abe5c5fde84d51a", "class_name": "RelatedNodeInfo"}}, "text": "from scipy.spatial import cKDTree\r\nfrom .utils import guess_pos_columns\r\nimport numpy as np\r\nfrom pandas import DataFrame\r\n\r\nfrom .utils import pandas_concat\r\n\r\n# Maximum number of elements in the array of all distances.\r\n# Should be roughly (bytes of available memory)/16\r\nMAX_ARRAY_SIZE = 1e8\r\n\r\n\r\ndef proximity(features, pos_columns=None):\r\n    \"\"\"Find the distance to each feature's nearest neighbor.\r\n\r\n    Parameters\r\n    ----------\r\n    features : DataFrame\r\n    pos_columns : list of column names\r\n        ['x', 'y'] by default\r\n\r\n    Returns\r\n    -------\r\n    proximity : DataFrame\r\n        distance to each particle's nearest neighbor,\r\n        indexed by particle if 'particle' column is present in input\r\n\r\n    Examples\r\n    --------\r\n    Find the proximity of each particle to its nearest neighbor in every frame.\r\n\r\n    >>> prox = t.groupby('frame').apply(proximity).reset_index()\r\n    >>> avg_prox = prox.groupby('particle')['proximity'].mean()\r\n\r\n    And filter the trajectories...\r\n\r\n    >>> particle_nos = avg_prox[avg_prox > 20].index\r\n    >>> t_filtered = t[t['particle'].isin(particle_nos)]\r\n    \"\"\"\r\n    if pos_columns is None:\r\n        pos_columns = ['x', 'y']\r\n    leaf_size = max(1, int(np.round(np.log10(len(features)))))\r\n    tree = cKDTree(features[pos_columns].copy(), leaf_size)\r\n    proximity = tree.query(tree.data, 2)[0][:, 1]\r\n    result = DataFrame({'proximity': proximity})\r\n    if 'particle' in features:\r\n        result.set_index(features['particle'], inplace=True)\r\n    return result\r\n\r\n\r\ndef pair_correlation_2d(feat, cutoff, fraction=1., dr=.5, p_indices=None,\r\n                        ndensity=None, boundary=None, handle_edge=True,\r\n                        max_rel_ndensity=10):\r\n    \"\"\"Calculate the pair correlation function in 2 dimensions.\r\n\r\n    Parameters\r\n    ----------\r\n    feat : Pandas DataFrame\r\n        DataFrame containing the x and y coordinates of particles\r\n    cutoff : float\r\n        Maximum distance to calculate g(r)\r\n    fraction : float, optional\r\n        The fraction of particles to calculate g(r) with. May be used to\r\n        increase speed of function. Particles selected at random.\r\n    dr : float, optional\r\n        The bin width\r\n    p_indices : list or ndarray, optional\r\n        Only consider a pair of particles if one of them is in 'p_indices'.\r\n        Uses zero-based indexing, regardless of how 'feat' is indexed.\r\n    ndensity : float, optional\r\n        Density of particle packing. If not specified, density will be\r\n        calculated assuming rectangular homogeneous arrangement.\r\n    boundary : tuple, optional\r\n        Tuple specifying rectangular prism boundary of particles (xmin, xmax,\r\n        ymin, ymax). Must be floats. Default is to assume a rectangular packing.\r\n        Boundaries are determined by edge particles.\r\n    handle_edge : boolean, optional\r\n        If true, compensate for reduced area around particles near the edges.\r\n    max_rel_ndensity : number, optional\r\n        The relative maximum density deviation, used to estimate the maximum\r\n        number of neighbours. Lower numbers increase performance, until the\r\n        method fails because there are more neighbours than expected.\r\n\r\n    Returns\r\n    -------\r\n    r_edges : array\r\n        The bin edges, with 1 more element than g_r.\r\n    g_r : array\r\n        The values of g_r.\r\n    \"\"\"", "start_char_idx": 0, "end_char_idx": 3351, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fa7e52b2-6abb-4f84-ab65-484b24861dc5": {"__data__": {"id_": "fa7e52b2-6abb-4f84-ab65-484b24861dc5", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "33475eeb-211e-4d3b-bea8-9814bb151a88", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "882c66e2c0cb98fd636e85ce85aabd4fe6892aa2177e599b298bbc39f33fd350", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "328deb55-38b7-4c8d-9612-96dd37f39df8", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e06b0cd5330760ae4b4f7e5789259743bd16fc27e2782f3b3734639784b450b7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e2d373b3-70f9-465b-a292-5a1f5ff2b04e", "node_type": "1", "metadata": {}, "hash": "854e4ff4356a1c888f7420d5a8732d9fc4191c0a63f8f9c8da6abc1c02f763ca", "class_name": "RelatedNodeInfo"}}, "text": "ndensity : float, optional\r\n        Density of particle packing. If not specified, density will be\r\n        calculated assuming rectangular homogeneous arrangement.\r\n    boundary : tuple, optional\r\n        Tuple specifying rectangular prism boundary of particles (xmin, xmax,\r\n        ymin, ymax). Must be floats. Default is to assume a rectangular packing.\r\n        Boundaries are determined by edge particles.\r\n    handle_edge : boolean, optional\r\n        If true, compensate for reduced area around particles near the edges.\r\n    max_rel_ndensity : number, optional\r\n        The relative maximum density deviation, used to estimate the maximum\r\n        number of neighbours. Lower numbers increase performance, until the\r\n        method fails because there are more neighbours than expected.\r\n\r\n    Returns\r\n    -------\r\n    r_edges : array\r\n        The bin edges, with 1 more element than g_r.\r\n    g_r : array\r\n        The values of g_r.\r\n    \"\"\"\r\n\r\n    if boundary is None:\r\n        xmin, xmax, ymin, ymax = (feat.x.min(), feat.x.max(),\r\n                                  feat.y.min(), feat.y.max())\r\n    else:\r\n        xmin, xmax, ymin, ymax = boundary\r\n\r\n        # Disregard all particles outside the bounding box\r\n        feat = feat[(feat.x >= xmin) & (feat.x <= xmax) &\r\n                    (feat.y >= ymin) & (feat.y <= ymax)]\r\n\r\n    if ndensity is None:  # particle packing density\r\n        ndensity = (feat.x.count() - 1) / ((xmax - xmin) * (ymax - ymin))\r\n\r\n    if p_indices is None:\r\n        if fraction == 1.:\r\n            p_indices = slice(len(feat))\r\n        else:  # grab random sample of particles\r\n            p_indices = np.random.randint(0, len(feat),\r\n                                          int(fraction * len(feat)))\r\n\r\n    # radii bins to search for particles\r\n    r_edges = np.arange(0, cutoff + dr, dr)\r\n\r\n    # initialize kdtree for fast neighbor search\r\n    ckdtree = cKDTree(feat[['x', 'y']])\r\n    pos = ckdtree.data[p_indices]\r\n\r\n    # Estimate upper bound for neighborhood particle count\r\n    max_p_count = int(np.pi * (r_edges.max() + dr)**2 *\r\n                      ndensity * max_rel_ndensity)\r\n    # Protect against too large memory usage\r\n    if len(pos) * max_p_count > MAX_ARRAY_SIZE:\r\n          raise MemoryError('The distance array will be larger than the maximum '\r\n                          'allowed size. Please reduce the cutoff or '\r\n                          'max_rel_ndensity. Or run the analysis on a fraction '\r\n                          'of the features using the fraction parameter.')\r\n\r\n    dist, idxs = ckdtree.query(pos, k=max_p_count, distance_upper_bound=cutoff)\r\n    if np.any(np.isfinite(dist[:, -1])):\r\n        raise RuntimeError(\"There are too many particle pairs per particle. \"\r\n                           \"Apparently, density fluctuations are larger than \"\r\n                           \"max_rel_ndensity. Please increase it.\")\r\n\r\n    # drop zero and infinite dist values\r\n    mask = (dist > 0) & np.isfinite(dist)\r\n    dist = dist[mask]\r\n\r\n    if handle_edge:\r\n        pos_repeated = pos[:, np.newaxis].repeat(max_p_count, axis=1)[mask]\r\n        arclen = arclen_2d_bounded(dist, pos_repeated,\r\n                                   np.array([[xmin, xmax], [ymin, ymax]]))\r\n    else:\r\n        arclen = 2*np.pi*dist\r\n    g_r = np.histogram(dist, bins=r_edges, weights=1/arclen)[0]\r\n\r\n    return r_edges, g_r / (ndensity * len(pos) * dr)\r\n\r\n\r\ndef pair_correlation_3d(feat, cutoff, fraction=1., dr=.5, p_indices=None,\r\n                        ndensity=None, boundary=None, handle_edge=True,\r\n                        max_rel_ndensity=10):\r\n    \"\"\"Calculate the pair correlation function in 3 dimensions.\r\n\r\n    Parameters\r\n    ----------\r\n    feat : Pandas DataFrame\r\n        DataFrame containing the x, y and z coordinates of particles\r\n    cutoff : float\r\n        Maximum distance to calculate g(r)\r\n    fraction : float, optional\r\n        The fraction of particles to calculate g(r) with. May be used to\r\n        increase speed of function. Particles selected at random.\r\n    dr : float, optional\r\n        The bin width\r\n    p_indices : list or ndarray, optional\r\n        Only consider a pair of particles if one of them is in 'p_indices'.\r\n        Uses zero-based indexing, regardless of how 'feat' is indexed.\r\n    ndensity : float, optional\r\n        Density of particle packing. If not specified, density will be\r\n        calculated assuming rectangular homogeneous arrangement.", "start_char_idx": 2400, "end_char_idx": 6844, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e2d373b3-70f9-465b-a292-5a1f5ff2b04e": {"__data__": {"id_": "e2d373b3-70f9-465b-a292-5a1f5ff2b04e", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "33475eeb-211e-4d3b-bea8-9814bb151a88", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "882c66e2c0cb98fd636e85ce85aabd4fe6892aa2177e599b298bbc39f33fd350", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fa7e52b2-6abb-4f84-ab65-484b24861dc5", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "dd35af6637937b59d76a1457311cb1b77bca5008929b497c58523126d09282ca", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "00e0f831-a1ed-4d02-82ae-aa620fc5d848", "node_type": "1", "metadata": {}, "hash": "3a6b94cf5dd42f769bb87bb79160904d575a1279c4b28cc52df9a6e503d367c3", "class_name": "RelatedNodeInfo"}}, "text": "Parameters\r\n    ----------\r\n    feat : Pandas DataFrame\r\n        DataFrame containing the x, y and z coordinates of particles\r\n    cutoff : float\r\n        Maximum distance to calculate g(r)\r\n    fraction : float, optional\r\n        The fraction of particles to calculate g(r) with. May be used to\r\n        increase speed of function. Particles selected at random.\r\n    dr : float, optional\r\n        The bin width\r\n    p_indices : list or ndarray, optional\r\n        Only consider a pair of particles if one of them is in 'p_indices'.\r\n        Uses zero-based indexing, regardless of how 'feat' is indexed.\r\n    ndensity : float, optional\r\n        Density of particle packing. If not specified, density will be\r\n        calculated assuming rectangular homogeneous arrangement.\r\n    boundary : tuple, optional\r\n        Tuple specifying rectangular boundary of particles (xmin, xmax,\r\n        ymin, ymax, zmin, zmax). Must be floats. Default is to assume a\r\n        rectangular packing. Boundaries are determined by edge particles.\r\n    handle_edge : boolean, optional\r\n        If true, compensate for reduced volume around particles near the edges.\r\n    max_rel_ndensity : number, optional\r\n        The relative maximum density deviation, used to estimate the maximum\r\n        number of neighbours. Lower numbers increase performance, until the\r\n        method fails because there are more neighbours than expected.\r\n\r\n    Returns\r\n    -------\r\n    r_edges : array\r\n        The bin edges, with 1 more element than g_r.\r\n    g_r : array\r\n        The values of g_r.\r\n    \"\"\"\r\n\r\n    if boundary is None:\r\n        xmin, xmax, ymin, ymax, zmin, zmax = (feat.x.min(), feat.x.max(),\r\n                                              feat.y.min(), feat.y.max(),\r\n                                              feat.z.min(), feat.z.max())\r\n    else:\r\n        xmin, xmax, ymin, ymax, zmin, zmax = boundary\r\n\r\n        # Disregard all particles outside the bounding box\r\n        feat = feat[(feat.x >= xmin) & (feat.x <= xmax) &\r\n                    (feat.y >= ymin) & (feat.y <= ymax) &\r\n                    (feat.z >= zmin) & (feat.z <= zmax)]\r\n\r\n    if ndensity is None:  # particle packing density\r\n        ndensity = (feat.x.count() - 1) / \\\r\n                   ((xmax - xmin) * (ymax - ymin) * (zmax - zmin))\r\n\r\n    if p_indices is None:\r\n        if fraction == 1.:\r\n            p_indices = slice(len(feat))\r\n        else:  # grab random sample of particles\r\n            p_indices = np.random.randint(0, len(feat),\r\n                                          int(fraction * len(feat)))\r\n\r\n    # radii bins to search for particles\r\n    r_edges = np.arange(0, cutoff + dr, dr)\r\n\r\n    # initialize kdtree for fast neighbor search\r\n    ckdtree = cKDTree(feat[['x', 'y', 'z']])\r\n    pos = ckdtree.data[p_indices]\r\n\r\n    # Estimate upper bound for neighborhood particle count\r\n    max_p_count = int((4./3.) * np.pi * (r_edges.max() + dr)**3 *\r\n                      ndensity * max_rel_ndensity)\r\n    # Protect against too large memory usage\r\n    if len(pos) * max_p_count > MAX_ARRAY_SIZE:\r\n        raise MemoryError('The distance array will be larger than the maximum '\r\n                          'allowed size. Please reduce the cutoff or '\r\n                          'max_rel_ndensity. Or run the analysis on a fraction '\r\n                          'of the features using the fraction parameter.')\r\n\r\n    dist, idxs = ckdtree.query(pos, k=max_p_count, distance_upper_bound=cutoff)\r\n    if np.any(np.isfinite(dist[:, -1])):\r\n        raise RuntimeError(\"There are too many particle pairs in the frame. \"\r\n                           \"Please reduce the cutoff distance, increase \"\r\n                           \"max_rel_ndensity, or use a fraction.\")", "start_char_idx": 6071, "end_char_idx": 9797, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "00e0f831-a1ed-4d02-82ae-aa620fc5d848": {"__data__": {"id_": "00e0f831-a1ed-4d02-82ae-aa620fc5d848", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "33475eeb-211e-4d3b-bea8-9814bb151a88", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "882c66e2c0cb98fd636e85ce85aabd4fe6892aa2177e599b298bbc39f33fd350", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e2d373b3-70f9-465b-a292-5a1f5ff2b04e", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "7be448bf4d7e259d87cb7762d4f1520a4e0c7ce7efaacf15355c523706f17334", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c7bd55a2-2933-4ef3-bc98-37c0c0944fd2", "node_type": "1", "metadata": {}, "hash": "be2a6391ddc291ce2ecbd1eb61444a7e19fb31ca0ef4862dc7d8942648504f31", "class_name": "RelatedNodeInfo"}}, "text": "* np.pi * (r_edges.max() + dr)**3 *\r\n                      ndensity * max_rel_ndensity)\r\n    # Protect against too large memory usage\r\n    if len(pos) * max_p_count > MAX_ARRAY_SIZE:\r\n        raise MemoryError('The distance array will be larger than the maximum '\r\n                          'allowed size. Please reduce the cutoff or '\r\n                          'max_rel_ndensity. Or run the analysis on a fraction '\r\n                          'of the features using the fraction parameter.')\r\n\r\n    dist, idxs = ckdtree.query(pos, k=max_p_count, distance_upper_bound=cutoff)\r\n    if np.any(np.isfinite(dist[:, -1])):\r\n        raise RuntimeError(\"There are too many particle pairs in the frame. \"\r\n                           \"Please reduce the cutoff distance, increase \"\r\n                           \"max_rel_ndensity, or use a fraction.\")\r\n\r\n    # drop zero and infinite dist values\r\n    mask = (dist > 0) & np.isfinite(dist)\r\n    dist = dist[mask]\r\n\r\n    if handle_edge:\r\n        pos_repeated = pos[:, np.newaxis].repeat(max_p_count, axis=1)[mask]\r\n        area = area_3d_bounded(dist, pos_repeated,\r\n                               np.array([[xmin, xmax], [ymin, ymax],\r\n                                         [zmin, zmax]]))\r\n    else:\r\n        area = 4*np.pi*dist**2\r\n    g_r = np.histogram(dist, bins=r_edges, weights=1/area)[0]\r\n\r\n    return r_edges, g_r / (ndensity * len(pos) * dr)\r\n\r\n\r\ndef circle_cap_arclen(h, r):\r\n    \"\"\" Length of a circle arc of circle with radius R that is bounded by\r\n    a straight line `h` from the origin. h >= 0, h < R\"\"\"\r\n    return 2*r*np.arccos(h / r)\r\n\r\n\r\ndef circle_corner_arclen(h1, h2, r):\r\n    \"\"\" Length of a circle arc of circle with radius R that is bounded by\r\n    two perpendicular straight lines `h1` and `h2` from the origin.\r\n    h1**2 + h2**2 < R**2\r\n    h1 >= R\r\n    h2 >= R\r\n    \"\"\"\r\n    return r*(np.arccos(h2 / r) - np.arcsin(h1 / r))\r\n\r\n\r\ndef sphere_cap_area(h, r):\r\n    \"\"\" Area of a sphere cap of sphere with radius R that is bounded by\r\n    a flat plane `h` from the origin. h >= 0, h < R\"\"\"\r\n    return 2*np.pi*r*(r-h)\r\n\r\n\r\ndef sphere_edge_area(x, y, r):\r\n    \"\"\" Area of a sphere 'edge' of sphere with radius R that is bounded by\r\n    two perpendicular flat planes `h0`, `h1` from the origin. h >= 0, h < R\"\"\"\r\n    p = np.sqrt(r**2 - x**2 - y**2)\r\n    A = (r - x - y)*np.pi - 2*r*np.arctan(x*y/(p*r)) + \\\r\n        2*x*np.arctan(y/p) + 2*y*np.arctan(x/p)\r\n    return A*r\r\n\r\n\r\ndef sphere_corner_area(x, y, z, r):\r\n    \"\"\" Area of a sphere 'corner' of sphere with radius R that is bounded by\r\n    three perpendicular flat planes `h0`, `h1`, `h2` from the origin. \"\"\"\r\n    pxy = np.sqrt(r**2 - x**2 - y**2)\r\n    pyz = np.sqrt(r**2 - y**2 - z**2)\r\n    pxz = np.sqrt(r**2 - x**2 - z**2)\r\n    A = np.pi*(r - x - y - z)/2 + \\\r\n        x*(np.arctan(y/pxy) + np.arctan(z/pxz)) - r*np.arctan(y*z/(r*pyz)) + \\\r\n        y*(np.arctan(x/pxy) + np.arctan(z/pyz)) - r*np.arctan(x*z/(r*pxz)) + \\\r\n        z*(np.arctan(x/pxz) + np.arctan(y/pyz)) - r*np.arctan(x*y/(r*pxy))\r\n    return A*r\r\n\r\n\r\ndef _protect_mask(mask):\r\n    \"\"\" Boolean masks with length 1 may give a problem in the following syntax:\r\n    array[mask] = 2 * array[mask]. Replace [True] by 0 and return None when\r\n    the operation should be skipped.\"\"\"", "start_char_idx": 8957, "end_char_idx": 12221, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c7bd55a2-2933-4ef3-bc98-37c0c0944fd2": {"__data__": {"id_": "c7bd55a2-2933-4ef3-bc98-37c0c0944fd2", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "33475eeb-211e-4d3b-bea8-9814bb151a88", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "882c66e2c0cb98fd636e85ce85aabd4fe6892aa2177e599b298bbc39f33fd350", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "00e0f831-a1ed-4d02-82ae-aa620fc5d848", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "e9aa92185c94e5a4b0334a3febe8bbf3ad16d79daaf3a71a80f02dac749db1b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "85c6f2ad-a505-42a1-b5d2-449f2231304a", "node_type": "1", "metadata": {}, "hash": "b927428cf77e8bbb450103c28487250b6fcef742fddb12f3a8a3892ab6ff875a", "class_name": "RelatedNodeInfo"}}, "text": "Replace [True] by 0 and return None when\r\n    the operation should be skipped.\"\"\"\r\n    if mask.size == 0:\r\n        return None  # []\r\n    elif mask.size > 1:\r\n        return mask  # mask with len > 1\r\n    if mask.ravel()[0]:\r\n        return 0     # [True]\r\n    else:\r\n        return None  # [False]\r\n\r\n\r\ndef arclen_2d_bounded(dist, pos, box):\r\n    arclen = 2*np.pi*dist\r\n\r\n    h = np.array([pos[:, 0] - box[0, 0], box[0, 1] - pos[:, 0],\r\n                  pos[:, 1] - box[1, 0], box[1, 1] - pos[:, 1]])\r\n\r\n    for h0 in h:\r\n        mask = _protect_mask(h0 < dist)\r\n        if mask is None:\r\n            continue\r\n        arclen[mask] -= circle_cap_arclen(h0[mask], dist[mask])\r\n\r\n    for h1, h2 in [[0, 2], [0, 3], [1, 2], [1, 3]]:  # adjacent sides\r\n        mask = _protect_mask(h[h1]**2 + h[h2]**2 < dist**2)\r\n        if mask is None:\r\n            continue\r\n        arclen[mask] += circle_corner_arclen(h[h1, mask], h[h2, mask],\r\n                                             dist[mask])\r\n\r\n    arclen[arclen < 10**-5 * dist] = np.nan\r\n    return arclen\r\n\r\n\r\ndef area_3d_bounded(dist, pos, box):\r\n    \"\"\" Calculated using the surface area of a sphere equidistant\r\n    to a certain point.\r\n\r\n    When the sphere is truncated by the box boundaries, this distance\r\n    is subtracted using the formula for the sphere cap surface. We\r\n    calculate this by defining h = the distance from point to box edge.\r\n\r\n    When for instance sphere is bounded by the top and right boundaries,\r\n    the area in the edge may be counted double. This is the case when\r\n    h1**2 + h2**2 < R**2. This double counted area is calculated\r\n    and added if necessary.\r\n\r\n    When the sphere is bounded by three adjacant boundaries,\r\n    the area in the corner may be subtracted double. This is the case when\r\n    h1**2 + h2**2 + h3**2 < R**2. This double counted area is calculated\r\n    and added if necessary.\r\n\r\n    The result is the sum of the weights of pos0 and pos1.\"\"\"", "start_char_idx": 12140, "end_char_idx": 14092, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "85c6f2ad-a505-42a1-b5d2-449f2231304a": {"__data__": {"id_": "85c6f2ad-a505-42a1-b5d2-449f2231304a", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "33475eeb-211e-4d3b-bea8-9814bb151a88", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "882c66e2c0cb98fd636e85ce85aabd4fe6892aa2177e599b298bbc39f33fd350", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7bd55a2-2933-4ef3-bc98-37c0c0944fd2", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d8bd5e59a50ece065dbb7ef35a1e5ffc02f14a0a0e73f2aa02321171c47c2dec", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a1bd4651-cb3c-4cab-a0e1-9dc57d636a51", "node_type": "1", "metadata": {}, "hash": "27a21fd0b0464b5e9f014e83d423c7012d47295915d5d2380ea3a551b5a77a15", "class_name": "RelatedNodeInfo"}}, "text": "When the sphere is truncated by the box boundaries, this distance\r\n    is subtracted using the formula for the sphere cap surface. We\r\n    calculate this by defining h = the distance from point to box edge.\r\n\r\n    When for instance sphere is bounded by the top and right boundaries,\r\n    the area in the edge may be counted double. This is the case when\r\n    h1**2 + h2**2 < R**2. This double counted area is calculated\r\n    and added if necessary.\r\n\r\n    When the sphere is bounded by three adjacant boundaries,\r\n    the area in the corner may be subtracted double. This is the case when\r\n    h1**2 + h2**2 + h3**2 < R**2. This double counted area is calculated\r\n    and added if necessary.\r\n\r\n    The result is the sum of the weights of pos0 and pos1.\"\"\"\r\n\r\n    area = 4*np.pi*dist**2\r\n\r\n    h = np.array([pos[:, 0] - box[0, 0], box[0, 1] - pos[:, 0],\r\n                  pos[:, 1] - box[1, 0], box[1, 1] - pos[:, 1],\r\n                  pos[:, 2] - box[2, 0], box[2, 1] - pos[:, 2]])\r\n\r\n    for h0 in h:\r\n        mask = _protect_mask(h0 < dist)\r\n        if mask is None:\r\n            continue\r\n        area[mask] -= sphere_cap_area(h0[mask], dist[mask])\r\n\r\n    for h1, h2 in [[0, 2], [0, 3], [0, 4], [0, 5],\r\n                   [1, 2], [1, 3], [1, 4], [1, 5],\r\n                   [2, 4], [2, 5], [3, 4], [3, 5]]:  # 2 adjacent sides\r\n        mask = _protect_mask(h[h1]**2 + h[h2]**2 < dist**2)\r\n        if mask is None:\r\n            continue\r\n        area[mask] += sphere_edge_area(h[h1, mask], h[h2, mask],\r\n                                       dist[mask])\r\n\r\n    for h1, h2, h3 in [[0, 2, 4], [0, 2, 5], [0, 3, 4], [0, 3, 5], [1, 2, 4],\r\n                       [1, 2, 5], [1, 3, 4], [1, 3, 5]]:  # 3 adjacent sides\r\n        mask = _protect_mask(h[h1]**2 + h[h2]**2 + h[h3]**2 < dist**2)\r\n        if mask is None:\r\n            continue\r\n        area[mask] -= sphere_corner_area(h[h1, mask], h[h2, mask],\r\n                                         h[h3, mask], dist[mask])\r\n\r\n    area[area < 10**-7 * dist**2] = np.nan\r\n\r\n    return area\r\n\r\n\r\nclass Clusters:\r\n    \"\"\" Class that clusters features.\"\"\"", "start_char_idx": 13336, "end_char_idx": 15438, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a1bd4651-cb3c-4cab-a0e1-9dc57d636a51": {"__data__": {"id_": "a1bd4651-cb3c-4cab-a0e1-9dc57d636a51", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "33475eeb-211e-4d3b-bea8-9814bb151a88", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "882c66e2c0cb98fd636e85ce85aabd4fe6892aa2177e599b298bbc39f33fd350", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "85c6f2ad-a505-42a1-b5d2-449f2231304a", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "dc3045c9521193007fac952f2b9c932303b856b0f411ac758a4642e691f63239", "class_name": "RelatedNodeInfo"}}, "text": "@classmethod\r\n    def from_pairs(cls, pairs, length):\r\n        clusters = cls(range(length))\r\n        for (a, b) in pairs:\r\n            clusters.add(a, b)\r\n        return clusters\r\n\r\n    @classmethod\r\n    def from_kdtree(cls, kdtree, separation):\r\n        pairs = kdtree.query_pairs(separation)\r\n        return cls.from_pairs(pairs, len(kdtree.data))\r\n\r\n    @classmethod\r\n    def from_coords(cls, coords, separation):\r\n        pairs = cKDTree(np.array(coords) / separation).query_pairs(1)\r\n        return cls.from_pairs(pairs, len(coords))\r\n\r\n    def __init__(self, indices):\r\n        self.clusters = {i: {i} for i in indices}\r\n        self.pos_ids = list(indices)\r\n\r\n    def __iter__(self):\r\n        return (list(self.clusters[k]) for k in self.clusters)\r\n\r\n    def add(self, a, b):\r\n        i1 = self.pos_ids[a]\r\n        i2 = self.pos_ids[b]\r\n        if i1 != i2:  # if a and b are already clustered, do nothing\r\n            self.clusters[i1] = self.clusters[i1].union(self.clusters[i2])\r\n            for f in self.clusters[i2]:\r\n                self.pos_ids[f] = i1\r\n            del self.clusters[i2]\r\n\r\n    @property\r\n    def cluster_size(self):\r\n        result = [None] * len(self.pos_ids)\r\n        for cluster in self:\r\n            for f in cluster:\r\n                result[f] = len(cluster)\r\n        return result\r\n\r\n\r\ndef cluster_iter(f, separation, pos_columns=None, t_column='frame'):\r\n    \"\"\" Cluster features, returns generator iterating over frames.\r\n\r\n    Returns\r\n    -------\r\n    generator of:\r\n        frame_no\r\n        DataFrame with added cluster and cluster_size column\r\n\r\n    See also\r\n    --------\r\n    find_clusters\r\n    \"\"\"\r\n    if pos_columns is None:\r\n        pos_columns = guess_pos_columns(f)\r\n\r\n    next_id = 0\r\n\r\n    for frame_no, f_frame in f.groupby(t_column):\r\n        clusters = Clusters.from_coords(f_frame[pos_columns].values, separation)\r\n        result = f_frame.copy()\r\n        result['cluster'] = clusters.pos_ids\r\n        result['cluster_size'] = clusters.cluster_size\r\n        result['cluster'] += next_id\r\n        next_id = result['cluster'].max() + 1\r\n        yield frame_no, result\r\n\r\n\r\ndef cluster(f, separation, pos_columns=None, t_column='frame'):\r\n    \"\"\" Cluster features from one or several frames.\r\n\r\n    A cluster is defined as the largest group of features of which each feature\r\n    has at least one feature closer than ``separation``.\r\n\r\n    Parameters\r\n    ----------\r\n    f: DataFrame\r\n        pandas DataFrame containing pos_columns and t_column\r\n    separation: number or tuple\r\n        Separation distance below which particles are considered inside cluster\r\n    pos_columns: list of strings, optional\r\n        Column names that contain the position coordinates.\r\n        Defaults to ['y', 'x'] (or ['z', 'y', 'x'] if 'z' exists)\r\n    t_column: string\r\n        Column name containing the frame number (Default: 'frame')\r\n\r\n    Returns\r\n    -------\r\n    Copy of ``f`` with added \"cluster\" and \"cluster_size\" column\r\n    \"\"\"\r\n    if t_column not in f:\r\n        f[t_column] = 0\r\n        remove_t_column = True\r\n    else:\r\n        remove_t_column = False\r\n\r\n    result = pandas_concat(x[1] for x in cluster_iter(f, separation, pos_columns,\r\n                                                   t_column))\r\n\r\n    if remove_t_column:\r\n        del f[t_column]\r\n\r\n    return result", "start_char_idx": 15444, "end_char_idx": 18776, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "daf23db7-2e87-4dcc-9644-33c491552f4c": {"__data__": {"id_": "daf23db7-2e87-4dcc-9644-33c491552f4c", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\tracking.py", "file_name": "tracking.py", "file_type": "text/x-python", "file_size": 41, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d62af2ac-59fc-49bf-929a-cfc3267c326e", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\tracking.py", "file_name": "tracking.py", "file_type": "text/x-python", "file_size": 41, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "2637c50fcdf927119efb9e06e063521319dad06430d90990de01d060714be365", "class_name": "RelatedNodeInfo"}}, "text": "from trackpy.linking import *  # legacy", "start_char_idx": 0, "end_char_idx": 39, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b245d025-bcd9-48c8-bade-5fe385a2e175": {"__data__": {"id_": "b245d025-bcd9-48c8-bade-5fe385a2e175", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\try_numba.py", "file_name": "try_numba.py", "file_type": "text/x-python", "file_size": 3171, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8b0f921c-88eb-469d-a896-42883dba0683", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\try_numba.py", "file_name": "try_numba.py", "file_type": "text/x-python", "file_size": 3171, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "cc2b046e1b7a853734605c2a68fab25a0d2ae9249106ca7b9bd5cd4f72b4ec78", "class_name": "RelatedNodeInfo"}}, "text": "import sys\r\nimport warnings\r\n\r\n# re-import some builtins for legacy numba versions if future is installed\r\ntry:\r\n    from __builtin__ import int, round\r\nexcept ImportError:\r\n    from builtins import int, round\r\n\r\nENABLE_NUMBA_ON_IMPORT = True\r\n_registered_functions = list()  # functions that can be numba-compiled\r\n\r\nNUMBA_AVAILABLE = True\r\nmessage = ''\r\n\r\ntry:\r\n    # numba deprecationwarnings from numpy 1.20\r\n    with warnings.catch_warnings():\r\n        warnings.filterwarnings(\"ignore\", module=\"numpy\")\r\n        import numba\r\nexcept ImportError:\r\n    NUMBA_AVAILABLE = False\r\n    message = (\"To use numba-accelerated variants of core \"\r\n               \"functions, you must install numba.\")\r\n\r\n\r\nclass RegisteredFunction:\r\n    \"\"\"Enable toggling between original function and numba-compiled one.\"\"\"\r\n\r\n    def __init__(self, func, fallback=None, jit_kwargs=None):\r\n        self.func = func\r\n        self.func_name = func.__name__\r\n        self.module_name = func.__module__\r\n        self.jit_kwargs = jit_kwargs\r\n        if fallback is not None:\r\n            self.ordinary = fallback\r\n        else:\r\n            self.ordinary = func\r\n\r\n    @property\r\n    def compiled(self):\r\n        # Compile it if this is the first time.\r\n        if (not hasattr(self, '_compiled')) and NUMBA_AVAILABLE:\r\n            if self.jit_kwargs is not None:\r\n                self._compiled = numba.jit(**self.jit_kwargs)(self.func)\r\n            else:\r\n                self._compiled = numba.jit(self.func)\r\n        return self._compiled\r\n\r\n    def point_to_compiled_func(self):\r\n        setattr(sys.modules[self.module_name], self.func_name, self.compiled)\r\n\r\n    def point_to_ordinary_func(self):\r\n        setattr(sys.modules[self.module_name], self.func_name, self.ordinary)\r\n\r\n\r\ndef try_numba_jit(func=None, **kwargs):\r\n    \"\"\"Wrapper for numba.jit() that treats the function as pure Python if numba is missing.\r\n\r\n    Usage is as with jit(): Either as a bare decorator (no parentheses), or with keyword\r\n    arguments.\r\n\r\n    The resulting compiled numba function can subsequently be turned on or off with\r\n    enable_numba() and disable_numba(). It will be on by default.\"\"\"\r\n    def return_decorator(func):\r\n        # Register the function with a global list of numba-enabled functions.\r\n        f = RegisteredFunction(func, jit_kwargs=kwargs)\r\n        _registered_functions.append(f)\r\n\r\n        if ENABLE_NUMBA_ON_IMPORT and NUMBA_AVAILABLE:\r\n            # Overwrite the function's reference with a numba-compiled function.\r\n            # This can be undone by calling disable_numba()\r\n            return f.compiled\r\n        else:\r\n            return f.ordinary\r\n    if func is None:\r\n        return return_decorator\r\n    else:\r\n        return return_decorator(func)\r\n\r\ndef disable_numba():\r\n    \"\"\"Do not use numba-accelerated functions, even if numba is available.\"\"\"\r\n    for f in _registered_functions:\r\n        f.point_to_ordinary_func()\r\n\r\n\r\ndef enable_numba():\r\n    \"\"\"Use numba-accelerated variants of core functions.\"\"\"\r\n    if NUMBA_AVAILABLE:\r\n        for f in _registered_functions:\r\n            f.point_to_compiled_func()\r\n    else:\r\n        raise ImportError(message)", "start_char_idx": 0, "end_char_idx": 3169, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d8f8d5cd-1272-4c96-88da-e6d07170aac2": {"__data__": {"id_": "d8f8d5cd-1272-4c96-88da-e6d07170aac2", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\uncertainty.py", "file_name": "uncertainty.py", "file_type": "text/x-python", "file_size": 4633, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c4cf643-8275-44c8-bb4a-d059ee2cce6c", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\uncertainty.py", "file_name": "uncertainty.py", "file_type": "text/x-python", "file_size": 4633, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6ec507bcb64a0142fffe530f6ec7c68947f989c754202cd03bbf9f095be68d84", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "02ecfb36-afed-4669-9700-dc1beb9b54c3", "node_type": "1", "metadata": {}, "hash": "7d00a62cd1a7182084bf79fca92a0bdbeac9a569673f970e760853a540c76752", "class_name": "RelatedNodeInfo"}}, "text": "import numpy as np\r\nfrom scipy.ndimage import binary_dilation\r\nfrom pandas import DataFrame\r\n\r\nfrom .masks import binary_mask, x_squared_masks\r\nfrom .utils import memo, validate_tuple\r\n\r\n\r\ndef measure_noise(image_bp, image_raw, radius):\r\n    \"\"\"Compute the mean and standard deviation of the dark pixels outside the\r\n    signal. The bandpassed image is used to identify background regions. The\r\n    raw image is used to characterize the background.\r\n    See Biophysical journal 88(1) 623-638 Figure C.\r\n\r\n    Parameters\r\n    ----------\r\n    image_bp : ndarray\r\n        preprocessed (bandpassed) image\r\n    image_raw : ndarray\r\n        raw image\r\n    radius : number or tuple of numbers\r\n        feature radius used for centroid identification\r\n\r\n    Returns\r\n    -------\r\n    background mean, background standard deviation\r\n    \"\"\"\r\n    structure = binary_mask(radius, image_bp.ndim)\r\n    background = ~binary_dilation(image_bp, structure=structure)\r\n    n_background = background.sum()\r\n    if n_background == 0:  # edge case of no background identified\r\n        return np.nan, np.nan\r\n    elif n_background == 1:  # edge case of not enough background identified\r\n        return image_raw[background].mean(), np.nan\r\n    else:\r\n        return image_raw[background].mean(), image_raw[background].std()\r\n\r\n\r\n@memo\r\ndef _root_sum_x_squared(radius, ndim):\r\n    \"Returns the root of the sum of all x^2 inside the mask for each dim.\"\r\n    masks = x_squared_masks(radius, ndim)\r\n    r2 = np.sum(masks, axis=tuple(range(1, ndim + 1)))  # each ax except first\r\n    return np.sqrt(r2)\r\n\r\n\r\ndef _static_error(mass, noise, radius, noise_size):\r\n    coord_moments = _root_sum_x_squared(radius, len(radius))\r\n    N_S = noise / mass\r\n    if np.all(radius[1:] == radius[:-1]) and \\\r\n       np.all(noise_size[1:] == noise_size[:-1]):\r\n        ep = N_S * noise_size[0] * coord_moments[0]\r\n    else:\r\n        ep = N_S[:, np.newaxis] * \\\r\n             (np.array(noise_size) * np.array(coord_moments))[np.newaxis, :]\r\n    return ep\r\n\r\n\r\ndef static_error(features, noise, diameter, noise_size=1, ndim=2):\r\n    \"\"\"Compute the uncertainty in particle position (\"the static error\").\r\n\r\n    Parameters\r\n    ----------\r\n    features : DataFrame of features\r\n        The feature dataframe should have a `mass` column that is already\r\n        background corrected.\r\n    noise : number or DataFrame having `noise` column, indexed on `frame`\r\n        standard deviation of the noise\r\n    diameter : number or tuple, feature diameter used to locate centroids\r\n    noise_size : noise correlation length, may be tuple-valued\r\n    ndim : number of image dimensions, default 2\r\n        if diameter is tuple-valued then its length will override ndim\r\n\r\n    Returns\r\n    -------\r\n    DataFrame of static error estimates, indexed like the features.\r\n    When either radius or noise_size are anisotropic, the returned DataFrame\r\n    contains one column for each dimension.\r\n\r\n    Where uncertainty estimation fails, NaN is returned.\r\n\r\n    Note\r\n    ----\r\n    This is an adjusted version of the process described by Thierry Savin and\r\n    Patrick S. Doyle in their paper \"Static and Dynamic Errors in Particle\r\n    Tracking Microrheology,\" Biophysical Journal 88(1) 623-638.\r\n\r\n    Instead of measuring the peak intensity of the feature and calculating the\r\n    total intensity (assuming a certain feature shape), the total intensity\r\n    (=mass) is summed directly from the data. This quantity is more robust\r\n    to noise and gives a better estimate of the static error.\r\n\r\n    In addition, the sum of squared coordinates is calculated by taking the\r\n    discrete sum instead of taking the continuous limit and integrating. This\r\n    makes it possible to generalize this analysis to anisotropic masks.\r\n    \"\"\"", "start_char_idx": 0, "end_char_idx": 3773, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "02ecfb36-afed-4669-9700-dc1beb9b54c3": {"__data__": {"id_": "02ecfb36-afed-4669-9700-dc1beb9b54c3", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\uncertainty.py", "file_name": "uncertainty.py", "file_type": "text/x-python", "file_size": 4633, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c4cf643-8275-44c8-bb4a-d059ee2cce6c", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\uncertainty.py", "file_name": "uncertainty.py", "file_type": "text/x-python", "file_size": 4633, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6ec507bcb64a0142fffe530f6ec7c68947f989c754202cd03bbf9f095be68d84", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d8f8d5cd-1272-4c96-88da-e6d07170aac2", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\uncertainty.py", "file_name": "uncertainty.py", "file_type": "text/x-python", "file_size": 4633, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "6caefbb63734a745a86f2094f4b25d5351d5c927d3c6e76e9c739c710a74a240", "class_name": "RelatedNodeInfo"}}, "text": "When either radius or noise_size are anisotropic, the returned DataFrame\r\n    contains one column for each dimension.\r\n\r\n    Where uncertainty estimation fails, NaN is returned.\r\n\r\n    Note\r\n    ----\r\n    This is an adjusted version of the process described by Thierry Savin and\r\n    Patrick S. Doyle in their paper \"Static and Dynamic Errors in Particle\r\n    Tracking Microrheology,\" Biophysical Journal 88(1) 623-638.\r\n\r\n    Instead of measuring the peak intensity of the feature and calculating the\r\n    total intensity (assuming a certain feature shape), the total intensity\r\n    (=mass) is summed directly from the data. This quantity is more robust\r\n    to noise and gives a better estimate of the static error.\r\n\r\n    In addition, the sum of squared coordinates is calculated by taking the\r\n    discrete sum instead of taking the continuous limit and integrating. This\r\n    makes it possible to generalize this analysis to anisotropic masks.\r\n    \"\"\"\r\n    if hasattr(diameter, '__iter__'):\r\n        ndim = len(diameter)\r\n    noise_size = validate_tuple(noise_size, ndim)[::-1]\r\n    diameter = validate_tuple(diameter, ndim)[::-1]\r\n    radius = tuple([d // 2 for d in diameter])\r\n\r\n    if np.isscalar(noise):\r\n        ep = _static_error(features['mass'], noise, radius, noise_size)\r\n    else:\r\n        assert 'noise' in noise\r\n        temp = features.join(noise, on='frame')\r\n        ep = _static_error(temp['mass'], temp['noise'], radius, noise_size)\r\n\r\n    ep[ep < 0] = np.nan\r\n\r\n    if ep.ndim == 1:\r\n        ep.name = 'ep'\r\n    elif ep.ndim == 2:\r\n        if ndim < 4:\r\n            coord_columns = ['ep_x', 'ep_y', 'ep_z'][:ndim]\r\n        else:\r\n            coord_columns = map(lambda i: 'ep_x' + str(i), range(ndim))\r\n        ep = DataFrame(ep, columns=coord_columns, index=features.index)\r\n    return ep", "start_char_idx": 2816, "end_char_idx": 4631, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5189a10d-5554-44b8-ab70-da50fe3b23a4": {"__data__": {"id_": "5189a10d-5554-44b8-ab70-da50fe3b23a4", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4a66f4ae-e766-43cd-a75e-36273460ca82", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "5ac814b97be61e283423d50560fc24efc846c097a3862ae0cc0111247653c2fe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "35e34bf0-e5ca-4f25-97c4-f10b66f8da2b", "node_type": "1", "metadata": {}, "hash": "a10cd3f22dadd095da3b50a91abd5cddb4a84c12b3a9256a6eb16150fc33d120", "class_name": "RelatedNodeInfo"}}, "text": "import logging\r\nimport functools\r\nimport re\r\nimport sys\r\nimport warnings\r\nfrom collections.abc import Hashable\r\nfrom datetime import datetime, timedelta\r\nfrom looseversion import LooseVersion\r\nfrom multiprocessing.pool import Pool\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\nimport scipy\r\nfrom scipy import stats\r\nimport yaml\r\n\r\nimport trackpy\r\n\r\n\r\ntry:\r\n    is_pandas_since_023 = (LooseVersion(pd.__version__) >=\r\n                           LooseVersion('0.23.0'))\r\nexcept ValueError:  # Probably a development version\r\n    is_pandas_since_023 = True\r\n\r\n# Emit warnings in refine.least_squares for scipy 1.5\r\ntry:\r\n    is_scipy_15 = LooseVersion(\"1.5.0\") <= LooseVersion(scipy.__version__) < LooseVersion('1.6.0')\r\nexcept ValueError:  # Probably a development version\r\n    is_scipy_15 = False\r\n\r\n\r\ndef fit_powerlaw(data, plot=True, **kwargs):\r\n    \"\"\"Fit a powerlaw by doing a linear regression in log space.\"\"\"\r\n    ys = pd.DataFrame(data)\r\n    x = pd.Series(data.index.values, index=data.index, dtype=np.float64)\r\n    values = pd.DataFrame(index=['n', 'A'])\r\n    fits = {}\r\n    for col in ys:\r\n        y = ys[col].dropna()\r\n        slope, intercept, r, p, stderr = \\\r\n            stats.linregress(np.log(x), np.log(y))\r\n        values[col] = [slope, np.exp(intercept)]\r\n        fits[col] = x.apply(lambda x: np.exp(intercept)*x**slope)\r\n    values = values.T\r\n    fits = pandas_concat(fits, axis=1)\r\n    if plot:\r\n        from trackpy import plots\r\n        plots.fit(data, fits, logx=True, logy=True, legend=False, **kwargs)\r\n    return values\r\n\r\n\r\nclass memo:\r\n    \"\"\"Decorator. Caches a function's return value each time it is called.\r\n    If called later with the same arguments, the cached value is returned\r\n    (not reevaluated).\r\n    http://wiki.python.org/moin/PythonDecoratorLibrary#Memoize \"\"\"\r\n    def __init__(self, func):\r\n        self.func = func\r\n        self.cache = {}\r\n        functools.update_wrapper(self, func)\r\n\r\n    def __call__(self, *args):\r\n        if not isinstance(args, Hashable):\r\n            # uncacheable. a list, for instance.\r\n            warnings.warn(\"A memoization cache is being used on an uncacheable \" +\r\n                          \"object. Proceeding by bypassing the cache.\",\r\n                          UserWarning)\r\n            return self.func(*args)\r\n        if args in self.cache:\r\n            return self.cache[args]\r\n        else:\r\n            value = self.func(*args)\r\n            self.cache[args] = value\r\n            return value\r\n# This code trips up numba. It's nice for development\r\n# but it shouldn't matter for users.\r\n#   def __repr__(self):\r\n#      '''Return the function's docstring.'''\r\n#      return self.func.__doc__\r\n\r\n    def __get__(self, obj, objtype):\r\n        '''Support instance methods.'''\r\n        return functools.partial(self.__call__, obj)\r\n\r\n\r\ndef extract(pattern, string, group, convert=None):\r\n    \"\"\"Extract a pattern from a string. Optionally, convert it\r\n    to a desired type (float, timestamp, etc.) by specifying a function.\r\n    When the pattern is not found, gracefully return None.\"\"\"\r\n    # group may be 1, (1,) or (1, 2).\r\n    if type(group) is int:\r\n        grp = (group,)\r\n    elif type(group) is tuple:\r\n        grp = group\r\n    assert type(grp) is tuple, \"The arg 'group' should be an int or a tuple.\"\r\n    try:\r\n        result = re.search(pattern, string, re.DOTALL).group(*grp)\r\n    except AttributeError:\r\n        # For easy unpacking, when a tuple is expected, return a tuple of Nones.\r\n        return None if type(group) is int else (None,)*len(group)\r\n    return convert(result) if convert else result\r\n\r\n\r\ndef timestamp(ts_string):\r\n    \"Convert a timestamp string to a datetime type.\"\r\n    if ts_string is None:\r\n        return None\r\n    return datetime.strptime(ts_string, '%Y-%m-%d %H:%M:%S')\r\n\r\n\r\ndef time_interval(raw):\r\n    \"Convert a time interval string into a timedelta type.\"", "start_char_idx": 0, "end_char_idx": 3886, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "35e34bf0-e5ca-4f25-97c4-f10b66f8da2b": {"__data__": {"id_": "35e34bf0-e5ca-4f25-97c4-f10b66f8da2b", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4a66f4ae-e766-43cd-a75e-36273460ca82", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "5ac814b97be61e283423d50560fc24efc846c097a3862ae0cc0111247653c2fe", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5189a10d-5554-44b8-ab70-da50fe3b23a4", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "901f3999461b321ef529b66b892d2e8dfacd4eac30fa13fb581ebec10db2559c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "909eda1a-62c4-459b-9148-6f2dc785e81a", "node_type": "1", "metadata": {}, "hash": "7411638e872feeec808d6108ff8cf5f9ccef9b734d22999107c0bfddc3251518", "class_name": "RelatedNodeInfo"}}, "text": "if type(group) is int:\r\n        grp = (group,)\r\n    elif type(group) is tuple:\r\n        grp = group\r\n    assert type(grp) is tuple, \"The arg 'group' should be an int or a tuple.\"\r\n    try:\r\n        result = re.search(pattern, string, re.DOTALL).group(*grp)\r\n    except AttributeError:\r\n        # For easy unpacking, when a tuple is expected, return a tuple of Nones.\r\n        return None if type(group) is int else (None,)*len(group)\r\n    return convert(result) if convert else result\r\n\r\n\r\ndef timestamp(ts_string):\r\n    \"Convert a timestamp string to a datetime type.\"\r\n    if ts_string is None:\r\n        return None\r\n    return datetime.strptime(ts_string, '%Y-%m-%d %H:%M:%S')\r\n\r\n\r\ndef time_interval(raw):\r\n    \"Convert a time interval string into a timedelta type.\"\r\n    if raw is None:\r\n        return None\r\n    m = re.match('([0-9][0-9]):([0-5][0-9]):([0-5][0-9])', raw)\r\n    h, m, s = map(int, m.group(1, 2, 3))\r\n    return timedelta(hours=h, minutes=m, seconds=s)\r\n\r\n\r\ndef suppress_plotting():\r\n    import matplotlib.pyplot as plt\r\n    plt.switch_backend('Agg') # does not plot to screen\r\n\r\n\r\n# HH:MM:SS, H:MM:SS, MM:SS, M:SS all OK\r\nlazy_timestamp_pat = r'\\d?\\d?:?\\d?\\d:\\d\\d'\r\n\r\n# a time stamp followed by any text comment\r\nltp = lazy_timestamp_pat\r\nvideo_log_pattern = r'(' + ltp + r')-?(' + ltp + r')? ?(RF)?(.+)?'\r\n\r\n\r\ndef lazy_timestamp(partial_timestamp):\r\n    \"\"\"Regularize a lazy timestamp like '0:37' -> '00:00:37'.\r\nHH:MM:SS, H:MM:SS, MM:SS, and M:SS all OK.\r\n\r\n    Parameters\r\n    ----------\r\n    partial_timestamp : string or other object\r\n\r\n    Returns\r\n    -------\r\n    regularized string\r\n    \"\"\"\r\n    if not isinstance(partial_timestamp, str):\r\n        # might be NaN or other unprocessable entry\r\n        return partial_timestamp\r\n    input_format = r'\\d?\\d?:?\\d?\\d:\\d\\d'\r\n    if not re.match(input_format, partial_timestamp):\r\n        raise ValueError(\"Input string cannot be regularized.\")\r\n    partial_digits = list(partial_timestamp)\r\n    digits = ['0', '0', ':', '0', '0', ':', '0', '0']\r\n    digits[-len(partial_digits):] = partial_digits\r\n    return ''.join(digits)\r\n\r\n\r\ndef timedelta_to_frame(timedeltas, fps):\r\n    \"\"\"Convert timedelta times into frame numbers.\r\n\r\n    Parameters\r\n    ----------\r\n    timedelta : DataFrame or Series of timedelta64 datatype\r\n    fps : frames per second (integer)\r\n\r\n    Result\r\n    ------\r\n    DataFrame\r\n\r\n    Note\r\n    ----\r\n    This sounds like a stupidly easy operation, but handling missing data\r\n    and multiplication is tricky with timedeltas.\r\n    \"\"\"\r\n    ns = timedeltas.values\r\n    seconds = ns * 1e-9\r\n    frame_numbers = seconds*fps\r\n    result = pd.DataFrame(frame_numbers, dtype=np.int64,\r\n                          index=timedeltas.index, columns=timedeltas.columns)\r\n    result = result.where(timedeltas.notnull(), np.nan)\r\n    return result\r\n\r\n\r\ndef random_walk(N):\r\n    return np.cumsum(np.random.randn(N), 1)\r\n\r\n\r\ndef record_meta(meta_data, file_obj):\r\n    file_obj.write(yaml.dump(meta_data, default_flow_style=False))\r\n\r\ndef validate_tuple(value, ndim):\r\n    if not hasattr(value, '__iter__'):\r\n        return (value,) * ndim\r\n    if len(value) == ndim:\r\n        return tuple(value)\r\n    raise ValueError(\"List length should have same length as image dimensions.\")\r\n\r\n\r\ntry:\r\n    from IPython.display import clear_output\r\nexcept ImportError:\r\n    pass\r\n\r\n\r\ndef make_pandas_strict():\r\n    \"\"\"Configure Pandas to raise an exception for \"chained assignments.\"\r\n\r\n    This is useful during tests.\r\n    See http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\r\n\r\n    Does nothing for Pandas versions before 0.13.0.\r\n    \"\"\"\r\n    if LooseVersion(pd.__version__) >= LooseVersion('0.13.0'):\r\n        pd.set_option('mode.chained_assignment', 'raise')\r\n\r\n\r\nclass IPythonStreamHandler(logging.StreamHandler):\r\n    \"A StreamHandler for logging that clears output between entries.\"", "start_char_idx": 3117, "end_char_idx": 7006, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "909eda1a-62c4-459b-9148-6f2dc785e81a": {"__data__": {"id_": "909eda1a-62c4-459b-9148-6f2dc785e81a", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4a66f4ae-e766-43cd-a75e-36273460ca82", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "5ac814b97be61e283423d50560fc24efc846c097a3862ae0cc0111247653c2fe", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "35e34bf0-e5ca-4f25-97c4-f10b66f8da2b", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "d4ed5d5fbda8e287ce2d55713b6fd5563b6c2342b523eda27e1bfc23eb66d057", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5fefe9c5-86a8-47cf-94a9-8739b87c1e37", "node_type": "1", "metadata": {}, "hash": "f351dd96f38326d2be435c920461354744eb09abc4ff321b0d1e67b0b6706006", "class_name": "RelatedNodeInfo"}}, "text": "try:\r\n    from IPython.display import clear_output\r\nexcept ImportError:\r\n    pass\r\n\r\n\r\ndef make_pandas_strict():\r\n    \"\"\"Configure Pandas to raise an exception for \"chained assignments.\"\r\n\r\n    This is useful during tests.\r\n    See http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\r\n\r\n    Does nothing for Pandas versions before 0.13.0.\r\n    \"\"\"\r\n    if LooseVersion(pd.__version__) >= LooseVersion('0.13.0'):\r\n        pd.set_option('mode.chained_assignment', 'raise')\r\n\r\n\r\nclass IPythonStreamHandler(logging.StreamHandler):\r\n    \"A StreamHandler for logging that clears output between entries.\"\r\n    def emit(self, s):\r\n        clear_output(wait=True)\r\n        print(s.getMessage())\r\n    def flush(self):\r\n        sys.stdout.flush()\r\n\r\n\r\nFORMAT = \"%(name)s.%(funcName)s:  %(message)s\"\r\nformatter = logging.Formatter(FORMAT)\r\n\r\n# Check for IPython and use a special logger\r\nuse_ipython_handler = False\r\ntry:\r\n    import IPython\r\nexcept ImportError:\r\n    pass\r\nelse:\r\n    if IPython.get_ipython() is not None:\r\n        use_ipython_handler = True\r\nif use_ipython_handler:\r\n    default_handler = IPythonStreamHandler()\r\nelse:\r\n    default_handler = logging.StreamHandler(sys.stdout)\r\ndefault_handler.setLevel(logging.INFO)\r\ndefault_handler.setFormatter(formatter)\r\n\r\n\r\ndef handle_logging():\r\n    \"Send INFO-level log messages to stdout. Do not propagate.\"\r\n    if use_ipython_handler:\r\n        # Avoid double-printing messages to IPython stderr.\r\n        trackpy.logger.propagate = False\r\n    trackpy.logger.addHandler(default_handler)\r\n    trackpy.logger.setLevel(logging.INFO)\r\n\r\n\r\ndef ignore_logging():\r\n    \"Reset to factory default logging configuration; remove trackpy's handler.\"\r\n    trackpy.logger.removeHandler(default_handler)\r\n    trackpy.logger.setLevel(logging.NOTSET)\r\n    trackpy.logger.propagate = True\r\n\r\n\r\ndef quiet(suppress=True):\r\n    \"\"\"Suppress trackpy information log messages.\r\n\r\n    Parameters\r\n    ----------\r\n    suppress : boolean\r\n        If True, set the logging level to WARN, hiding INFO-level messages.\r\n        If False, set level to INFO, showing informational messages.\r\n    \"\"\"\r\n    if suppress:\r\n        trackpy.logger.setLevel(logging.WARN)\r\n    else:\r\n        trackpy.logger.setLevel(logging.INFO)\r\n\r\n\r\ndef pandas_sort(df, by, *args, **kwargs):\r\n    \"\"\"\r\n    Use sort_values() to sort a DataFrame\r\n    This raises a ValueError if the given value is both\r\n    a column and an index label, i.e.:\r\n    ValueError: 'frame' is both an index level and a column\r\n    label, which is ambiguous.\r\n    Because we usually sort by columns, we can rename\r\n    the index to supress the ValueError.\r\n    \"\"\"\r\n    if df.index.name is not None and df.index.name in by:\r\n        df.index.name += '_index'\r\n    return df.sort_values(*args, by=by, **kwargs)\r\n\r\n\r\ndef _pandas_concat_post_023(*args, **kwargs):\r\n    \"\"\"Pass sort = False. Breaks API by not sorting, but we don't care. \"\"\"", "start_char_idx": 6377, "end_char_idx": 9314, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5fefe9c5-86a8-47cf-94a9-8739b87c1e37": {"__data__": {"id_": "5fefe9c5-86a8-47cf-94a9-8739b87c1e37", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4a66f4ae-e766-43cd-a75e-36273460ca82", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "5ac814b97be61e283423d50560fc24efc846c097a3862ae0cc0111247653c2fe", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "909eda1a-62c4-459b-9148-6f2dc785e81a", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "3b71bd953ed98bac7035f2eab289cb6c5cdf90706451cfbb013fa59e081e67b8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9b7ac8dd-ad1a-4d2f-8cc7-fd2c08cfe167", "node_type": "1", "metadata": {}, "hash": "5c00f42bc5019fdea480baf4a34c85f8590affbb7db74798ea58681cab63218e", "class_name": "RelatedNodeInfo"}}, "text": "if suppress:\r\n        trackpy.logger.setLevel(logging.WARN)\r\n    else:\r\n        trackpy.logger.setLevel(logging.INFO)\r\n\r\n\r\ndef pandas_sort(df, by, *args, **kwargs):\r\n    \"\"\"\r\n    Use sort_values() to sort a DataFrame\r\n    This raises a ValueError if the given value is both\r\n    a column and an index label, i.e.:\r\n    ValueError: 'frame' is both an index level and a column\r\n    label, which is ambiguous.\r\n    Because we usually sort by columns, we can rename\r\n    the index to supress the ValueError.\r\n    \"\"\"\r\n    if df.index.name is not None and df.index.name in by:\r\n        df.index.name += '_index'\r\n    return df.sort_values(*args, by=by, **kwargs)\r\n\r\n\r\ndef _pandas_concat_post_023(*args, **kwargs):\r\n    \"\"\"Pass sort = False. Breaks API by not sorting, but we don't care. \"\"\"\r\n    kwargs.setdefault('sort', False)\r\n    return pd.concat(*args, **kwargs)\r\n\r\nif is_pandas_since_023:\r\n    pandas_concat = _pandas_concat_post_023\r\nelse:\r\n    pandas_concat = pd.concat\r\n\r\n\r\ndef guess_pos_columns(f):\r\n    \"\"\" Guess the position columns from a given feature DataFrame \"\"\"\r\n    if 'z' in f:\r\n        pos_columns = ['z', 'y', 'x']\r\n    else:\r\n        pos_columns = ['y', 'x']\r\n    return pos_columns\r\n\r\n\r\ndef default_pos_columns(ndim):\r\n    \"\"\" Sets the default position column names \"\"\"\r\n    if ndim < 4:\r\n        return ['z', 'y', 'x'][-ndim:]\r\n    else:\r\n        return list(map(lambda i: 'x' + str(i), range(ndim)))\r\n\r\n\r\ndef default_size_columns(ndim, isotropic):\r\n    \"\"\" Sets the default size column names \"\"\"\r\n    if isotropic:\r\n        return ['size']\r\n    else:\r\n        return ['size_' + cc for cc in default_pos_columns(ndim)]\r\n\r\n\r\ndef is_isotropic(value):\r\n    \"\"\" Determine whether all elements of a value are equal \"\"\"\r\n    if hasattr(value, '__iter__'):\r\n        return np.all(value[1:] == value[:-1])\r\n    else:\r\n        return True\r\n\r\n\r\nclass ReaderCached:\r\n    \"\"\" Simple wrapper that provides cacheing of image readers \"\"\"\r\n    def __init__(self, reader):\r\n        self.reader = reader\r\n        self._cache = None\r\n        self._cache_i = None\r\n\r\n    def __getitem__(self, i):\r\n        if self._cache_i == i:\r\n            return self._cache.copy()\r\n        else:\r\n            value = self.reader[i]\r\n            self._cache = value.copy()\r\n            return value\r\n\r\n    def __repr__(self):\r\n        return repr(self.reader) + \"\\nWrapped in ReaderCached\"\r\n\r\n    def __getattr__(self, attr):\r\n        return getattr(self.reader, attr)\r\n\r\n\r\ndef catch_keyboard_interrupt(gen, logger=None):\r\n    \"\"\" A generator that stops on a KeyboardInterrupt \"\"\"\r\n    running = True\r\n    gen = iter(gen)\r\n    while running:\r\n        try:\r\n            yield next(gen)\r\n        except KeyboardInterrupt:\r\n            if logger is not None:\r\n                logger.warn('KeyboardInterrupt')\r\n            running = False\r\n        except StopIteration:\r\n            running = False\r\n        else:\r\n            pass\r\n\r\nEXPONENT_EPS_FLOAT64 = np.log(np.finfo(np.float64).eps)\r\ndef safe_exp(arr):\r\n    # Calculate exponent, dealing with NaN and Underflow warnings\r\n    result = np.zeros_like(arr)\r\n    result[np.isnan(arr)] = np.nan  # propagate NaNs\r\n    with np.errstate(invalid='ignore'):  # ignore comparison with NaN\r\n        mask = arr > EXPONENT_EPS_FLOAT64\r\n    result[mask] = np.exp(arr[mask])\r\n    return result\r\n\r\ndef get_pool(processes):\r\n    \"\"\"Returns the appropriate pool and map functions if multiprocessing needs\r\n    to be used, otherwise None, map.\r\n\r\n    Parameters\r\n    ----------\r\n    processes : integer or \"auto\"\r\n        The number of processes to use in parallel. If <= 1, multiprocessing is\r\n        disabled. If \"auto\", the number returned by `os.cpu_count()`` is used.", "start_char_idx": 8529, "end_char_idx": 12222, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9b7ac8dd-ad1a-4d2f-8cc7-fd2c08cfe167": {"__data__": {"id_": "9b7ac8dd-ad1a-4d2f-8cc7-fd2c08cfe167", "embedding": null, "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4a66f4ae-e766-43cd-a75e-36273460ca82", "node_type": "4", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "5ac814b97be61e283423d50560fc24efc846c097a3862ae0cc0111247653c2fe", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5fefe9c5-86a8-47cf-94a9-8739b87c1e37", "node_type": "1", "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}, "hash": "35efd4d9bef36e6a4546585f4988ea0074d691d7206448ba01619398ab32d882", "class_name": "RelatedNodeInfo"}}, "text": "Parameters\r\n    ----------\r\n    processes : integer or \"auto\"\r\n        The number of processes to use in parallel. If <= 1, multiprocessing is\r\n        disabled. If \"auto\", the number returned by `os.cpu_count()`` is used.\r\n\r\n    Returns\r\n    -------\r\n    pool, map_func\r\n\r\n    See Also\r\n    --------\r\n    batch\r\n    \"\"\"\r\n    # Handle & validate argument `processes`\r\n    if processes == \"auto\":\r\n        processes = None  # Is replaced with `os.cpu_count` in Pool\r\n    elif not isinstance(processes, int):\r\n        raise TypeError(\"`processes` must either be an integer or 'auto', \"\r\n                        \"was type {}\".format(type(processes)))\r\n\r\n    if processes is None or processes > 1:\r\n        # Use multiprocessing\r\n        pool = Pool(processes=processes)\r\n        map_func = pool.imap\r\n    else:\r\n        pool = None\r\n        map_func = map\r\n\r\n    return pool, map_func\r\n\r\n\r\ndef stats_mode_scalar(a):\r\n    \"\"\"Returns a scalar from scipy.stats.mode().\r\n\r\n    See https://docs.scipy.org/doc/scipy-1.9.3/reference/generated/scipy.stats.mode.html\r\n    \"\"\"\r\n    try:\r\n        # scipy >= 1.11\r\n        return stats.mode(a, keepdims=False).mode\r\n    except TypeError:\r\n        # Old behavior (keepdims is not accepted)\r\n        return stats.mode(a).mode[0]", "start_char_idx": 12000, "end_char_idx": 13261, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"c1bb021d-c026-414e-978d-e50117b7b240": {"node_ids": ["ec294211-ea6c-422a-9fbf-3ffdf691b338"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\__init__.py", "file_name": "__init__.py", "file_type": "text/x-python", "file_size": 285, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "b55fad2e-5468-4402-83ba-2a4dcccbb970": {"node_ids": ["aca37b48-6b1f-430f-b20b-5df62a74059a", "ec3a6d6c-8ce3-4944-a2a9-1c00ddafc32c", "b203f11e-0356-405e-b791-9c6911b38bf6", "670affde-bda1-4aa7-8d08-c792e77bfe8c", "a20f28c8-74f3-43d8-aafe-5588bf9d31f7"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\_version.py", "file_name": "_version.py", "file_type": "text/x-python", "file_size": 16126, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "526a3a14-babc-49ab-b719-060f22c8acde": {"node_ids": ["370b1bb6-4124-420a-a37c-db8eb51d68ec"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\api.py", "file_name": "api.py", "file_type": "text/x-python", "file_size": 1467, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "142d2b06-2a04-4014-b1ba-e900d1f1a974": {"node_ids": ["89ebeb32-70cb-4650-a253-7f734cfaa477", "d28bf661-b545-4d7f-b694-b82e868764ef", "d05750ce-0fc9-461c-8960-3b4226dc7cb4", "0fbed2a3-552f-4e86-b264-b5bb0b8081d9", "c237c144-f112-495f-b0a6-b4b3fd320948", "7686b79b-7ec6-44cf-8c8f-ea127aeecc50", "c86b5e4e-81b6-4f44-823d-bdb26cc82c6c", "b0d26fbf-24ad-4369-828f-0a35cb2ae210"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\artificial.py", "file_name": "artificial.py", "file_type": "text/x-python", "file_size": 22254, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "8b4cb2e3-5daf-4f35-9422-b871544a3553": {"node_ids": ["789a2479-3af1-4241-92fe-08a7e2c4bcd2"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\diag.py", "file_name": "diag.py", "file_type": "text/x-python", "file_size": 1533, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "46e93b41-ad95-4467-909a-25bee6310e92": {"node_ids": ["683b30de-b242-44b3-bdcc-1f11bf7cb7a9", "472224fc-e18f-459f-a378-42775b012790", "93638a5c-ec51-43d4-8fc0-7b7d2dd42b0f", "8b057e07-3860-4b09-bec1-6aef08707715", "243e90fc-5988-4ff2-819b-92866b8a2593", "0a2230cf-d536-4d4e-8d6e-4a79a9549907", "f87f924d-dd4d-4e3e-817b-99be324cf7d6", "b893a183-5a4c-406b-a547-3d237e52ebfd"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\feature.py", "file_name": "feature.py", "file_type": "text/x-python", "file_size": 26945, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "a2397c02-ef77-4e66-a996-bd92936a906a": {"node_ids": ["dd337360-80af-4c87-9c5f-b933e04cdf49"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\filtering.py", "file_name": "filtering.py", "file_type": "text/x-python", "file_size": 2508, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "c8e54ded-0a8c-4735-84cc-717723633d3c": {"node_ids": ["ccc71d38-5a26-47c6-ad36-c889b3ebec78", "667dff72-31cf-45b3-9418-4fba278c21d9"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\find.py", "file_name": "find.py", "file_type": "text/x-python", "file_size": 7409, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "e2be2921-7682-4cd6-97ed-f4febdca9ede": {"node_ids": ["07962b5f-fbf2-4244-b93c-44d043b8ccb8", "15caced0-bd93-4f15-97dc-2fbf877182c5", "e6b0b270-46ac-47b1-8ddb-7461aee811f3"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\framewise_data.py", "file_name": "framewise_data.py", "file_type": "text/x-python", "file_size": 10358, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "5042ea56-9bd0-42bd-972f-b469bdc85dd3": {"node_ids": ["6a8056b6-ec31-4b40-9466-2bbbf6f2ab54", "c6266478-f7d5-497c-b2d1-bbfd69f585e4", "fddc9aef-13f1-4501-97bd-5c8857c46ed4"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\masks.py", "file_name": "masks.py", "file_type": "text/x-python", "file_size": 7781, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "04960000-bdbb-4945-9b63-1b573c1547ff": {"node_ids": ["3887f856-f3bb-4ec9-afba-a4d4b730a96b", "d1245507-4d09-436e-a832-69b255e4acf3", "bfa5e719-3f1c-4a82-8b2d-c7e1b0c8d716", "c1ee8682-6045-4237-840c-176bf074517e", "84651a80-f1ca-469f-a720-0323ac01dfa2", "eb670015-50de-45f3-87d3-9a81932f56ba", "065feb0e-d739-455b-b15a-1c3f6009134c"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\motion.py", "file_name": "motion.py", "file_type": "text/x-python", "file_size": 21624, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "b9a72acd-14d0-438c-966b-ae3f50a604d0": {"node_ids": ["adb90f85-b90a-40bd-99f9-d0d3dd1d2166", "398b5d0b-9007-47da-b894-fa0ab1e4a092", "bd877776-d1ba-4c2a-8182-cf6857fe1788", "b9f62199-5805-4461-a2d5-67f69642edd4", "564888d8-ef72-4be8-8c44-ed42371db73d", "a260fdeb-846a-470b-9d3b-1e1d7e53bb34", "2115b34a-a52e-4c77-8f05-1354636b69ff", "a43c2e60-0840-4ea9-9115-d5d3f2bf2a1c", "b0131a46-10dd-4d1f-a083-3b2e3e31ef72", "10483143-2734-4430-8a32-8e0cb6a47761"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\plots.py", "file_name": "plots.py", "file_type": "text/x-python", "file_size": 31328, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "4028d764-4d2a-43ab-b597-c78ea8082de0": {"node_ids": ["aa83e7ed-7fe7-41c8-b76d-87c18ed9c522", "53fc4b1f-5534-4133-9725-7a8394a76498", "8ae21b56-433b-47d4-acb2-8bc98f2c745c", "4f83db66-c900-48be-9738-5a55289ca695", "db1e61d0-568f-4a5b-95d3-748be1b2c1af", "2525f3b0-a618-4880-a597-0ff9ea4a4639"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict.py", "file_name": "predict.py", "file_type": "text/x-python", "file_size": 20020, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "e692095b-711d-46c7-b7b8-8a052dc2e6a1": {"node_ids": ["3e754b4c-01d4-4040-8fdb-8beb3cdd70a8"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\predict_test_llama370b.py", "file_name": "predict_test_llama370b.py", "file_type": "text/x-python", "file_size": 776, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "6eff1c77-d741-4887-84c3-a75c26a30af4": {"node_ids": ["f62be28f-ba87-424e-977a-d644aac7eef8", "b12ee25d-cb1a-4b8f-af02-42f38a09f449", "8b3d4e32-ddb3-4eda-b1d7-bd348c98b8c9", "ed31e661-e370-4374-89ad-42f25ea4d794"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\preprocessing.py", "file_name": "preprocessing.py", "file_type": "text/x-python", "file_size": 12555, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "33475eeb-211e-4d3b-bea8-9814bb151a88": {"node_ids": ["328deb55-38b7-4c8d-9612-96dd37f39df8", "fa7e52b2-6abb-4f84-ab65-484b24861dc5", "e2d373b3-70f9-465b-a292-5a1f5ff2b04e", "00e0f831-a1ed-4d02-82ae-aa620fc5d848", "c7bd55a2-2933-4ef3-bc98-37c0c0944fd2", "85c6f2ad-a505-42a1-b5d2-449f2231304a", "a1bd4651-cb3c-4cab-a0e1-9dc57d636a51"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\static.py", "file_name": "static.py", "file_type": "text/x-python", "file_size": 18778, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "d62af2ac-59fc-49bf-929a-cfc3267c326e": {"node_ids": ["daf23db7-2e87-4dcc-9644-33c491552f4c"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\tracking.py", "file_name": "tracking.py", "file_type": "text/x-python", "file_size": 41, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "8b0f921c-88eb-469d-a896-42883dba0683": {"node_ids": ["b245d025-bcd9-48c8-bade-5fe385a2e175"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\try_numba.py", "file_name": "try_numba.py", "file_type": "text/x-python", "file_size": 3171, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "6c4cf643-8275-44c8-bb4a-d059ee2cce6c": {"node_ids": ["d8f8d5cd-1272-4c96-88da-e6d07170aac2", "02ecfb36-afed-4669-9700-dc1beb9b54c3"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\uncertainty.py", "file_name": "uncertainty.py", "file_type": "text/x-python", "file_size": 4633, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}, "4a66f4ae-e766-43cd-a75e-36273460ca82": {"node_ids": ["5189a10d-5554-44b8-ab70-da50fe3b23a4", "35e34bf0-e5ca-4f25-97c4-f10b66f8da2b", "909eda1a-62c4-459b-9148-6f2dc785e81a", "5fefe9c5-86a8-47cf-94a9-8739b87c1e37", "9b7ac8dd-ad1a-4d2f-8cc7-fd2c08cfe167"], "metadata": {"file_path": "C:\\Users\\marcb\\Downloads\\trackpy\\trackpy\\utils.py", "file_name": "utils.py", "file_type": "text/x-python", "file_size": 13263, "creation_date": "2024-05-30", "last_modified_date": "2024-05-30"}}}}